{
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 322.5803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.65656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up <em>Infinite</em> <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-09T21:46:22Z",
      "updated_at": "2021-11-13T20:48:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.00937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 322.5803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.65656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up <em>Infinite</em> <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-09T21:47:44Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.48206,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 322.5802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-09T21:46:22Z",
      "updated_at": "2021-11-13T20:48:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.00935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    },
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Examine logs for trace details",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-12-09T21:47:44Z",
      "updated_at": "2021-11-13T20:42:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: APM: C APM: Golang APM: Java APM: .NET APM: Node.js APM: PHP APM: Python APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. Examine logs for trace details You can bring your logs and application's data together to make troubleshooting easier and faster. With logs in context, you can see log messages related to your errors and traces directly in your app's UI. From the Transactions page, click on a trace to go to the Trace details page. From the trace details page, click See logs. To view details related to an individual log message, click directly on the message. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. To set up Infinite Tracing, you need to install the Infinite Tracing gem. The gem is available in rubygems.org. For applications using Bundler, additionally include the Infinite Tracing gem in the Gemfile: gem 'newrelic-infinite_tracing' Copy If you're using Rails 3 or higher, or Rails 2.3 in the recommended configuration, Rails will automatically call Bundler.require and cause newrelic-infinite_tracing to be required during startup of your application. If you're using Sinatra or another framework, you must manually call require 'newrelic/infinite_tracing' or manually call Bundler.require. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever or -1. For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For Infinite Tracing, you also need to install the Infinite Tracing gem. For best results, update to the latest Ruby agent version and Infinite Tracing gem version, if applicable. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 7.0.0 or higher (includes W3C Trace Context) newrelic-infinite_tracing 7.0.0 or higher Supported environments: Ruby 2.5 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.48204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " in the UI: <em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you"
      },
      "id": "6072a66564441fb28e9d8595"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 322.5802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to enable <em>Infinite</em> <em>Tracing</em>. Choosing <em>Infinite</em> <em>Tracing</em> has implications for how you configure sampling in your telemetry tool: Standard installation without <em>Infinite</em> <em>Tracing</em>: A standard installation assumes you want your telemetry tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.65646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up <em>Infinite</em> <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> data to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-12-09T21:46:22Z",
      "updated_at": "2021-11-13T20:48:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing model: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.00935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em> feature. For an overview of all <em>distributed</em> <em>tracing</em> options, see Enable <em>distributed</em> <em>tracing</em>. What is <em>Infinite</em> <em>Tracing</em>? <em>Infinite</em> <em>Tracing</em> allows you to send all your <em>trace</em> data to our cloud-based service and rely on <em>Infinite</em> <em>Tracing</em> to make sampling decisions. You can configure <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.44257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.75616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.21236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.44257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.75616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.21236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.44257,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.75616,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.21236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.44247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.75607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.21228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.44247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> <em>API</em> New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.75607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " to sample <em>trace</em> data before it&#x27;s sent to us. (If your <em>trace</em> data exceeds our <em>Trace</em> <em>API</em> limits, we may also do additional sampling.) Install with Infinite <em>Tracing</em>: If you choose Infinite <em>Tracing</em> (read requirements), we assume your telemetry tool&#x27;s sampling is set to 100%, so that all of that tool"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.21228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> <em>API</em>, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.11046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.10223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> data, telemetry tools rely on data sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.09953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.11046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ". To learn about all our <em>distributed</em> <em>tracing</em> options, see Intro to <em>distributed</em> <em>tracing</em>. Set up the <em>trace</em> observer Before setting up a <em>trace</em> observer, <em>understand</em> these points: With the exception of the <em>Trace</em> API, these instructions are not standalone; they&#x27;re part of larger enable procedures. If you&#x27;re"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Kamon AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.10223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "Enable <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you use the telemetry tools Kamon, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because <em>distributed</em> systems can generate a lot of <em>trace</em> data, telemetry tools rely on data sampling (filtering). When you install"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-12-09T20:14:27Z",
      "updated_at": "2021-12-04T21:47:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Kamon AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.09953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-09T21:50:46Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.0945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-12-09T21:49:20Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.18529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.1104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Trace map",
        "Span properties",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-12-09T21:50:46Z",
      "updated_at": "2021-11-06T02:13:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see a map of services (if available), and a \"waterfall\" display of that trace's spans. When you select a trace from the list of traces, you see details about it. Trace map If a trace involves more than one entity, and we have information about those entities, the trace page includes a map. For more about how that, see Maps in context. Span properties The UI indicates span properties with these icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span error within the scope of that span This table describes how different span errors are handled: Error type Description Spans ending in errors An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. OpenTelemetry Errors The Error Details box of the right pane is populated by spans containing otel.status_code = ERROR and displays the content of otel.status_description. Tip OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking View span events in the right pane. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID For more information on the factors affecting your access to accounts, see Account access. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 225.0945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-12-09T21:49:12Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.13986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.1104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-12-09T21:49:20Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.18529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-12-09T21:49:12Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.13986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    },
    {
      "sections": [
        "Set up the trace observer",
        "Tip",
        "Important",
        "Send sample payload",
        "Trace observer endpoints"
      ],
      "title": "Set up the trace observer",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "bf72691e2db5eb458c5d2e626b75554b2fd3d16b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/set-trace-observer/",
      "published_at": "2021-12-09T21:47:01Z",
      "updated_at": "2021-12-04T21:50:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you're following the Enable distributed tracing procedures and want to set up Infinite Tracing, you'll need to set up a trace observer. A trace observer is a cloud-based New Relic tool that decides what trace data to keep and send to New Relic. The trace observer lives in New Relic Edge, which is an AWS-based service that provides you with a low-latency and low-cost way to send your telemetry data to New Relic. The trace observer sends data via our Trace API, which is the entry point for all distributed trace data we ingest. Tip This documentation is for our Infinite Tracing feature. To learn about all our distributed tracing options, see Intro to distributed tracing. Set up the trace observer Before setting up a trace observer, understand these points: With the exception of the Trace API, these instructions are not standalone; they're part of larger enable procedures. If you're still figuring out what you need, see Enable distributed tracing. To avoid configuration conflict issues, you should ideally enable Infinite Tracing for all associated services. If some services in a trace have our standard distributed tracing enabled, you should upgrade those to Infinite Tracing. To set up a trace observer: Go to one.newrelic.com, and click Apps. Under Your apps, click New Relic Edge. Select an account in the upper-left dropdown. If you have access to multiple accounts, make sure you're in the account where you want Infinite Tracing enabled. If no trace observers are already present, click New trace observer to add one, fill out the information, and click Create. Important Note: If you select a trace observer in an EU region, you’ll still need a US-based New Relic account because data is reported to US data centers. Under the Endpoints dropdown: Copy the For other integrations endpoint value and have it ready: this will be referred to in later instructions as YOUR_TRACE_OBSERVER_URL. If you're enabling a language agent, also copy the For language agents value and have it ready: this will be referred to as YOUR_TRACE_OBSERVER_HOST. (Optional but recommended) To verify things are working, we recommend sending a sample trace payload. If you're using our Trace API: this step is especially recommended to learn how the API works. Send sample payload Important If you're using Zipkin-format data, see Send Zipkin payload. This test sends a sample trace payload with one trace and two spans from a service named Test Service A. To send this sample request: Get the license key for the account you want to report data to and have it ready. Copy the following curl request into a text editor: curl -i -H \"Content-Type: application/json\" \\ -H \"Api-Key: $YOUR_LICENSE_KEY\" \\ -H 'Data-Format: newrelic' \\ -H 'Data-Format-Version: 1' \\ -X POST \\ -d '[ { \"common\": { \"attributes\": { \"environment\": \"staging\" } }, \"spans\": [ { \"trace.id\": \"123456\", \"id\": \"ABC\", \"attributes\": { \"duration.ms\": 12.53, \"host\": \"host123.example.com\", \"name\": \"/home\", \"service.name\": \"Test Service A\" } }, { \"trace.id\": \"123456\", \"id\": \"DEF\", \"attributes\": { \"duration.ms\": 2.97, \"host\": \"host456.example.com\", \"error.message\": \"Invalid credentials\", \"name\": \"/auth\", \"parent.id\": \"ABC\", \"service.name\": \"Test Service B\" } } ] } ]' \\ '$YOUR_TRACE_OBSERVER_URL' Copy Insert your own values into the curl request: Value Description $YOUR_LICENSE_KEY Replace this with your license key. $YOUR_TRACE_OBSERVER_URL Replace this with the For other integrations endpoint value you copied in a previous step. Copy the curl request into a terminal and execute it. The test should return HTTP/1.1 202 Accepted, indicating success. If it does not, check the following common issues: Confirm that you used the For other integrations endpoint value. Confirm you're using single quotes around YOUR_TRACE_OBSERVER_URL. Check that you're using the correct API key. If your test returned HTTP/1.1 202 Accepted, go to the New Relic UI to see a query of the sample payload data using the span attribute service.name = Test Service A (here's a link for that query). Because the sample payload contains an error attribute, the error sampler will mark it for keeping. If you modify the payload to remove the error attributes, the random sampler may not choose to keep this particular trace. Tip Traces may take up to one minute to show up in the UI. (Optional) There are several ways to configure Infinite Tracing. This configuration can wait until after you've completed the enable procedures. This procedure is complete. Next, return to finish any remaining instructions for the tracing tool you started enabling: Language agents Third-party telemetry integrations (OpenTelemetry and others) Trace API: once the trace observer is set up, you're finished and can start instrumenting your application. Trace observer endpoints In the trace observer UI, there's an Endpoints dropdown. When setting up the trace observer, we have you copy these values for use at various points of our tracing tool setup instructions. There are two values: For language agents: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_HOST. This is used for configuring our language agents to send data to the trace observer. For other integrations: This value is referenced in our code examples as YOUR_TRACE_OBSERVER_URL. This is used for configuring our telemetry integrations and for sending data via the Trace API (including sending sample payloads).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.1104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up the <em>trace</em> observer",
        "sections": "Set up the <em>trace</em> observer",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "If you&#x27;re following the Enable <em>distributed</em> <em>tracing</em> procedures and want to set up Infinite <em>Tracing</em>, you&#x27;ll need to set up a <em>trace</em> observer. A <em>trace</em> observer is a cloud-based New Relic tool that decides what <em>trace</em> <em>data</em> to keep and send to New Relic. The <em>trace</em> observer lives in New Relic Edge, which"
      },
      "id": "6072a6a3e7b9d23abba5c682"
    }
  ],
  "/docs/errors-inbox/error-limiting": [
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-10T06:25:34Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.74966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "sections": [
        "Know your data limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting system limits",
        "Account-level limits",
        "Data ingest API limits",
        "Finding other agent and integration limits"
      ],
      "title": "Know your data limits",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "7c540d94a8b5e4f024d175ad53cab9fab343187c",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/view-system-limits/",
      "published_at": "2021-12-09T20:48:37Z",
      "updated_at": "2021-10-31T06:37:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting system limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Distributed tracing: Max age of span timestamp values 20 minutes. Timestamp must be within 20 minutes of current time at ingest or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Distributed tracing: Max spans per minute per account Dependent on agreement. Max limit: 2M. Distributed tracing: Max spans per trace 50K Distributed tracing: Max attributes per span 200 Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest API limits Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Finding other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our quickstarts here. Some default reporting limits are located in these tools' configuration docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.17285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Know your data <em>limits</em>",
        "sections": "Know your data <em>limits</em>",
        "body": " monitoring a new high-traffic application, or have a sudden data spike. When you do <em>reach</em> a <em>limit</em>, New Relic responds according to the type of data and the <em>limit</em> that’s <em>reached</em>. For example: We place a <em>limit</em> on the number of ingested requests per minute (RPM) per data type. When this <em>limit</em> is <em>reached</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Query system limits",
        "Important",
        "What happens when you reach a limit",
        "Tip",
        "Create a dashboard to view your limit status",
        "Resource Consumption Limits as a %",
        "Max % Consumption in an hour",
        "APM Agent API transaction events request per minute",
        "Trace API With limit line",
        "Impact FACET",
        "NrIntegrationError by limit",
        "Multi-Account limits (on time series charts only)",
        "Limit list and NrIntegrationError",
        "Limit metrics",
        "newrelic.resourceConsumption.limitValue",
        "newrelic.resourceConsumption.currentValue",
        "newrelic.resourceConsumption.impact",
        "Metric attributes",
        "Set alerts on resource metrics",
        "Limits faceted by LimitName and scoped by Timewindow",
        "Alert on a single limit",
        "Alert on limit impact faceted by dataType, impact, resource, and reason",
        "Alert on impact of a single dataType"
      ],
      "title": "Query system limits",
      "type": "docs",
      "tags": [
        "Ingest data manage data",
        "Manage data",
        "Resource metrics",
        "system limits"
      ],
      "external_id": "7ac33e47dfcfb91089e020a39097c9d648389f51",
      "image": "https://docs.newrelic.com/static/16cb17d5244a118d794df354f67bab81/c1b63/limits-dashboard.png",
      "url": "https://docs.newrelic.com/docs/data-apis/manage-data/query-limits/",
      "published_at": "2021-12-09T20:49:25Z",
      "updated_at": "2021-11-13T19:58:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has resource limits in place to protect your experience, our systems, and our other customers. These limits range from the maximum number of characters you can have in a query, to API request rates, to how many events your queries inspect, and more. This page describes the limit metrics and NrIntegrationError events that enable you to view your limits, your current data usage and overall resource consumption as compared to those limits, and the impact of experiencing a limit event. We also provide a handful of queries that, when compiled into a dashboard, can give you consistent insight into your limits status. Important While NrIntegrationError events provide data on many limits types, resource limit metrics currently only cover request rate ingestion and API query rate limits. What happens when you reach a limit Our response to reaching a limit depends on a handful of factors: the type of limit that’s reached, as well as the duration, frequency, and amount at which you exceed the limit. Exceeding a limit doesn’t always mean you experience a limit event, such as dropped data, rejected traffic, or having your data turned off for the rest of the day. We sometimes allow a small buffer before enforcing a limit. That said, any resource consumed above 100% is at risk for limit impact at any time. Many of our rate limits apply proportionally. That means if you’re barely exceeding the limit, we will take less action than if you're exceeding by 200%. Limit metrics are only visible if you're sending data in to a corresponding dataType or limitName API. For example, if you send in data via the Metric API, you’ll see the Metric API resource metrics, but if you don't send any APM data in, you won't see APM resource metrics. Tip Impact metrics will be generated regardless of impact; if there's no impact, you’ll see a 0. An NrIntegrationError event is generated when you experience impact and is a good way to quickly see if you’re experiencing any limit events. See View System Limits for more information. Create a dashboard to view your limit status Using three limit metrics together on a dashboard, you can quickly see detailed visuals of your Ingest Resource Request Per Minute limits, and with NrIntegrationError get a view into more limits. Dashboard displaying limits status using a handful of queries. We used the following queries to create this dashboard. To make a dashboard like this in New Relic One, select Dashboards, and then Create a dashboard. Then, add a new chart for each query you want to regularly monitor. The three limits metrics included in these queries are described in a separate section, below. From left to right, top to bottom: Resource Consumption Limits as a % FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) /latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName where limitTimeInterval = '1 minute' timeseries limit max Copy Max % Consumption in an hour SELECT max(`usage`) FROM (FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 as 'usage' facet limitName timeseries ) facet limitName limit max Copy APM Agent API transaction events request per minute FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) where limitName = 'APM Agent API transaction events requests per minute' TIMESERIES Copy Trace API With limit line FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'usage', latest(newrelic.resourceConsumption.limitValue) as 'limit' where limitName = 'Trace API requests per minute' TIMESERIES Copy Impact FACET From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource TIMESERIES 1 minute limit max Copy NrIntegrationError by limit FROM NrIntegrationError select count(*) facet limitName TIMESERIES MAX since 1 day ago limit max Copy Multi-Account limits (on time series charts only) If you want to see limits for multiple accounts on one chart: run this query from one of the accounts: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Click Add another query. Select a different account. Then run this query again: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) / latest(newrelic.resourceConsumption.limitValue) * 100 facet limitName, consumingAccountId where limitTimeInterval = '1 minute' timeseries limit max Copy Finally, save it. Limit list and NrIntegrationError FROM Metric, NrIntegrationError select rate(sum(newrelic.resourceConsumption.currentValue), 1 minute) as 'Per Minute Count',latest(newrelic.resourceConsumption.limitValue) as ' limit Value',(rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue)*100)as 'Percent Used', filter (count(*), where NrIntegrationError.limitValue is not null) as 'limit reached count' facet limitName limit 1000 Copy Limit metrics These metrics, used in the dashboard queries above, can hone in on a single limit or resource. Or, with the help of FACET limitName or resource provide a view across all your limits. newrelic.resourceConsumption.limitValue limitValue allows you to see the setting for a limit by limitName and understand more about what resource is linked to this limit. The following examples use the limit value metric in the query: Example for Metric API requests per minute. FROM Metric select latest(newrelic.resourceConsumption.limitValue) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select latest(newrelic.resourceConsumption.limitValue) WHERE limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.currentValue currentValue shows you how much of a given resource you’re currently consuming. To get a better glimpse into how our systems are viewing your consumption, use a rate() function with the time period that aligns with the limitTimeInterval. Limit 200. Example for Metric API request per minute: FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitName = 'Metric API requests per minute' Copy To show all limits, add FACET limitName and consider grouping by limitTimeInterval. FROM Metric select rate(sum(newrelic.resourceConsumption.currentValue),1 minute) where limitTimeInterval = '1 minute' FACET limitName limit max Copy newrelic.resourceConsumption.impact impact lets you know for any given resource what impact limit events are having. Zeros mean you are not currently impacted. The most granular we have is dataType. It is possible for multiple instances of limitName to impact a single type, such as Metric RPM and DPM. If we know, we will display limitName. From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, resource, impact, limitName TIMESERIES limit max Copy Metric attributes Attributes on newrelic.resourceConsumption.limitValue and newrelic.resourceConsumption.currentValue: limitName: The Name of the limit for the metric data, for example RPM Metric API. dataType: What kind of data the metric is tracking, for example Metric, Log, or APM. Resource: What resource is being consumed, for example Requests or DPM. limitTimeInterval: What time window this resource is evaluated for limiting. consumingAccountId: The New Relic account where the resource is being consumed. Attributes on newrelic.resourceConsumption.impact dataType: The kind of data that is being impacted, for example Metric, Log, or APM. Resource: What resource is being impacted, for example Request Rate. Impact: A count of what is happening when resource has exceeded set limit, for example dropped requests. consumingAccountId: The New Relic account where the resource is being consumed. Set alerts on resource metrics While building a dashboard to see all your limits is handy, being able to automate it is even better. You can set alerts on your limit metrics to provide updates on limits changes. Tip Because we currently only have metrics on 1 minute time windows, setting TimeWindow = 1 minute, will cover them all. Eventually, we make more metrics available, you might want to set separate alerts for limits that are enforced by different time windows. You can use the following NRQL queries to create alerts. Learn about creating alerts with NRQL queries here. Limits faceted by LimitName and scoped by Timewindow From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 facet limitName Copy Alert on a single limit From Metric select (rate(sum(newrelic.resourceConsumption.currentValue), 1 minute)/latest(newrelic.resourceConsumption.limitValue))*100 where limitName = 'my limit' Copy Alert on limit impact faceted by dataType, impact, resource, and reason From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason Copy Alert on impact of a single dataType From Metric select rate(sum(newrelic.resourceConsumption.impact), 1 minute) facet dataType, impact, resource, reason WHERE dataType = 'important things' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.15745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query system <em>limits</em>",
        "sections": "What happens when you <em>reach</em> a <em>limit</em>",
        "tags": "system <em>limits</em>",
        "body": " insight into your limits status. Important While NrIntegration<em>Error</em> events provide data on many limits types, resource <em>limit</em> metrics currently only cover request rate ingestion and API query rate limits. What happens when you <em>reach</em> a <em>limit</em> Our response to reaching a <em>limit</em> depends on a handful"
      },
      "id": "608abed9196a67a63064a7a6"
    }
  ],
  "/docs/errors-inbox/errors-inbox": [
    {
      "image": "https://docs.newrelic.com/static/45de34e3a56f26f44cbd62f69d1bb8b6/ae694/error.png",
      "url": "https://docs.newrelic.com/whats-new/2021/06/errors-inbox/",
      "sections": [
        "Errors Inbox: Error tracking across your entire stack"
      ],
      "published_at": "2021-12-09T22:53:01Z",
      "title": "Errors Inbox: Error tracking across your entire stack",
      "updated_at": "2021-06-25T12:10:39Z",
      "type": "docs",
      "external_id": "9ee9b292d1ae812a2b6cff8dbf6f0a2b19a9caa0",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Recently, we launched New Relic Errors Inbox, an error tracking solution that provides you a single place to view, triage and resolve errors across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates in our blog post and watch a demo in the latest Nerdlog episode here. What’s Included with New Relic Errors Inbox: Errors Inbox. Errors are grouped and displayed on a single screen for visibility and easy triaging. Filter to just the applications and services that you care about. Rich Error Details. Resolve errors faster with context of the full stack, including APM, Browser (RUM), Mobile, and Serverless (AWS Lambda Function) data. Error data persists to provide continued context for recurring errors. Log Data. Logs in Context are provided alongside other error data right in the error group details for even more information to resolve errors faster. Cross Team Collaboration. Work errors as a team with shared error visibility, shared comments, and an integration with Slack. Next Steps New Relic Errors Inbox is available to all New Relic Full-Stack Observability customers in the U.S. datacenter. To enable Errors Inbox, sign up for a free account or log in to your existing account and follow these steps: From one.newrelic.com, select More in the top right and click Errors Inbox. If this is your first time accessing Errors Inbox, you will be prompted to select a workload in the top left.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.83641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "sections": "<em>Errors</em> <em>Inbox</em>: <em>Error</em> <em>tracking</em> across your entire stack",
        "body": "Recently, we launched New Relic <em>Errors</em> <em>Inbox</em>, an <em>error</em> <em>tracking</em> solution that provides you a single place to view, triage and resolve <em>errors</em> across your full application stack. This exciting feature now includes Logs in Context and an integration with Slack. Read more about the latest updates"
      },
      "id": "60d5c7bfe7b9d208f1d67792"
    },
    {
      "sections": [
        "Introduction to notifications",
        "Early access",
        "Destinations",
        "Message templates"
      ],
      "title": "Introduction to notifications",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Notifications",
        "Workflows",
        "Error Inbox"
      ],
      "external_id": "f623ca3e096307c13e6e9214cc2fa6908707d101",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/intro-notifications/",
      "published_at": "2021-12-10T06:25:34Z",
      "updated_at": "2021-11-25T00:02:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Notifications are a consolidation of the different ways to send notification-events to third-party services, such as Slack, Jira, ServiceNow, and email. You can also use webhooks to send your data to any compatible third-party service. Integrate with your systems by configuring destinations and message templates. Destinations Destinations are unique identifiers and connection details for third-party systems. Use destinations to integrate, send notifications and share data between New Relic and your third-party systems. Message templates Configure the eventual notification events and map New Relic One data to your third-party services using message-templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.10487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Error</em> <em>Inbox</em>"
      },
      "id": "6190270f64441f165fe9d12b"
    },
    {
      "image": "https://docs.newrelic.com/static/43b6374d961bba813b6b0cac7118cf56/ae694/Errorsinbox_Jira.png",
      "url": "https://docs.newrelic.com/whats-new/2021/11/EI_Jira/",
      "sections": [
        "The Jira integration for errors inbox is now available",
        "We’re excited to announce the New Relic errors inbox Jira integration."
      ],
      "published_at": "2021-12-11T01:41:57Z",
      "title": "The Jira integration for errors inbox is now available",
      "updated_at": "2021-11-23T21:24:24Z",
      "type": "docs",
      "external_id": "9647462564e73c6366b152c94f58512b2d52d94d",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We’re excited to announce the New Relic errors inbox Jira integration. With the Jira integration you can start tracking, managing, and updating tickets from New Relic errors inbox. Continue to work and collaborate in the tools you're already familiar with without losing context, for faster error resolution. Start your errors inbox journey today!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.897446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The Jira integration for <em>errors</em> <em>inbox</em> is now available",
        "sections": "The Jira integration for <em>errors</em> <em>inbox</em> is now available",
        "body": "We’re excited to announce the New Relic <em>errors</em> <em>inbox</em> Jira integration. With the Jira integration you can start <em>tracking</em>, managing, and updating tickets from New Relic <em>errors</em> <em>inbox</em>. Continue to work and collaborate in the tools you&#x27;re already familiar with without losing context, for faster <em>error</em> resolution. Start your <em>errors</em> <em>inbox</em> journey today!"
      },
      "id": "619d5c0828ccbc3c38b993a7"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Destinations",
        "Early access",
        "Tip",
        "Required capabilities",
        "Manage destinations",
        "Destination status",
        "Notifications log"
      ],
      "title": "Destinations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "6a4550f053d167b43178996347fc6a51d2953e59",
      "image": "https://docs.newrelic.com/static/a4a0201ffecf01f56e314de250eeee71/c1b63/destinations-overview.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/destinations/",
      "published_at": "2021-12-10T06:26:14Z",
      "updated_at": "2021-12-10T06:26:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Destinations are where we send notifications about your New Relic One data. A destination is a unique identifier for a third-party system that you use. Destination settings contain the connection details to integrate with third-party systems and can be used across a variety of tools in New Relic One. The supported destination platforms include: Atlassian Jira ServiceNow Slack Webhook Email For more on these and other destinations, see notification integrations. Tip It's also possible to configure destinations using the aiNotifications NerdGraph API. Required capabilities Destination settings require specific capabilities: To access your settings: you need View capabilities for Applied Intelligence:Destinations or Alerts. To modify or delete your settings: you need Modify capabilities for Applied Intelligence:Destinations or Alerts. Manage destinations Go to one.newrelic.com, click Alerts & AI, and in the left nav under Enrich and Respond, click Destinations. The destinations table shows information about the existing destinations and allows users to enable, disable, and modify. To add a destination, click the appropriate platform tile. To modify destination settings, click the destination row in the destinations table. one.newrelic.com > Alerts & AI > Destinations. Destination status Destinations have a 'status' value that indicates if we encountered issues while processing and sending events to them (see the destinations table in the above image). Some errors, like Authentication or Authorization issues, require an update to the destination's connection details. After the update, the destination status value will be changed to \"Default\". Notifications log To view past notification events details, go to the Destination menu, and click the Notifications log tab. Notifications log enable you to view the history and status of all your past notifications. Here you can view the status of any notification along with related error details and destination ticket numbers. Filter your destination logs by destination type, sent by, and status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.09125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " in New Relic One. The supported destination <em>platforms</em> include: Atlassian Jira ServiceNow Slack Webhook Email For more on these and <em>other</em> destinations, see notification integrations. Tip It&#x27;s also possible to configure destinations using the aiNotifications NerdGraph <em>API</em>. Required capabilities Destination"
      },
      "id": "618f3a3ee7b9d2bd07388279"
    },
    {
      "sections": [
        "Integrations",
        "Early access",
        "Integration details",
        "Atlassian Jira",
        "Permissions",
        "Set up a Jira destination",
        "Important",
        "Two-way sync",
        "Configure the message template",
        "Send a test notification",
        "ServiceNow (Incident-Management)",
        "Roles",
        "Set up a destination",
        "Slack",
        "Prerequisites",
        "Set up a Slack destination",
        "Configure the Slack message settings",
        "Webhook",
        "Set up a webhook destination",
        "Configure the webhook event template",
        "Customize the webhook payload",
        "Email",
        "Configure the email settings"
      ],
      "title": "Integrations",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident Intelligence",
        "Destinations"
      ],
      "external_id": "7220c630fc187bb61784ff2cc2213e588b269b00",
      "image": "https://docs.newrelic.com/static/d4e9baecc3a76dd1a5945f8ec0aeca66/c1b63/webhook-notification-template.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/notifications/notification-integrations/",
      "published_at": "2021-12-10T06:26:14Z",
      "updated_at": "2021-12-10T06:26:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Early access The features described here are early access. You won't be able to use these features if you're not part of the early access program. For more information on related features, see our docs on Alerts notification channels, Incident Intelligence destinations, and Proactive Detection notifications. Alerts and Applied Intelligence notification integrations are specific services and platforms you can use to send notifications from New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud) and automatically create and update Jira issues. Permissions The required permissions from the Jira API-Token are create, edit, and close tickets. To enable the two-way sync toggle, the provided Jira API-Key should have an Admin role. Set up a Jira destination Create Jira issues, then enable Jira and New Relic to share updates and stay synced. To create a Jira destination, enter the following information: Destination name: Custom name to identify the destination Jira account endpoint: the URL of the destination User-name: this will be the email address of the user making the connection API token: generated from your Atlassian account Important New Relic currently supports Atlassian-Jira Classic (company-managed) projects. Before saving the destination, we recommend you test the connection via the test connection button. Jira destination configuration. We recommand to test the connection before saving. Two-way sync You can enable a two-way integration with Jira to keep the issues' state synced with the corresponding state in New Relic. To enable two-way sync, turn on the ‘two-way integration’ toggle. When turned on, a Jira Webhook would be created in your Jira account at a later stage, for the selected project (see ‘customize a message template’). The webhook would contain access details to Newrelic (URL and Newrelic-API-KEY) Configure the message template To configure a template for a Jira issue, you first need to choose a destination. You will be able to create a new destination at this stage. Upon successful connection to the destination, you will need to choose a project, and then select the Jira issue type you would like to be used. Once the issue-type is selected, the configured project's fields are fetched from your account and automatically mapped to your Jira instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Jira message template. Send a test notification You can see how the JIRA issue will appear by clicking a test notification with default field values. If successful, a JIRA issue will be created and a link will appear. ServiceNow (Incident-Management) Integrate New Relic with ServiceNow Incident-Management and automatically create and update incidents. Roles As part of the integrations, we fetch fields from the your serviceNow incident table and optional values. For this, the provided ServiceNow user details required read permissions for the tables: sys_dictionary, sys_choice, sys_user and task. A read/write permission to incident To be able to fetch users for the caller column, we required read permissions for the sys_users table. The above permissions can be achieved with the roles personalize_choices, personalize_dictionary, rest_service, itil. Read/Write permissions to the api_key_credentials table is required to enable two-way integration. This can be covered with the roles credentials_admin and discovery_admin. Set up a destination To create a ServiceNow destination, enter the following information: Destination Name: custom name to identify the destination Domain: the URL of the destination User-name: the name of the user Password: the user name’s password Before saving the destination, we recommend testing the connection by clicking the test connection button. Two-way sync You can configure a two-way integration with ServiceNow Incidents Management to keep the incidents' state synced with the corresponding state in New Relic. Here are some required steps to remember when configuring the two-way integration: Turn on the two-way integration toggle. Open and download this XML file, which includes the business rule triggering events back to New Relic One. In the ServiceNow sidebar menu, go to System Definition > Business Rules. Click the menu icon in one of the column headers, select Import XML and upload the XML file you downloaded. Once the Destination is saved, a New-Relic API-Key will be kept in the api_key_credentials. The key would sent in a header as part of the callback REST call to New-Relic Configure the message template Upon a successful connection, ServiceNow incident table columns are fetched from your account and automatically mapped to your ServiceNow instance. To help you get started, we automatically present the required and recommended fields and values. Required fields must be set with a value. You can add or remove optional fields(use the X mark on their right side) Select, edit or remove fields for the ServiceNow-Incident template. Send a test notification You can see how the ServiceNow incident will appear by clicking a test notification with default field values. If successful, an incident will be created and a link will appear. Slack Send notifications-messages to your Slack channels. Prerequisites Your Slack workspace needs to have the New Relic application installed. The application must be approved by a workspace admin before it can be individually installed by users Set up a Slack destination Click on the `one-click Slack authentication' will lead you to the Slack landing page to continue the OAuth2 authentication process. On the Slack landing page, if you're not signed into the required workspace, you're redirected to Slack to sign in. Add your workspace name or select the relevant workspace and click Continue. When signed in to the selected workspace, you are requested to allow New Relic to perform the specified actions. Clicking `Allow' will redirect you back to the Destination page. Configure the Slack message settings Select a Destination(Workspace) and select a Slack-channel where the messages will be sent. You can create a new destination if there is no pre-defined destination for the required workspace. Note that, for privacy reasons, users need to be authenticated to select private channels (one-time process) Send a test notification You can send a test notification with a pre-defined example payload to the channel. This creates a message in the selected Slack-channel. Webhook Use the webhook notifier to send the notification messages to any endpoint you like. Set up a webhook destination To create a webhook destination, you need the following: Destination Name: A unique destination name URL: the endpoint of the target application, authentication and custom headers if needed. Authorization mechanism (Optional):. Can be basic authentication or a bearer token Configure the webhook event template Pick a webhook destination from the list and configure the HTTP-POST request. The request configuration requires you to: Set a name for the template. Select a pre-configured destination from the destinations list or create a new one. Add custom headers (optional). Configure the request’s payload. Customize the webhook payload You can use the default payload or customize it to contain the required data. Pick Variables from the variables menu and apply handlebars syntax to enrich your webhook. Note that the request’s content-type is JSON by default. Hence, the payload needs to keep the JSON form. See Usage examples The ‘preview’ section on the right hand-side shows an expected payload after the template is rendered. If the eventual payload would not form a valid Json, an error will be shown and it won’t be possible to save the template. If the webhook payload conforms a valid Json, you can send a test notification to your defined webhook destination We recommend sending a test notification to make sure that everything's connected correctly. Email Send email notifications to users. Configure the email settings Add one or more recipients. Users with New Relic accounts can be found via autocomplete when searching for their name or email address. To add a user without a New Relic account or email distribution list, add the full email address. Every recipient will be translated into a 'destination'. You can follow the email notifications per destination in the notifications-log Send a test notification You can send a test notification to make sure the email notifications reach the inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.56633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Important</em>",
        "body": " notifications. Alerts and Applied Intelligence notification integrations are specific services and <em>platforms</em> you can use to send notifications <em>from</em> New Relic. Integration details Read more about each of our specific notification integrations. Atlassian Jira Integrate New Relic with Atlassian Jira(Cloud"
      },
      "id": "618ff71628ccbc60710321e4"
    },
    {
      "sections": [
        "Datarobot MLOps integration",
        "Integrate Datarobot with New Relic",
        "Connect your Datarobot data to New Relic",
        "Monitor your machine learning models [#monitor]"
      ],
      "title": "Datarobot MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOps integrations",
        "Datarobot integrations"
      ],
      "external_id": "951e675ea15cd955a488bb0dd1ea326ce1a79302",
      "image": "https://docs.newrelic.com/static/e5770f365474a584b077b7565f273a79/c1b63/algorithmia-flow.png",
      "url": "https://docs.newrelic.com/docs/mlops/integrations/datarobot-mlops-integration/",
      "published_at": "2021-12-10T14:55:24Z",
      "updated_at": "2021-12-10T10:55:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Datarobot provides tools for deploying your machine-learning models into production. By integrating Datarobot with New Relic, you'll be able to instrument, analyze, troubleshoot, and optimize your machine-learning performance across your entire system. By rigorously observing your capabilities, you'll be able to react quickly to changes in the model's input or output and the relationship between the two. Send your model performance metrics from Datarobot Insights to New Relic and you'll have real-time monitoring for your algorithms. You'll explore your metrics data with user-friendly charts and learn the state of your algorithms at a glance for faster and more efficient troubleshooting. Integrate Datarobot with New Relic First, Datarobot uses a Kafka topic to stream Insights from your machine-learning algorithm's performance metrics. Then, the New Relic connector (another algorithm) transforms the Kafka topic into a metrics data payload for a specific New Relic account. Datarobot uses Kafka and Event Flows to send data to New Relic. With Datarobot’s Event Flows, when a new message is set to your Kafka topic, your configured New Relic connector algorithm gets called. The connector transforms your metrics and sends them to your New Relic account. Connect your Datarobot data to New Relic By integrating Incident Intelligence with your Datarobot machine-learning models, you can monitor your machine learning model performance. Start monitoring your Datarobot event flows with New Relic. Get your API key: From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard: From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Datarobot Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Datarobot Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Configure Datarobot Insights for New Relic: Use Datarobot's docs for how to configure Datarobot for New Relic. Create the New Relic connector algorithm: Use Python 3.8 to create a connector algorithm. If you're new to writing code to generate algorithms, see Datarobot's getting started guide. import Datarobot import json from datetime import datetime from newrelic_telemetry_sdk import GaugeMetric, MetricClient client = Datarobot.client() metric_client = MetricClient(os.environ[\"newrelic_api_key\"]) def convert_str_timestamp_to_epoch(str_time): obj_time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%S.%f\") return int(obj_time.timestamp() * 1000) def get_operational_metrics(payload): ALGORITHM_TAGS = { \"algorithm_version\", \"request_id\", \"time\", \"algorithm_name\", \"session_id\", \"algorithm_owner\" } inference_metrics = { key: payload[key] for key in payload.keys() ^ ALGORITHM_TAGS } return inference_metrics def send_to_newrelic(inference_metrics, insights_payload): newrelic_metrics = [] for key, value in inference_metrics.items(): name = \"algorithmia.\" + key epoch_time = convert_str_timestamp_to_epoch(insights_payload[\"time\"]) tags = { \"algorithm_name\": insights_payload[\"algorithm_name\"], \"algorithm_version\": insights_payload[\"algorithm_version\"], \"algorithm_owner\": insights_payload[\"algorithm_owner\"], \"request_id\": insights_payload[\"request_id\"], \"session_id\": insights_payload[\"session_id\"], } newrelic_metrics.append(GaugeMetric( name=name, value=value, tags=tags, end_time_ms=epoch_time )) response = metric_client.send_batch(newrelic_metrics) response.raise_for_status() def apply(input): insights_payload = input inference_metrics = get_operational_metrics(insights_payload) send_to_newrelic(inference_metrics, insights_payload) return None Copy Include these dependencies: algorithmia>=1.0.0,<2.0 newrelic_telemetry_sdk==0.4.2 Copy Once your algorithm build finishes, you can test it with this sample payload to make sure it runs successfully. Your output should look something like this. { \"risk_score\": 0.2, \"duration_milliseconds\": 8, \"algorithm_version\": \"1.0.6\", \"session_id\": \"rses-f28bb94a-5556-4aeb-a6d2-89493626bf4f\", \"time\": \"2021-02-20T00:21:54.867231\", \"algorithm_name\": \"credit_card_approval\", \"request_id\": \"req-9f5345b4-a1cd-431c-a43a-bd2a06f4a6f4\", \"algorithm_owner\": \"asli\" } Copy Configure with your API key: Add your New Relic API key to the Datarobot secret store. Set up Datarobot Event Flows with New Relic: See Datarobot's documentation on setting up your connector algorithm to send event-based machine learning flows to New Relic. Monitor your machine learning models [#monitor] Follow these steps to get the most of observing your machine-learning data in New Relic. Get your API key: From one.newrelic.com the account menu, click API keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on API keys, see our docs. Create a dashboard: From one.newrelic.com go to Dashboards, then click the Import dashboards button. Copy and paste the JSON code into the Paste your JSON field code. Update the YOUR_ACCOUNT_ID values with your account ID. { \"name\": \"Datarobot Dashboard for Default Metrics\", \"description\": null, \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Datarobot Dashboard for Default Metrics\", \"description\": null, \"widgets\": [ { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Runtime Duration by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT average(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Throughput by Algorithm\", \"rawConfiguration\": { \"legend\": { \"enabled\": true }, \"nrqlQueries\": [ { \"accountId\": YOUR_ACCOUNT_ID, \"query\": \"SELECT count(algorithmia.duration_milliseconds) FROM Metric TIMESERIES FACET `algorithm_name` LIMIT 10 SINCE 1800 seconds ago\" } ], \"yAxisLeft\": { \"zero\": true } }, \"linkedEntityGuids\": null } ] } ] } Copy Set up alerts notifications: Once you've created some dashboards, you can get alerted on your data. To create a NRQL alerts condition from a chart, click the chart menu , then click Create alert condition. Once you've named and customized your condition, you can add it to an existing policy or create a new one. Get notified: Once you've created an alerts condition, you can choose how you want to be notified. See our docs on how to set up notification channels. Correlate your incidents: In addition to notifications, you can use Incident Intelligence to correlate your incidents. See our docs on how to correlate incidents using decisions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.14049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Datarobot</em> MLOps integration",
        "sections": "<em>Datarobot</em> MLOps integration",
        "tags": "<em>Datarobot</em> integrations",
        "body": " Relic. Get your <em>API</em> key: <em>From</em> one.newrelic.com the account menu, click <em>API</em> keys and then create a user key for your account with a meaningful name. Make note of this name for later. For more on <em>API</em> keys, see our docs. Create a dashboard: <em>From</em> one.newrelic.com go to Dashboards, then click the <em>Import</em>"
      },
      "id": "61b15c85e7b9d22b7facd3a5"
    }
  ],
  "/docs/glossary/glossary": [
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "f47a40a9afd699e69c351f5e87f64ed5dadd7e43",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/intro-new-relic/",
      "published_at": "2021-12-09T21:22:45Z",
      "updated_at": "2021-11-23T21:21:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will set up many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in New Relic One, no matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data that’s more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic Instant Observability. There you will find integrations bundled into quickstarts, providing you instant access to pre-built dashboards and alerts specific to your technology. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure you’re meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. As a full platform user you get access to our entire set of observability tools in New Relic One: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.60742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em>",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. <em>Get</em> <em>started</em> with <em>New</em> <em>Relic</em> Here&#x27;s how you can quickly <em>get</em> <em>started</em> capturing and analyzing your data: If you don&#x27;t have a <em>New</em> <em>Relic</em> account, sign up at newrelic.com&#x2F;signup. It&#x27;s"
      },
      "id": "619d5b3e196a6705bda0837d"
    },
    {
      "sections": [
        "Our EU and US region data centers",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Our EU and US region data centers",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "38baae8599707418dbb5d42e05001e202b1bd28c",
      "image": "https://docs.newrelic.com/static/45e4547efe0b69d68711fc9786383ab1/c1b63/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/our-eu-us-region-data-centers/",
      "published_at": "2021-12-09T21:01:09Z",
      "updated_at": "2021-10-31T08:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.58739,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "6044586c64441f844b378edd"
    },
    {
      "sections": [
        "Find help and use the Support portal",
        "Ask in New Relic's Explorers Hub, our free forum",
        "Run the New Relic Diagnostics tool",
        "Find answers in New Relic Docs and New Relic University",
        "Contribute to our documentation",
        "Don't find what you need? File a documentation issue",
        "File a ticket in the support portal",
        "Important",
        "Check the status of our systems",
        "Licenses and security information"
      ],
      "title": "Find help and use the Support portal",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "a3cb329c2dbc048ddecfb4b42a4bf08c4d94206e",
      "image": "https://docs.newrelic.com/static/c1aad1bdedcb0decd159ea2f000d0cf7/c1b63/new-relic-explorers-hub.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/find-help-use-support-portal/",
      "published_at": "2021-12-09T20:58:35Z",
      "updated_at": "2021-09-08T11:34:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of support options, including online help, a troubleshooting tool, open source documentation with detailed procedures and troubleshooting tips, and support assistance. Ask in New Relic's Explorers Hub. Run the New Relic Diagnostics tool. Find answers in New Relic Docs and New Relic University. Contribute to our documentation. Don't find what you need? File a documentation issue. File a ticket in the support portal. Check the status of our systems. Read about our licenses, data security, and compliance information. Ask in New Relic's Explorers Hub, our free forum New Relic's Explorer Hub is our forum that's free for all users. New Relic users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss new features. discuss.newrelic.com: The Explorer Hub is our public forum. Use it to ask questions and find answers. Join our community of users to learn more about New Relic and get some inspiration. Run the New Relic Diagnostics tool New Relic Diagnostics is our automated diagnostic tool for Linux, Windows, and Mac. If it detects a problem with any of our agents, it suggests solutions and saves troubleshooting logs that you can attach to tickets. Find answers in New Relic Docs and New Relic University New Relic's docs site contains helpful installation, configuration, and troubleshooting tips. From the main page, select from frequently-used categories and topics, like release notes. Or, search from any page. For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. Contribute to our documentation Our documentation is open source and available in GitHub, and we encourage you to contribute! We really care about ensuring our docs are helpful, complete, and accurate. To edit a page, click the Edit page button in any document to create a pull request with the edit you think is needed. We don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. Don't find what you need? File a documentation issue If you can't find an answer in the documentation, you can file an issue to ask us for help. When you find places the docs could be better, let us know too! To do it, click the Create issue button in any document and we'll look into your problem to find a solution. docs.newrelic.com: At the right-hand side of each page you'll find a feedback widget. Use it to tell us whether a page is helpful, create an issue, or edit the page. File a ticket in the support portal If none of the above methods worked, go to support.newrelic.com. The Support portal gives you access to unified search across all of New Relic's help resources. If you can't find what you are looking for and your subscription level includes technical support, you can file a support ticket. Important Support for beta or limited release features may not be available. To file a new ticket: Go to support.newrelic.com > Login. From the Support portal, select the area of New Relic where you need help. Select your account. Provide as many details as possible. Include the URL, if applicable, or select Attach file to include a log file, a New Relic Diagnostics file, screenshots, or other useful attachments. Click Submit. Check the status of our systems It's always a good idea to visit status.newrelic.com to check the status of our systems. If there are open incidents, you'll be able to find more information. Licenses and security information Review New Relic's licenses, attributions, and other notices. Read about our data security, privacy, and compliance policies.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.4205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find help and <em>use</em> the Support portal",
        "sections": "Ask in <em>New</em> <em>Relic&#x27;s</em> Explorers Hub, our free forum",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>Relic</em>&#x27;s Explorer Hub is our forum that&#x27;s free for all users. <em>New</em> <em>Relic</em> users and employees engage every day in conversations to troubleshoot and solve issues, find workarounds, and discuss <em>new</em> features. discuss.newrelic.com: The Explorer Hub is our public forum. <em>Use</em> it to ask questions and find"
      },
      "id": "603eb6b5e7b9d299072a07e5"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53873,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63017,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55759,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55759,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53835,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-10T05:16:31Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.19595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.6301,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55731,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55719,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5379,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-10T05:16:31Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.19591,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53764,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.5376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon EC2 monitoring integration",
        "Features",
        "Activate EC2 integration",
        "Important",
        "Configuration and polling",
        "Note about legacy tag format",
        "Use data in New Relic UI",
        "View and use data"
      ],
      "title": "Amazon EC2 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "80772c2f77cfe424ea3432d5023737b5dc03cf9e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration/",
      "published_at": "2021-12-10T05:16:31Z",
      "updated_at": "2021-10-30T20:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring integrations include an Amazon Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon's EC2 is a central part of Amazon's cloud-computing platform. All New Relic Infrastructure users, regardless of subscription level, can use the New Relic Infrastructure agent to get a comprehensive, real-time view of their host's performance and status. New Relic's EC2 integration uses the ec2Describe* policy to add data about your EC2 instances to your standard Infrastructure data. Infrastructure also imports Amazon EC2 custom tags and adds it to your data. You can also create custom attributes to be analyzed in New Relic. Activate EC2 integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important You must install the infrastructure agent on each EC2 host to see metrics from that host. Connecting your EC2 account allows New Relic to access EC2 metadata, such as region, type, and tags. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon EC2 integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes, depending on CloudWatch plan Note about legacy tag format Starting October 27, 2021, EC2 instances that start being monitored by New Relic have only the following metadata tag formats: Tag format in UI: tag.tagName Tag format as attribute: provider.attributeName. Examples: provider.ec2InstanceId, provider.ec2State, provider.ec2AmiId. For your EC2 instances monitored by New Relic before that date, you have the option to keep our legacy tag formats (below). To keep these formats, go into the New Relic configuration UI for your EC2 host and select Keep legacy metadata format. This allows you to access tags that have both current and legacy formats. Disabling the legacy format means you can only use the current format. If you disable the legacy format, consider checking to see if you have dashboards or alert conditions using that format. The legacy metadata tag format: Legacy tag format in UI: provider.ec2Tag_tagName ec2Tag_tagName Legacy tag format as attribute: attributeName. Examples: ec2InstanceId, ec2State, ec2AmiId. Use data in New Relic UI This table describes the locations in New Relic One where you can find and use your EC2 data: UI page You can... System page Examine overall resource usage by CPU, load, and memory. Processes page Monitor CPU, memory, and I/O read or write processes. Network page View bandwidth and error data to examine saturation levels, compare load balances, and identify other potential performance problems. Storage page Monitor the capacity and efficiency of overall utilization, disk usage, or I/O operations. Inventory page Review detailed configuration data by hosts, specific EC2 instances, etc. Events page From a live feed of changes in your environment, search for and view EC2 events. Integrations page Find links to several product locations where you can find and use EC2 integration data, including links to alert condition creation and viewing your data in New Relic. Infrastructure also imports your Amazon EC2 custom tags, typically prefaced by label.<tag_key>. For more on how to find and use integration data, see Understand integration data. View and use data You can query and explore your data using the ComputeSample event type, with a provider value of Ec2Instance. The EC2 integration collects the following subset of instance metrics from AWS CloudWatch. Name Description statusCheckFailedInstance Reports whether the instance has passed the instance status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailedSystem Reports whether the instance has passed the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). statusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in a one minute period. The check result can be either 0 (passed) or 1 (failed). For more about the specific data that can be reported, see EC2 integration attributes. For complete descriptions, see the Amazon EC2 documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.195885,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> EC2 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure monitoring <em>integrations</em> include an <em>Amazon</em> Elastic Compute Cloud (EC2) integration for reporting your EC2 metadata to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em>&#x27;s EC2 is a central part"
      },
      "id": "617da7aee7b9d2c532c039e8"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53748,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53748,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53743,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55661,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.55661,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon ECS/ECR monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Tip",
        "Cluster and service metrics",
        "Cluster metrics",
        "Service metrics",
        "Inventory data",
        "aws/ecs/cluster",
        "aws/ecs/service"
      ],
      "title": "Amazon ECS/ECR monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "58ee15de138543031f8b39f407369a50a15758b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration/",
      "published_at": "2021-12-10T06:31:58Z",
      "updated_at": "2021-12-04T17:01:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon EC2 Container Service (ECS) data and your Amazon EC2 Container Registry (ECR) data to New Relic products. This document explains the integration's features, how to activate it, and what data can be reported. Important New Relic also offers an ECS on-host integration, which reports a different data set than this cloud integration. For complete ECS monitoring, we recommend enabling both integrations. Features With New Relic's ECS/ECR monitoring integration, you can monitor reserved vs. utilized capacity, task execution, and registry of containers. AWS integration data is also available for analysis and chart creation in New Relic One. Activate integration To enable this integration, follow standard procedures to Connect AWS services to New Relic. If you have services running on ECS, you can also enable monitoring of those services. Important In AWS, you have to opt-in for the new ARN format (announcement) to differentiate services with the same name in different clusters. If not, you could have data collision Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon ECS/ECR integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute or 5 minutes Find and use data To find this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Amazon ECS/ECR integration links. You can query and explore your data using the ComputeSample event type. Use a provider value of EcsCluster for cluster data, or a provider value of EcsService for cluster-service data. The integration collects these ECR/ECS definitions: Name Description ClusterName This dimension filters the data you request for all resources in a specified cluster. All Amazon ECS metrics are filtered by ClusterName. ServiceName This dimension filters the data you request for all resources in a specified service within a specified cluster. For more on how to find and use integration data, see Understand integration data. Metric data The ECS/ECR integration collects the following data: Tip For full descriptions of these metrics, see Amazon's documentation on ECS and ECR. Cluster and service metrics Name Data type CPUUtilization percent MemoryUtilization percent Cluster metrics Name Data type CPUReservation percent MemoryReservation percent Service metrics Name Description Active Service The number of services that are running on the cluster in an ACTIVE state Pending Tasks Number of tasks in the cluster that are in PENDING state Running Tasks Number of tasks in the cluster that are in RUNNING state Registered Instances Number of container instances registered into the cluster Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. aws/ecs/cluster Name Description status The status of the cluster. The valid values are ACTIVE or INACTIVE. ACTIVE indicates that you can register container instances with the cluster and the associated instances can accept tasks. name User-generated string to identify the cluster. awsRegion AWS region where the cluster is running. aws/ecs/service Name Description status The status of the service. The valid values are ACTIVE, DRAINING or INACTIVE. ACTIVE means the instance accepts new tasks, DRAINING means the instance prevents new tasks from being started and notifies the service scheduler to move tasks to other instances in the cluster, generally used with the purpose of maintaining the instance or scale it down and INACTIVE means the instance is not active. clusterName User-generated string to identify the cluster. serviceName User-generated string to identify the service. launchType Type of infrastructure on which tasks and services are hosted. The valid values are EC2 and FARGATE. awsRegion AWS region where the service is running. deploymentMaximumPercent Upper limit on the number of service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount. deploymentMinimumPercent Lower limit on the number of service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount. desiredCount The number of instantiations of the specified task definition to place and keep running on the cluster. taskDefinition ARN of the task definition file that describes the containers that form the application.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.53738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> ECS&#x2F;ECR monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> EC2 Container Service (ECS) data and your <em>Amazon</em> EC2 Container Registry (ECR) data to New Relic products. This document explains the integration&#x27;s features, how to activate it, and what data can be reported"
      },
      "id": "617d6c3064441facbdfbcea9"
    },
    {
      "sections": [
        "Amazon S3 monitoring integration",
        "Features",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Amazon S3 data for buckets",
        "Amazon S3 data for request metrics",
        "Inventory data",
        "Tip",
        "/bucket",
        "/bucket/acl",
        "/bucket/acl/owner",
        "/bucket/crossOriginConfiguration",
        "/bucket/lifecycleConfiguration",
        "/bucket/loggingConfiguration",
        "/bucket/notificationConfiguration/configurations",
        "/bucket/policy",
        "/bucket/replicationConfiguration",
        "/bucket/taggingConfiguration",
        "/bucket/versioningConfiguration",
        "/bucket/websiteConfiguration"
      ],
      "title": "Amazon S3 monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "57b94df7edeb1069d468f62a9c5802823319acc7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration/",
      "published_at": "2021-12-10T05:21:26Z",
      "updated_at": "2021-11-13T14:01:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. With New Relic's Amazon S3 integration, data reported includes S3 bucket size, bucket object counts, GET requests, POST requests, and other metrics and inventory data. S3 data is available in pre-built dashboards and you can also create custom queries and charts in New Relic One. You can also create alert conditions to notify you of changes in S3 data. Activate integration Important Request and Data Transfer metrics are premium metrics and paid for separately through AWS. For Cloudwatch pricing information, see Amazon's S3 enhanced monitoring documentation. To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon S3 integration: New Relic polling intervals: S3 buckets: 1 hour S3 requests: 5 minutes Amazon CloudWatch polling intervals: S3 buckets: 24 hours S3 requests: 1 minute Note that changing the polling interval for this integration will only affect data collection for S3 request metrics. Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the S3 integration links. You can query and explore your data using the DatastoreSample event type, with a provider value of S3Bucket. For more on how to use your data, see Understand integration data. Metric data This integration collects the following Amazon S3 metrics. For more details about these metrics, see Amazon's S3 documentation. Amazon S3 data for buckets Metric Description BucketSizeBytes The amount of data in bytes stored in a bucket including Standard Storage, Reduced Redundancy Storage, Infrequent Access Storage (IAS), One zone IAS, and Glacier Storage including overheads. NumberOfObjects The total number of objects stored in a bucket for all storage classes except for the GLACIER storage class. Amazon S3 data for request metrics To collect these metrics, you must enable request metrics for your S3 bucket: Metric Description AllRequests The total number of HTTP requests made to an Amazon S3 bucket, regardless of type. If you’re using a metrics configuration with a filter, then this metric only counts HTTP requests from objects which meet the filter's requirements. GetRequests The number of HTTP GET requests made for objects in an Amazon S3 bucket. This doesn't include list operations. PutRequests The number of HTTP PUT requests made for objects in an Amazon S3 bucket. DeleteRequests The number of HTTP DELETE requests made for objects in an Amazon S3 bucket. This also includes Delete Multiple Objects requests. This metric shows the number of requests, not the number of objects deleted. HeadRequests The number of HTTP HEAD requests made to an Amazon S3 bucket. PostRequests The number of HTTP POST requests made to an Amazon S3 bucket. ListRequests The number of HTTP requests that list the contents of a bucket. BytesDownloaded The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max BytesUploaded The number bytes uploaded that contain a request body, made to an Amazon S3 bucket. Valid statistics: Average (bytes per request), Sum (bytes per period), Sample Count, Min, Max 4xxErrors The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The average statistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count 5xxErrors The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1. The averagestatistic shows the error rate, and the sum statistic shows the count of that type of error, during each period. Valid statistics: Average (reports per request), Sum (reports per period), Min, Max, Sample Count FirstByteLatency The per-request time, in milliseconds, from the time the S3 bucket received a complete request to the time the response started to be returned. Valid statistics: Average, Sum, Min, Max, Sample Count TotalRequestLatency The elapsed per-request time, in milliseconds, from the first byte received to the last byte sent to an Amazon S3 bucket. This includes the time taken to receive the request body and send the response body, which is not included in FirstByteLatency. Valid statistics: Average, Sum, Min, Max, Sample Count Inventory data This integration collects the following inventory data. For more about inventory data, see Understand integration data. Tip In order to fetch inventory data for the following items, you must have extended inventory collection turned on: /bucket/acl /bucket/loggingConfiguration /bucket/notificationConfiguration/configurations /bucket/policy /bucket/replicationConfiguration /bucket/versioningConfiguration /bucket/websiteConfiguration /bucket/lifecycleConfiguration /bucket/crossOriginConfiguration /bucket Name Description region The AWS region this bucket is provisioned in. name Name of the S3 bucket. /bucket/acl Name Description grantList This property holds the list of accounts that have been granted access according to the S3 Access Control List (ACL) for the bucket. JSON format. For more about ACLs, see Amazon's ACL documentation. isRequesterCharged True if the requestor pays, false if not. For more information, see Amazon's documentation on requester-pays buckets. /bucket/acl/owner Name Description displayName Name of the account that owns this bucket according to the S3 Acccess Control list (ACL). JSON format. For more about ACLs, see Amazon's ACL documentation. /bucket/crossOriginConfiguration Name Description rules Cross origin resource sharing (CORS) rules defining what domains may share the data in the bucket. JSON format. For more about CORS, see Amazon's CORS documentation. /bucket/lifecycleConfiguration Name Description rules Lifecycle configuration rules for data storage management. JSON format. For more about life-cycle configuration, see Amazon's lifecycle configuration documentation. /bucket/loggingConfiguration Name Description rules Access logging configuration in JSON format. Access log records provide information about each access request, including the requester, bucket name, request time, and error code, if any. For more about logging configuration, see Amazon's server access logging documentation. /bucket/notificationConfiguration/configurations Name Description events The bucket event for which to send notifications, for a certain notification configuration. *Arn Resource ARN that Amazon S3 will use when it detects events of the specified type (this can be an SNS topic, an SQS queue, or a Lambda function). /bucket/policy Name Description policyText Bucket policy as well as user policy are two access policy options that you can use to grant permission to your Amazon S3 resources. JSON format. For more about bucket policy, see Amazon's bucket policy documentation. /bucket/replicationConfiguration Name Description rules Replication configuration of the bucket in JSON format. /bucket/taggingConfiguration Name Description tagSets Tags can be used to organize your AWS billing to reflect your own cost structure. JSON format. For more about tags, see Amazon's tag documentation. /bucket/versioningConfiguration Name Description status This indicates if versioning of the data in the S3 bucket is \"Enabled\" or \"Suspended\" For more about versioning, see Amazon's versioning documentation. /bucket/websiteConfiguration Name Description indexDocumentSuffix When you configure your bucket as a website, you should provide the name of the index document. indexDocumentSuffix is the suffix appended to a request for a directory on the website endpoint. (For example, if the suffix is index.html and you make a request to samplebucket/images/, the data returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character. For more on configuring a bucket as a static website, see Amazon's example of setting up a static website. routingRules RedirectRule is a property of the Amazon S3 website configuration routing rules property that describes how requests are redirected. You can specify a different error code to return in the event an error occurs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.62993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> S3 monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> S3 data to New Relic. This document explains how to activate the integration and describes the data reported. Features <em>Amazon</em> Simple Storage Service (<em>Amazon</em> S3), provides developers and IT teams with secure"
      },
      "id": "617daaef64441f29cafbc942"
    }
  ],
  "/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02173,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.554214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.67691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-10T06:22:37Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.366425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-10T06:21:53Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.663284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.67691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-10T06:22:37Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.366425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-10T06:22:38Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.678,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.67691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-10T06:21:53Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-10T06:22:38Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.67799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.67691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-10T06:22:37Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.36642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-10T06:21:53Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-10T06:22:37Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.36642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-10T06:21:53Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by CloudWatch metric streams and all API polling integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "8dce4040d05d25ec88b4d2f3f079cac50a39e5e3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-12-10T06:22:38Z",
      "updated_at": "2021-10-24T00:44:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by CloudWatch metric streams and all API polling integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.67799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "617dc3ee64441f5514fbdcaf"
    }
  ],
  "/docs/infrastructure/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "7cf89c2eb75c934cc6fb30bcb7f5fb1f397326a6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-24T00:43:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.6769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "617dc3ed64441f8880fbe1c6"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "1c6a51e7ba3914f93661d78557cb79d1d51aa8cf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-12-10T06:22:37Z",
      "updated_at": "2021-10-24T00:44:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.36642,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "617db39f196a67ae1af7c161"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "e2162c88630edd9d48276564b8ef0fb61981c7d2",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-12-10T06:21:53Z",
      "updated_at": "2021-10-24T00:45:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.66328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "617db3a028ccbcf5b880086d"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Rate limit alerts from Amazon",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit alerts from Amazon",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "a16c440cd1a39275af8a8fd1e16d0aca1fcd6b57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon/",
      "published_at": "2021-12-10T06:21:51Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are experiencing a massive increase of AWS usage in New Relic dashboards for your AWS account due to a high number of Amazon EC2 and/or ELB API calls. This manifests as a rate-limiting alert from Amazon. This may also result in an increase on your CloudWatch bill. Solution If you are experiencing throttling issues, try these solutions as applicable: Consider adjusting configuration settings for your Infrastructure agent. Disconnect the AWS integration that is causing throttling issues. Contact support.newrelic.com to disable calls being made on behalf of each AWS integration. Cause Infrastructure Amazon integrations query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure's ELB integration performs calls to the Amazon ELB API. Infrastructure's EC2, VPC, and EBS integrations perform calls to the Amazon EC2 API. If you have a large amount of AWS integration entities, the polling interval can throttle the data being communicated between Amazon and New Relic. For example, if you have 200 Elastic Load Balancers, New Relic makes API calls to pull data on every one of those load balancers every five minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.55402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit alerts from <em>Amazon</em>",
        "sections": "Rate limit alerts from <em>Amazon</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". Cause Infrastructure <em>Amazon</em> <em>integrations</em> query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure&#x27;s ELB integration performs calls"
      },
      "id": "617db3a064441f667bfbe7bb"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.55421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    },
    {
      "sections": [
        "Rate limit alerts from Amazon",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit alerts from Amazon",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "a16c440cd1a39275af8a8fd1e16d0aca1fcd6b57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon/",
      "published_at": "2021-12-10T06:21:51Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are experiencing a massive increase of AWS usage in New Relic dashboards for your AWS account due to a high number of Amazon EC2 and/or ELB API calls. This manifests as a rate-limiting alert from Amazon. This may also result in an increase on your CloudWatch bill. Solution If you are experiencing throttling issues, try these solutions as applicable: Consider adjusting configuration settings for your Infrastructure agent. Disconnect the AWS integration that is causing throttling issues. Contact support.newrelic.com to disable calls being made on behalf of each AWS integration. Cause Infrastructure Amazon integrations query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure's ELB integration performs calls to the Amazon ELB API. Infrastructure's EC2, VPC, and EBS integrations perform calls to the Amazon EC2 API. If you have a large amount of AWS integration entities, the polling interval can throttle the data being communicated between Amazon and New Relic. For example, if you have 200 Elastic Load Balancers, New Relic makes API calls to pull data on every one of those load balancers every five minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.55402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit alerts from <em>Amazon</em>",
        "sections": "Rate limit alerts from <em>Amazon</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". Cause Infrastructure <em>Amazon</em> <em>integrations</em> query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure&#x27;s ELB integration performs calls"
      },
      "id": "617db3a064441f667bfbe7bb"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    },
    {
      "sections": [
        "Rate limit alerts from Amazon",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit alerts from Amazon",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "a16c440cd1a39275af8a8fd1e16d0aca1fcd6b57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon/",
      "published_at": "2021-12-10T06:21:51Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are experiencing a massive increase of AWS usage in New Relic dashboards for your AWS account due to a high number of Amazon EC2 and/or ELB API calls. This manifests as a rate-limiting alert from Amazon. This may also result in an increase on your CloudWatch bill. Solution If you are experiencing throttling issues, try these solutions as applicable: Consider adjusting configuration settings for your Infrastructure agent. Disconnect the AWS integration that is causing throttling issues. Contact support.newrelic.com to disable calls being made on behalf of each AWS integration. Cause Infrastructure Amazon integrations query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure's ELB integration performs calls to the Amazon ELB API. Infrastructure's EC2, VPC, and EBS integrations perform calls to the Amazon EC2 API. If you have a large amount of AWS integration entities, the polling interval can throttle the data being communicated between Amazon and New Relic. For example, if you have 200 Elastic Load Balancers, New Relic makes API calls to pull data on every one of those load balancers every five minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.554016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit alerts from <em>Amazon</em>",
        "sections": "Rate limit alerts from <em>Amazon</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". Cause Infrastructure <em>Amazon</em> <em>integrations</em> query your AWS services according to polling intervals, which vary depending on the integration. Polling intervals ensure that your AWS data is up to date, and every AWS entity is polled during each interval. Infrastructure&#x27;s ELB integration performs calls"
      },
      "id": "617db3a064441f667bfbe7bb"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.02171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.021706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-10T05:19:56Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.63803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " to 24 hours. Inventory: the Inventory page is not supported with AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> (inventory telemetry is not included in the <em>stream</em>). <em>Integrations</em> not fully replaced by <em>metric</em> <em>streams</em> The AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration only collects <em>CloudWatch</em> metrics, resource metadata"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "Amazon SageMaker MLOps integration",
        "Stream AWS CloudWatch Metrics to New Relic",
        "Important",
        "Manual option",
        "Automated option",
        "Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch",
        "Advanced options",
        "Explore your MLOps entities and dashboards"
      ],
      "title": "Amazon SageMaker MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOPs",
        "Amazon SageMaker"
      ],
      "external_id": "51bf2cfead556f345a559403dce5efba6b574116",
      "image": "https://docs.newrelic.com/static/cc36912643153bc52f79def15b0fce81/a76f4/aws-sm-flow.png",
      "url": "https://docs.newrelic.com/docs/mlops/integrations/aws-sagemaker-mlops-integration/",
      "published_at": "2021-12-10T10:58:28Z",
      "updated_at": "2021-12-10T10:58:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By integrating Amazon SageMaker's integration with New Relic, you'll be able to instrument, analyze, troubleshoot, and optimize your machine-learning performance across your entire system. Rigorously observe your capabilities to react quickly to changes in the model's input or output and the relationship between the two. Take the next steps to monitor your Amazon SagaMaker metrics and objects (that are sent to AWS CloudWatch) and view them as entities and dashboards in New Relic. Stream AWS CloudWatch Metrics to New Relic Start benefiting from New Relic MLOps entities in a single simple step (and just a few minutes!): Important Each metric sent to CloudWatch is automatically sent to New Relic's metric table in NRDB, according to the namespace filter. You can always query them using NRQL: FROM Metric SELECT * WHERE aws.Namespace='/aws/sagemaker/Endpoints' LIMIT MAX SINCE 1 WEEK AGO Copy Manual option Follow our docs to set up CloudWatch Metric Streams. Automated option You may automate the set up with the Terraform code: module \"example_usage\" { source = \"modules/nr-cloudwatch-metric-stream\" name_suffix = \"suffix\" # optional aws_account_id = \"your-aws-account-id\" newrelic_collector_endpoint = \"newrelic-endpoint-url\" newrelic_trusted_account_id = \"12345678\" newrelic_license_key = \"your-newrelic-license-key\" } Copy When calling the module, please write the correct newrelic_collector_endpoint: HTTP endpoint URL - US datacenter HTTP endpoint URL - EU datacenter When you set the metric stream you can choose to stream the metric from all the namespaces, or you can specify namespaces. Important You can view each entity's metrics in a dashboard that's created automatically when the metrics arrive at the New Relic. Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch SageMaker automatically monitors your endpoints’ performance, and sends statistic metrics to CloudWatch. For more information, see Endpoint CloudWatch Metrics. To obtain more benefits from the Amazon SageMaker MLOps integration, use the Amazon SageMaker Model Monitor tools. You'll have to define scheduled monitoring jobs to monitor the quality of your machine learning models in production and send metrics to CloudWatch. The Amazon SageMaker Model Monitor provides the following types of monitoring: Monitor Data Quality: Monitor drift in data quality. Example notebook: Amazon SageMaker Model Monitor CloudWatch metrics for namespace aws/sagemaker/Endpoints/data-metrics Monitor Model Quality: Monitor drift in model quality metrics, such as accuracy. Example notebook: Amazon SageMaker Model Quality Monitor CloudWatch metrics for namespace aws/sagemaker/Endpoints/model-metrics Monitor Bias Drift for Models in Production: Monitor bias in you model's predictions. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/bias-metrics Monitor Feature Attribution Drift for Models in Production: Monitor drift in feature attribution. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/explainability-metrics Advanced options You can aso publish metric data points to Amazon CloudWatch and define the namespaces and one of the above using the put_metric_data function. If you use your own algorithm for hyperparameter tuning, make sure that it sends at least one metric by writing evaluation data to stderr or stdout. Read more on how to define metrics in automatic model tuning. See also the example notebook Develop, Train, Optimize and Deploy Scikit-Learn Random Forest. Explore your MLOps entities and dashboards We generate aws-entities (under the MLOps entity domain) for the detailed namespaces. For these entities, you can get out-of-the-box dashboards and views. You can also create your own dashboard to view metrics that are not being displayed as part of the entities' views. New Relic entity Namespace Machine learning endpoint /aws/sagemaker/Endpoints, AWS/SageMaker Machine learning model data aws/sagemaker/Endpoints/data-metrics Machine learning model aws/sagemaker/Endpoints/model-metrics, aws/sagemaker/Endpoints/explainability-metrics Go to one.newrelic.com and select the Explorer to view: Your machine-learning entities The dashboard for the metrics of the endpoint from one of the Amazon SageMaker entities The dashboard for the model data entity",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.5791,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> SageMaker MLOps <em>integration</em>",
        "sections": "<em>Stream</em> AWS <em>CloudWatch</em> <em>Metrics</em> to New Relic",
        "tags": "<em>Integrations</em>",
        "body": " Manual option Follow our docs to set up <em>CloudWatch</em> <em>Metric</em> <em>Streams</em>. Automated option You may automate the set up with the Terraform code: module &quot;example_usage&quot; { source = &quot;modules&#x2F;nr-<em>cloudwatch</em>-<em>metric</em>-<em>stream</em>&quot; name_suffix = &quot;suffix&quot; # optional aws_account_id = &quot;your-aws-account-id"
      },
      "id": "61b332d428ccbc3c8e8c55b8"
    },
    {
      "sections": [
        "AWS SageMaker MLOps integration",
        "Stream AWS CloudWatch Metrics to New Relic",
        "Important",
        "Manual option",
        "Automated option",
        "Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch",
        "Advanced options",
        "Explore your MLOps entities and dashboards"
      ],
      "title": "AWS SageMaker MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOPs",
        "AWS SageMaker"
      ],
      "external_id": "0478de05ebc6487a0d4d4d884d80195f98dd4559",
      "image": "https://docs.newrelic.com/static/efa7795547dec4ffd205989d13ad4911/ef9e5/aws-sm-flow.png",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/mlops/integrations/aws-sagemaker-mlops-integration/",
      "published_at": "2021-12-10T14:55:19Z",
      "updated_at": "2021-12-09T01:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By integrating AWS SageMaker's integration with New Relic, you'll be able to instrument, analyze, troubleshoot, and optimize your machine-learning performance across your entire system. Rigorously observe your capabilities to react quickly to changes in the model's input or output and the relationship between the two. Take the next steps to monitor your AWS SagaMaker metrics and objects (that are sent to AWS CloudWatch) and view them as entities and dashboards in New Relic. Stream AWS CloudWatch Metrics to New Relic Start benefiting from New Relic MLOps entities in a single simple step (and just a few minutes!): Important Each metric sent to CloudWatch is automatically sent to New Relic's metric table in NRDB, according to the namespace filter. You can always query them using NRQL: FROM Metric SELECT * WHERE aws.Namespace='/aws/sagemaker/Endpoints' LIMIT MAX SINCE 1 WEEK AGO Copy Manual option Follow our docs to set up CloudWatch Metric Streams. Automated option You may automate the set up with the Terraform code: module \"example_usage\" { source = \"modules/nr-cloudwatch-metric-stream\" name_suffix = \"suffix\" # optional aws_account_id = \"your-aws-account-id\" newrelic_collector_endpoint = \"newrelic-endpoint-url\" newrelic_trusted_account_id = \"12345678\" newrelic_license_key = \"your-newrelic-license-key\" } Copy When calling the module, please write the correct newrelic_collector_endpoint: HTTP endpoint URL - US datacenter HTTP endpoint URL - EU datacenter When you set the metric stream you can choose to stream the metric from all the namespaces, or you can specify namespaces. Important You can view each entity's metrics in a dashboard that's created automatically when the metrics arrive at the New Relic. Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch SageMaker automatically monitors your endpoints’ performance, and sends statistic metrics to CloudWatch. For more information, see Endpoint CloudWatch Metrics. To obtain more benefits from the AWS SageMaker MLOps integration, use the Amazon SageMaker Model Monitor tools. You'll have to define scheduled monitoring jobs to monitor the quality of your machine learning models in production and send metrics to CloudWatch. The Amazon SageMaker Model Monitor provides the following types of monitoring: Monitor Data Quality: Monitor drift in data quality. Example notebook: Amazon SageMaker Model Monitor CloudWatch metrics for namespace aws/sagemaker/Endpoints/data-metrics Monitor Model Quality: Monitor drift in model quality metrics, such as accuracy. Example notebook: Amazon SageMaker Model Quality Monitor CloudWatch metrics for namespace aws/sagemaker/Endpoints/model-metrics Monitor Bias Drift for Models in Production: Monitor bias in you model's predictions. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/bias-metrics Monitor Feature Attribution Drift for Models in Production: Monitor drift in feature attribution. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/explainability-metrics Advanced options You can aso publish metric data points to Amazon CloudWatch and define the namespaces and one of the above using the put_metric_data function. If you use your own algorithm for hyperparameter tuning, make sure that it sends at least one metric by writing evaluation data to stderr or stdout. Read more on how to define metrics in automatic model tuning. See also the example notebook Develop, Train, Optimize and Deploy Scikit-Learn Random Forest. Explore your MLOps entities and dashboards We generate aws-entities (under the MLOps entity domain) for the detailed namespaces. For these entities, you can get out-of-the-box dashboards and views. You can also create your own dashboard to view metrics that are not being displayed as part of the entities' views. New Relic entity Namespace Machine learning endpoint /aws/sagemaker/Endpoints, AWS/SageMaker Machine learning model data aws/sagemaker/Endpoints/data-metrics Machine learning model aws/sagemaker/Endpoints/model-metrics, aws/sagemaker/Endpoints/explainability-metrics Go to one.newrelic.com and select the Explorer to view: Your machine-learning entities The dashboard for the metrics of the endpoint from one of the AWS SageMaker entities The dashboard for the model data entity",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.53583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS SageMaker MLOps <em>integration</em>",
        "sections": "<em>Stream</em> AWS <em>CloudWatch</em> <em>Metrics</em> to New Relic",
        "tags": "<em>Integrations</em>",
        "body": " option Follow our docs to set up <em>CloudWatch</em> <em>Metric</em> <em>Streams</em>. Automated option You may automate the set up with the Terraform code: module &quot;example_usage&quot; { source = &quot;modules&#x2F;nr-<em>cloudwatch</em>-<em>metric</em>-<em>stream</em>&quot; name_suffix = &quot;suffix&quot; # optional aws_account_id = &quot;your-aws-account-id"
      },
      "id": "61b15c63e7b9d2bf82acd308"
    }
  ],
  "/docs/infrastructure/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "e8e4b2296398924dc6358d6d24337b979bf120b1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-12-10T05:23:04Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.65097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "617dc48228ccbcd1398004e6"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "f4618f822e6076e80c856b99f67d61928f89c498",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-12-10T06:23:21Z",
      "updated_at": "2021-10-23T10:52:09Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.021706,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "617dc45064441fe773fbe7f5"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "ae28dda762432952606027f7e22c3f27d64b3fea",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-12-10T05:22:40Z",
      "updated_at": "2021-10-23T16:45:32Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.5542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "617dc41e28ccbc78c57ff999"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.20917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.43391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Retrieve logs via SSH (EC2 launch type only) To <em>get</em> logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your <em>container</em> instances. Find"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.6586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "3beb992f60db19bb5f3c8a3ebef2b5904f958be8",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-12-10T05:51:13Z",
      "updated_at": "2021-10-24T00:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.23795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "617db40c196a6792daf7c8b2"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.43391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.7821,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "3beb992f60db19bb5f3c8a3ebef2b5904f958be8",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-12-10T05:51:13Z",
      "updated_at": "2021-10-24T00:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.23795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "617db40c196a6792daf7c8b2"
    },
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.43391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "sections": "ECS <em>integration</em> troubleshooting: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the <em>container</em> ID of the New Relic <em>integration</em> <em>container</em>, by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Save the logs from the <em>container</em> with the command docker logs NRI_ECS_<em>CONTAINER</em>_ID &gt; logs.txt. Leave the command running for about three minutes to generate sufficient"
      },
      "id": "617db44c28ccbc965d80120d"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9cc7726bfac01b6d287c335f5a5d6705b168e7a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-12-10T02:33:34Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but you’re still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.76636,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "617db44ce7b9d226b2c047e9"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.14375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.03864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "9a1b2b654d6eab700a65de4eb0a4b233ba6098e0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-10-24T01:52:11Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.25374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "617db44c28ccbc965d80120d"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.14374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS <em>integration</em> task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a <em>service</em> that runs the task on every EC2 <em>container</em> instance, deploy"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.0386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "6373cb619a787c0a22f4d91c954cd2a8d6ad3b41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2021-12-10T06:18:12Z",
      "updated_at": "2021-11-13T16:40:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName, awsRegion, ecsLaunchType and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName, ecsLaunchType and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.52046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "617db48de7b9d24953c05054"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.20915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.10397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "2adc4dd0bff89ea0d3e05fa756ba4d30adf9bf53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-12-10T06:18:12Z",
      "updated_at": "2021-10-24T01:53:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsedCoresPercent Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.95654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "617db48e64441f3722fbe764"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "EXTERNAL launch type",
        "Fargate launch type",
        "Tip",
        "Install with automatic script",
        "Manual install",
        "EC2 and EXTERNAL launch type",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "9c6d8581622d9eaed8fd049aff6f5897fea6697e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-12-10T06:16:34Z",
      "updated_at": "2021-11-13T21:50:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. Install overview Before you install our ECS integration, we recommend reviewing the requirements. During the install process: For EC2 and EXTERNAL launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. The Amazon ECS Fargate documentation defines a sidecar as a way to move part of a service's core responsibility into a containerized module that is deployed alongside the core application. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for EC2, EXTERNAL and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure you’re deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 and EXTERNAL launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every EC2 container instance, deploy this stack. Select EC2 Launch type. Then a Service named newrelic-infra will be created in the cluster. EXTERNAL launch type Additional steps for EXTERNAL launch type: To create a service that runs the task on every external container instance, deploy this stack. Select EXTERNAL Launch type. Then a Service named newrelic-infra-external will be created in the cluster. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy EXTERNAL launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY -e Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 and EXTERNAL launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: For EC2 launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EC2 Copy For EXTERNAL launch type: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra-external\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON --launch-type EXTERNAL Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Tip For Graviton, replace \"cpuArchitecture\": \"X86_64\" with \"cpuArchitecture\": \"ARM64\". Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy Registers the newrelic-infra ECS task definition for EC2 and EXTERNAL launch types. For EC2 launch type, this is also done: Creates the service newrelic-infra for the registered task using a daemon scheduling strategy and EC2 launch type. For EXTERNAL launch type, this is also done: Creates the service newrelic-infra-external for the registered task using a daemon scheduling strategy and EXTERNAL launch type.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.20914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " the placeholder busybox <em>container</em>. Next steps: Wait a few minutes and then look for your <em>data</em> in the UI. Recommended: Install our ECS cloud <em>integration</em>, which gets you other ECS <em>data</em>, including information about clusters and services. See recommended alert conditions. <em>Understand</em> the AWS resources"
      },
      "id": "617db40c196a6779f9f7c9f0"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "af54ea183f4f31c2270c5867e53424feb53dbead",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-12-10T06:17:23Z",
      "updated_at": "2021-11-13T19:34:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 and EXTERNAL launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 and EXTERNAL launch type, and not Fargate: Delete the services: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy aws ecs delete-service --service \"newrelic-infra-external\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.10397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation <em>Use</em> automatic installer script"
      },
      "id": "617db40ce7b9d2a21fc044c0"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-10T05:54:54Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.82028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-10T06:19:48Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.81784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-10T05:52:02Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.89467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-10T05:54:54Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.82028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-10T06:19:48Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.81784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-10T05:52:02Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.89467,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-10T05:54:54Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.82027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-10T06:19:48Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.81783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-10T05:52:02Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.89465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-10T05:54:54Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.82027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-10T06:19:48Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.81783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-10T05:52:02Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.89465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ],
  "/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Memorystore for Memcached",
        "BETA FEATURE",
        "Activate the integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Memcache MemcacheNode data"
      ],
      "title": "Google Memorystore for Memcached",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "365ded13f513d186dd6551d4a91d5e9ee5f276c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-memorystore-memcached/",
      "published_at": "2021-12-10T05:54:54Z",
      "updated_at": "2021-11-13T18:38:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. We offer a cloud integration for reporting your GCP Memcache data to our platform. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your GCP service. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Memcache integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select the integration. Data is attached to the following event types: Entity Event Type Provider MemcacheNode GcpMemcacheMemcacheNodeSample GcpMemcacheMemcacheNode For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Memcache data for MemcacheNode. Memcache MemcacheNode data Metric Unit Description node.ActiveConnections Count Connections active in this Memcached node. node.CacheMemory Bytes Bytes alloted for Memcached in this node, grouped by whether that memory is used or not. node.cpu.UsageTime Seconds CPU usage time by Memcached process grouped by user and kernel mode. node.cpu.Utilization Percent CPU usage percent by Memcached node. node.Eviction Count Count of items evicted by this Memcached node. node.HitRatio Percent Hit ratio, expressed as a percentage of the total cache requests excluding set operations. Values are numbers between 0.0 and 1.0, charts display the values as a percentage between 0% and 100%. node.Items Count Items stored in this Memcached node. node.Operation Count Count of Memcached operations grouped by command and response_type (for example: hit, miss). node.ReceivedBytes Bytes Bytes received by this Memcached node. node.SentBytes Bytes Bytes sent by this Memcached node. node.Uptime Seconds Time in seconds the node has been running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.82025,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Memorystore for Memcached",
        "sections": "<em>Google</em> Memorystore for Memcached",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "BETA FEATURE This feature is currently in beta. We offer a <em>cloud</em> integration for reporting your <em>GCP</em> Memcache data to our <em>platform</em>. Here we explain how to activate the integration and what data it collects. Activate the integration To enable the integration follow standard procedures to connect your"
      },
      "id": "617dbaa9e7b9d2d3dac03a25"
    },
    {
      "sections": [
        "Google Cloud Run monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Run Revision data"
      ],
      "title": "Google Cloud Run monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "75e24dd070c19c18f2ea0cd3c488a2270a7b0acf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-run-monitoring-integration/",
      "published_at": "2021-12-10T06:19:48Z",
      "updated_at": "2021-11-13T18:35:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP Run integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Revision GcpRunRevisionSample GcpRunRevision For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP Run data for Revision. Run Revision data Metric Unit Description container.BillableInstanceTime Seconds Billable time aggregated from all container instances of the revision. For a given container instance, billable time occurs when the container instance is starting or at least one request is being processed. Billable time is rounded up to the nearest 100 milliseconds. Examples: If a revision with 2 container instances has been continuously serving traffic in the last minute, the value is 2s/s with the default \"rate\" aligner. If a single request lasting 30ms was received by a revision in the past minute, it is rounded up to 100ms and averaged to 1.7ms/s over the minute with the default \"rate\" aligner. container.cpu.AllocationTime Seconds Container CPU allocation of the revision in seconds. container.memory.AllocationTime Other Container memory allocation of the revision in Gigabytes-seconds. Request Count Number of requests reaching the revision. Excludes requests that are not reaching your container instances (for example, unauthorized requests or when maximum number of instances is reached). RequestLatencies Milliseconds Distribution of request latency in milliseconds reaching the revision.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.81781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Run monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> Run data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "617dc53d64441f1e3ffbe2f0"
    },
    {
      "sections": [
        "Google Cloud Spanner monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpSpannerInstanceSample",
        "GcpSpannerDatabaseSample",
        "Inventory data",
        "gcp/spanner/instance",
        "gcp/spanner/database"
      ],
      "title": "Google Cloud Spanner monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "0291e2d3dc6dd80b186f5dcfe002971769bd4915",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-spanner-monitoring-integration/",
      "published_at": "2021-12-10T05:52:02Z",
      "updated_at": "2021-10-23T17:51:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations with the Google Cloud Platform (GCP) include an integration to report Google Cloud Spanner data to New Relic. This document explains how to activate the GCP Cloud Spanner integration and describes the data that can be reported. Features Google Cloud Spanner service is a globally-distributed relational database service built for the cloud. Using the Google Spanner Console, developers can create a Cloud Spanner instance, add schemas, write and modify data, and run queries. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling frequency for Google Cloud Spanner is five minutes. The resolution is 1 data point every minute. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data To view metric data for your GCP Spanner integration in New Relic, create NRQL queries for GcpSpannerInstanceSample and GcpSpannerDatabaseSample events and their related attributes. GcpSpannerInstanceSample Query GcpSpannerInstanceSample events in New Relic to view data for the following attributes: Attribute Description instance.cpu.Utilization Utilization of the provisioned CPU, between 0 and 1. instance.cpu.utilization_by_priority Utilization of the provisioned CPU by priority, between 0 and 1. instance.cpu.smoothed_utilization 24-hour smoothed utilization of the provisioned CPU , between 0 and 1. instance.nodes Total number of nodes. instance.sessions Number of sessions in use. instance.storage.UsedBytes Storage used in bytes. GcpSpannerDatabaseSample Query GcpSpannerDatabaseSample events in New Relic to view data for the following attributes: Attribute Description api.ReceivedBytes Uncompressed request bytes received by Cloud Spanner. api.Requests Rate of Cloud Spanner API requests. api.RequestLatencies Distribution of server request latencies for a database. This includes latency of request processing in Cloud Spanner backends and API layer. It does not include network or reverse-proxy overhead between clients and servers. api.SentBytes Uncompressed response bytes sent by Cloud Spanner. Inventory data To view inventory data for GCP Spanner services, go to one.newrelic.com > Infrastructure > Inventory and search for or select the following: gcp/spanner/instance Name Description projectId The project where the instance is. zone The region where the instance is. name The Id of the instance (not the name). state* The state of the instance. nodeCount* The number of nodes the instance has. instanceName* The name of the instance. labels* The labels set for the instance. * Only available if the GCP project is linked to New Relic through a service account. gcp/spanner/database Name Description projectId The project where the database is. zone The region where the database is. name The Id of the database (not the name). instanceId The Id of the instance where the database is. dl* The SQL definition of the instance. state* The state of the database. * Only available if the GCP project is linked to New Relic through a service account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.89465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Spanner monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) include an integration to report <em>Google</em> <em>Cloud</em> Spanner data to New Relic. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Spanner integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Spanner service"
      },
      "id": "617dc57828ccbc2e74801133"
    }
  ]
}