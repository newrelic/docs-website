{
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior": [
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 364.2171,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> overhead",
        "sections": "<em>Infrastructure</em> <em>agent</em> overhead",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> is a lightweight piece of software, designed to minimize its impact on the performance of <em>your</em> hosts. However, the exact load varies depending on <em>your</em> host&#x27;s workload, particularly on the number of processes running on the host. This is because the <em>agent</em> collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. macOS: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.7166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. macOS: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-10-18T18:55:37Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.81345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Start, stop, and restart the infrastructure agent",
        "Linux: Start, stop, restart, or check agent status",
        "Windows: Start, stop, restart, or check agent status",
        "Important",
        "Command prompt (cmd.exe)",
        "PowerShell",
        "macOS: Start, stop, restart, or check agent status",
        "Customize agent logs",
        "Determine your init system",
        "Configuration management tools"
      ],
      "title": "Start, stop, and restart the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "81bb8174fac415ee0ec94c51e123c32eba700d6e",
      "image": "https://docs.newrelic.com/static/19e41f9fd7395eb6f1c816aa87182bb9/103b3/otherlinux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-08-20T17:29:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent starts automatically after you run the installation script. However, there are situations where you may need to manually restart the agent (for example, after changing your agent configuration). Linux: Start, stop, restart, or check agent status For Linux, ensure you use the correct command for your init system. Select start, stop, restart, or status as appropriate: SystemD (Amazon Linux 2, SLES 12, CentOS 7 or higher, Debian 8 or higher, RHEL 7 or higher, Ubuntu 15.04 or higher): sudo systemctl <start|stop|restart|status> newrelic-infra Copy System V (Debian 7, SLES 11.4, RHEL 5): sudo /etc/init.d/newrelic-infra <start|stop|restart|status> Copy Upstart (Amazon Linux, RHEL 6, Ubuntu 14.04 or lower): sudo initctl <start|stop|restart|status> newrelic-infra Copy Windows: Start, stop, restart, or check agent status Important To start, stop, or restart the agent, you must run cmd.exe or PowerShell as Administrator. For Windows Server, you can use the Windows command prompt or PowerShell. Command prompt (cmd.exe) Start or stop the Windows agent: net <start|stop> newrelic-infra Copy Restart the Windows agent: net stop newrelic-infra ; net start newrelic-infra Copy Check the status of the Windows agent: sc query \"newrelic-infra\" | find \"STATE\" Copy PowerShell Start or stop the Windows agent: Stop-Service -Name \"newrelic-infra\" Start-Service -Name \"newrelic-infra\" Copy You can also use net start|stop newrelic-infra Restart the Windows agent: Restart-Service newrelic-infra Copy Check status of Windows agent: (Get-Service newrelic-infra).Status Copy macOS: Start, stop, restart, or check agent status Stop or start the agent: brew services stop newrelic-infra-agent brew services start newrelic-infra-agent Copy Restart the agent: brew services restart newrelic-infra-agent Copy Check status of the agent: brew services list Copy Customize agent logs The infrastructure agent logs to a default location which depends on your platform. You can customize this location with the log_file setting. You can also generate verbose logs for troubleshooting. Determine your init system For Windows Server, the commands in this document use the Windows command prompt. For Linux, the infrastructure agent selects an init system appropriate for your distribution: Distribution SystemD System V Upstart Amazon Linux Amazon Linux 2 CentOS 7 CentOS 8 Debian 7 (\"Wheezy\") Debian 8 (\"Jessie\") Debian 9 (\"Stretch\") RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To manage the infrastructure agent with your config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.71658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "sections": "Start, stop, and restart the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "&quot;) Debian 8 (&quot;Jessie&quot;) Debian 9 (&quot;Stretch&quot;) RHEL 5 RHEL 6 RHEL 7 RHEL 8 Ubuntu, 14.04 or lower Ubuntu, 16.04 or higher SLES 12 SLES 11 Configuration management tools To <em>manage</em> the <em>infrastructure</em> <em>agent</em> with <em>your</em> config management tool, see: Ansible configuration Chef configuration AWS Elastic Beanstalk configuration Puppet configuration"
      },
      "id": "603ec355e7b9d294092a0818"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 364.21704,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> overhead",
        "sections": "<em>Infrastructure</em> <em>agent</em> overhead",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> is a lightweight piece of software, designed to minimize its impact on the performance of <em>your</em> hosts. However, the exact load varies depending on <em>your</em> host&#x27;s workload, particularly on the number of processes running on the host. This is because the <em>agent</em> collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. macOS: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-10-18T18:55:37Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.81345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-18T18:56:45Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 364.21695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> overhead",
        "sections": "<em>Infrastructure</em> <em>agent</em> overhead",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> is a lightweight piece of software, designed to minimize its impact on the performance of <em>your</em> hosts. However, the exact load varies depending on <em>your</em> host&#x27;s workload, particularly on the number of processes running on the host. This is because the <em>agent</em> collects detailed"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " and requires Administrator privileges to run. macOS: The <em>agent</em> can be installed from any user account. Libraries For <em>agent</em> versions 1.1.19 or higher, you need the libcap library in order to <em>install</em> <em>Infrastructure</em>. It&#x27;s available in the official repositories of <em>your</em> distribution. Network access"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-10-18T18:55:37Z",
      "updated_at": "2021-08-20T21:39:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. macOS: Manually install agent versions through HomeBrew. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 275.81345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent": [
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update on macOS",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-10-18T18:58:27Z",
      "updated_at": "2021-08-20T17:30:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update on macOS To manually update the infrastructure agent on macOS, open the terminal and run the following commands: Stop the service (if already running): brew services stop newrelic-infra-agent Copy Uninstall the agent: brew update newrelic-infrastructure Copy Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.48465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-10-18T18:57:32Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you wont have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.8871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations": [
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall the macOS infrastructure agent",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-10-18T18:57:32Z",
      "updated_at": "2021-08-26T14:37:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the macOS infrastructure agent If you used the default install procedure for the infrastructure agent for macOS environments, to uninstall: Stop the infrastructure agent: brew services stop newrelic-infra-agent Copy From the terminal, run the uninstall command: brew uninstall newrelic-infra-agent Copy Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.59354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update on macOS",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-10-18T18:58:27Z",
      "updated_at": "2021-08-20T17:30:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update on macOS To manually update the infrastructure agent on macOS, open the terminal and run the following commands: Stop the service (if already running): brew services stop newrelic-infra-agent Copy Uninstall the agent: brew update newrelic-infrastructure Copy Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.48462,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent": [
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall the macOS infrastructure agent",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-10-18T18:57:32Z",
      "updated_at": "2021-08-26T14:37:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the macOS infrastructure agent If you used the default install procedure for the infrastructure agent for macOS environments, to uninstall: Stop the infrastructure agent: brew services stop newrelic-infra-agent Copy From the terminal, run the uninstall command: brew uninstall newrelic-infra-agent Copy Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.59354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-10-18T18:57:32Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you wont have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.8871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows": [
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 405.18167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>. You can place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>. You are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T04:33:58Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.49786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T13:07:05Z",
      "updated_at": "2021-10-13T02:51:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation. You can place files and folders wherever you want on your filesystem. This method gives you full control of the installation. You are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. For more information, see our documentation about troubleshooting a running infrastructure agent. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, to configure the agent's behavior. This file is placed in the same folder with the agent. You can create a new config file based on the config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named integration-name-config.yml by default. This config file is placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. The agent also uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 405.18167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>. You can place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>. You are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Install for Windows Server and Windows 10 using our guided install",
        "Install using our step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "Install using zip files",
        "Caution",
        "What's next?",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-10-18T18:59:23Z",
      "updated_at": "2021-08-26T18:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure, and supports Windows Server and Windows 10. You can also install with Chef. Before installation, be sure to review the requirements. If you haven't already, create a New Relic account. It's free, forever. Install for Windows Server and Windows 10 using our guided install To install the infrastructure monitoring agent for Windows, you can use our guided install. If you're in the EU, try our euro guided install. Install using our step-by-step instructions If guided install doesn't work, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.56357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". You can also <em>install</em> with Chef. Before <em>installation</em>, be sure to review the requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our guided <em>install</em> To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use"
      },
      "id": "6044672464441f9bb6378ed9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-10-19T04:55:10Z",
      "updated_at": "2021-10-19T04:55:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. You also need a New Relic account. Sign up for free. No credit card required. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. On-host integrations are also supported (with the exception of the Oracle integration). Built-in log forwarding is not yet available. macOS (Beta): 64-bit x86 processor (M1 processor is not supported yet). Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux 2 All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.16 to 1.22 Red Hat Enterprise Linux (RHEL) Version 7 or higher Oracle Linux Version 7 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, 12.4, 12.5, 15, 15.1, 15.2, 15.3 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Interim releases 20.10, 21.04. Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 and their service packs. macOS macOS 10.14 (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. macOS: The agent can be installed from any user account. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 300.98096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " (Mohave), 10.15 (Catalina), 11 (Big Sur). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Install for Windows Server and Windows 10 using our guided install",
        "Install using our step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "Install using zip files",
        "Caution",
        "What's next?",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-10-18T18:59:23Z",
      "updated_at": "2021-08-26T18:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure, and supports Windows Server and Windows 10. You can also install with Chef. Before installation, be sure to review the requirements. If you haven't already, create a New Relic account. It's free, forever. Install for Windows Server and Windows 10 using our guided install To install the infrastructure monitoring agent for Windows, you can use our guided install. If you're in the EU, try our euro guided install. Install using our step-by-step instructions If guided install doesn't work, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 276.56354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". You can also <em>install</em> with Chef. Before <em>installation</em>, be sure to review the requirements. If you haven&#x27;t already, create a New Relic account. It&#x27;s free, forever. <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our guided <em>install</em> To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use"
      },
      "id": "6044672464441f9bb6378ed9"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-10-18T04:33:58Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.49786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring": [
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-19T03:42:04Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.55144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.37932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-18T19:00:14Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data": [
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-19T03:42:04Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.55142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-18T19:00:14Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-10-18T18:59:22Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics": [
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.3793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-10-18T19:00:14Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-10-18T18:59:22Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting": [
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-19T03:42:04Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.55142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.3793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-10-18T18:59:22Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.8637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts": [
    {
      "sections": [
        "Group infrastructure results by specific attributes",
        "Group charts by specific attributes",
        "Combine filter sets and grouping",
        "Increased CPU usage on a single host"
      ],
      "title": "Group infrastructure results by specific attributes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "8436b1d0391cd7caa2a79c4080528697ff7a012d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes/",
      "published_at": "2021-10-18T19:00:14Z",
      "updated_at": "2021-03-11T10:49:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our infrastructure monitoring tool, you can use the Group by feature to group chart results by specific attributes. For example, on the Hosts page, you might display the AWS regions with the highest CPU usage grouped by awsRegion. Group by is available near the top of some infrastructure monitoring UI pages. Group charts by specific attributes On some infrastructure pages you can use Group by to group page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to group by will depend on your system setup. These may include: Default infrastructure attributes Custom attributes APM-related attributes To group infrastructure results by a specific attribute: On pages that have this feature, select Group by (located beside the time picker). From the dropdown, select an attribute to group by. Combine filter sets and grouping Grouping applies to any filter sets you have selected. By combining filter sets with Group by, you can find detailed system information quickly. Increased CPU usage on a single host On the Filter sets sidebar, you see alert threshold violations as Critical icon or Warning icon on one of your filter sets. To view only the hosts related to the filter set on your Hosts page, click the filter set name. To determine which of the hosts is causing the problem, select Group by, then select the hostname attribute. Review the charts which now show the hosts, by name, with the highest CPU usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.81415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "sections": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " monitoring UI pages. <em>Group</em> charts by specific attributes On some <em>infrastructure</em> pages you can use <em>Group</em> by to <em>group</em> page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to <em>group</em> by will depend on <em>your</em> system setup. These may include: Default"
      },
      "id": "6043edcd64441fd920378ecf"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-19T03:42:04Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.45152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes": [
    {
      "sections": [
        "Filter sets: Organize your hosts",
        "Benefits of filter sets",
        "Create filter sets",
        "Edit filter sets",
        "Delete filter sets",
        "Combine filter sets with grouping",
        "Copy filters from filter set to alerts",
        "Important",
        "Filter set logic",
        "Inclusion and exclusion",
        "Recommended: Select values by matching a string",
        "Tip",
        "Select values individually",
        "And/Or"
      ],
      "title": "Filter sets: Organize your hosts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "ae70ce239865f3cb006e2ed47fc9bf3fc0598d81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts/",
      "published_at": "2021-10-18T19:01:11Z",
      "updated_at": "2021-03-11T08:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure monitoring, you can combine filters into a filter set to organize hosts based on criteria that matter the most to you. Read on to learn about the benefits, use, and logic of filter sets. Benefits of filter sets You can create filter sets using available attributes or tags. For example, you can organize your infrastructure into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share filter sets with other people in your account, and you can quickly identify infrastructure problems by checking the color-coded health status of each host in the filter set. Create filter sets The default infrastructure filter set is All hosts, and it serves as a template for you to create filter sets. To create a filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. If All hosts is not displayed in the left sidebar, open that filter set by selecting Saved filter sets > All hosts. In All hosts, click Filter hosts. In the list, click an item to see a list of values. Click Include or Exclude (see Filter set logic). Click values individually or enter text to match multiple values. Continue adding filters until you have the filter set you want. To name your filter, click the icon, type a name, and click Save. Edit filter sets To change an existing filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. In the sidebar, click an option to update your filter set, and then save. Delete filter sets You can delete any saved filter set except the default All hosts. Go to one.newrelic.com > Infrastructure > Settings > Filter sets. Click to delete the filter set. Combine filter sets with grouping On some pages you can use Group by to group chart results by specific attributes. For example, on the Hosts page, you can group by awsRegion to display the AWS regions with the highest CPU usage. Grouping applies to the selected filter sets. By combining filter sets with grouping, you can find detailed system information quickly. For an example of using these tools to troubleshoot a problem, see Combining filter sets and grouping. Copy filters from filter set to alerts When you create an alert condition, you can build filters individually, or you can copy all the filters from a filter set into a new alert condition. This is a quick shortcut to populate a new alert condition with some filters. Important When you copy filter set filters to a new alert condition, these filters are no longer tied to the filter set. If you make changes to the filter set, the alert filters are not affected. To copy filter set filters to a new alert condition: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. Mouse over any chart and click > Create alert. Enter an alert condition name. Make adjustments to filters as necessary. Complete the remaining alert fields (see Create alert conditions). Filter set logic When you create a filter set, you generate a list of attributes and/or tags that narrow the results. This section explains how filter sets apply various rules to the list. Inclusion and exclusion As part of building a filter set, you designate whether a filter should include or exclude entities that match certain values. The way the inclusion or exclusion works depends on how you select values: Recommended: Select values by matching a string You can generate a list of values by entering a string that you want values to match. This is useful for matching multiple values. Tip String matching efficiently generates a list of values, and this approach scales as you add new entities. Here is the logic filter sets use with string matching: Comparator Logic Include If you click Include and then enter a string that you want values to match, the filter uses the comparator LIKE, which means the results include any entities that are like the string. For example, you could filter by the term East-, and all entities that contain that term are returned. Exclude If you click Exclude and then enter a string that you want values to match, the filter uses the comparator NOT LIKE, which means the results exclude any entities that are like the string. For example, you could filter by the term West-, and all entities that do not contain that term are returned. Select values individually You can click through the list of attributes/tags to identify individual values. Tip This approach does not scale well if you add new entities. Here is the logic filter sets use with individual value selection: Comparator Logic Include If you click Include and then click specific values, the filter uses the comparator IN, which means the filter looks for entities that exactly match one or more values in your list of selections. Exclude If you click Exclude and then click specific values, the filter set uses the comparator NOT IN, which means the filter returns all entities that do not exactly match one or more values in your list of selections. And/Or Filter sets use the logical operators AND and OR behind the scenes to join the data. Here are the rules for AND and OR: When you click values from multiple attributes or tags, they are joined by AND. When you click values from within an attribute or tags, they are joined by OR. The filter results display hosts for which both of the following are true: Hosts containing any one of the selected infrastructure agent versions Hosts in any one of the selected AWS availability zones",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.8111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "sections": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " or tags. For example, you can organize <em>your</em> <em>infrastructure</em> into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share <em>filter</em> sets with other people in <em>your</em> account, and you can quickly identify <em>infrastructure</em> problems by checking"
      },
      "id": "6043ed8ee7b9d289955799cb"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "BETA FEATURE",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-10-19T03:42:04Z",
      "updated_at": "2021-09-14T20:50:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentSha",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.45152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "BETA FEATURE This feature is currently in beta. New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-10-18T06:55:45Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.66804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-18T18:09:11Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.17337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-10-18T19:02:14Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.37447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-10-18T19:03:03Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-18T18:09:11Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.17337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-10-18T19:02:14Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.37447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-10-18T19:03:03Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-18T18:09:11Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.17336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-10-18T19:03:03Z",
      "updated_at": "2021-07-27T14:15:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. The no_trigger_on field is optional. When set to [\"shutdown\"] this enables the Don't trigger alerts for hosts that perform a clean shutdown infrastructure condition option. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12, \"no_trigger_on\": [\"shutdown\"] } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. For new conditions, if a value is not provided, the following default values are used: All conditions: 24 hours When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-10-18T19:02:13Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts": [
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Caution",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-10-18T18:09:11Z",
      "updated_at": "2021-09-20T19:26:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. Caution If you have filtered your Host Not Reporting condition using tags or labels and then remove a critical tag or label from a targeted host, the system will open a Host Not Reporting violation, since it will characterize that host as having lost its connection. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Alternatively, you can add the hostStatus: shutdown tag to your host along with checking the option mentioned above. This will stop all Host Not Reporting violations from opening for that host, as long as that tag is on it, regardless of agent version or OS. Removing the tag will allow the system to open Host Not Reporting violations for that host again. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.17336,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Alerts for infrastructure: Add, edit, or view host alert information",
        "Create alert conditions for infrastructure",
        "Important",
        "Other infrastructure alert condition methods",
        "Use the Alerts UI",
        "Use the Infrastructure UI",
        "Use infrastructure settings for integrations",
        "Tip",
        "View host alert events",
        "Update or delete host alert information",
        "Use New Relic Alerts to monitor your entire infrastructure",
        "Add a description",
        "Add or edit a runbook URL",
        "Violation time limit for violations",
        "Alert conditions that generate too-long NRQL queries"
      ],
      "title": "Alerts for infrastructure: Add, edit, or view host alert information",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "00207a1020aa29ea6d5d5bbb8e806a50a5966f80",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information/",
      "published_at": "2021-10-18T19:02:14Z",
      "updated_at": "2021-08-02T12:47:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring, you can create alert conditions directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic Alerts. Instead, you can immediately select your filter set and tailor the alert condition directly from the chart you are viewing. This helps you proactively manage and monitor the alerting system for your environment. Any alert violations will be created per entity within the filter set. Create alert conditions for infrastructure Alert conditions apply to alert policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to use other types of notification channels, create a new policy from within the Alerts UI. Important The Infrastructure REST API has a limit of 3,700 alert conditions, including both active and disabled conditions. The API, whether used directly or via the UI, will reject all requests to add any additional alert conditions beyond the 3,700 alert condition limit. To add an infrastructure alert condition to an alerts policy: Go to one.newrelic.com > Infrastructure, then select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Type a meaningful condition name. Select the Alert type, or refer to the examples to decide which type to select. Create individual filters, or copy all the filters from a filter set to identify the hosts that you want the alert condition to use. Important For more information about the rules behind filters, see Filter set logic. Define the Critical (required) and Warning (optional, if available) thresholds for triggering the alert notification. Optional: To create the condition criteria proactively but not receive alert notifications at this time, turn off the Enabled checkbox option. Select an existing policy for the new condition. OR Select the option to create a new policy and identify the email for alert notifications. Optional: Add a runbook url. Optional: Set Violation time limit for violations (this defaults to 24 hours). Select Create. Important If New Relic hasn't received a cloud integration service's attribute in the past 60 minutes, we refer to this as a \"silent attribute,\" and it won't be available to use as an alert condition in the UI. In this situation, you can use the API to create alert conditions for silent attributes. Other infrastructure alert condition methods You can also use these other methods to create an infrastructure alert condition: Use the Alerts UI Go to one.newrelic.com > Alerts & AI > Alerts > Alert policies > New alert policy > Create new condition, then select Infrastructure as the product. Use the Infrastructure UI Go to one.newrelic.com > Infrastructure. Select any of these Infrastructure monitoring pages: Hosts, Processes, Network, or Storage. Mouse over the chart you want to alert on, select the ellipses icon, and then select Create alert. Use infrastructure settings for integrations Tip Use this method to create an alert condition for infrastructure integrations. Go to one.newrelic.com > Infrastructure > Settings > Alerts, and then click Create alert condition. Name and describe the alert condition. Click the Integrations alert type, and then select the integration data source you'd like to use. Use the Filter entities dropdown to limit your condition to specific attributes. Use the Define thresholds dropdowns to define your condition's thresholds, and then click Create. The configuration settings are optional. You can always update them later. View host alert events Anyone included in the policy's notification channels receive alert notifications directly. In addition, anyone with permissions for your New Relic account can view Infrastructure alert incidents and individual violations through the user interface. Go to one.newrelic.com > Infrastructure > Events. To change the hosts or time frame, use the search window, Filter set, or Time functions. From the Events list, select the alert violation. To view detailed information in Alerts about the selected violation, select the link. Update or delete host alert information To edit, disable (or re-enable), or delete host alert information: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Use the search window or Select all checkbox to locate one or more alert conditions. Select any of the available functions to edit, disable, enable, or delete the selected conditions. Use New Relic Alerts to monitor your entire infrastructure New Relic Alerts provides a single, coordinated alerting tool across all of your New Relic products. This allows you to manage alert policies and conditions that focus on the metrics for entities that you care about the most, such as Docker containers, JVMs, and more. Alert features Features in Infrastructure Alert conditions Create: Use the Infrastructure UI. View, change, disable (or re-enable), or delete: Use the Infrastructure Settings > Alerts UI. Information on alerts View summary information about events: Use the Infrastructure Events UI. View detailed information about alert incidents or individual violations: Use the Alerts UI or the notification channel integrated with the associated policy. Alert policies View, add, change, disable, or delete: For policies with a variety of notification channels: Use the Alerts UI. For policies only needing email notifications: Go to one.newrelic.com > Infrastructure > Settings > Alerts > Create a new policy, and add one or more email addresses as needed. Add host conditions to an existing policy: Use the Infrastructure UI. Notification channels To view, add, change, or delete available notification options: Go to one.newrelic.com > Infrastructure > Settings > Alerts. Optional: Search for the condition or policy name. From the list of conditions, select the policy link to view notification channel information in the Alerts UI. Add a description The use of the Description field is available for these alert condition types: NRQL conditions: add a description using the NerdGraph API. Infrastructure conditions: add a description using the UI or the REST API. The text you place in an alert condition's Description field is passed downstream to associated violations and notifications. A description can be used for several purposes, including: Capturing the reason for the alert condition. Defining the signal being monitored. Defining next steps. Add metadata to downstream systems. You can use template substitution to insert values from the attributes in the associated violation event. The template format is {{attributeName}}. For the attributes you can use when creating a description, see Violation event attributes. One available attribute is the special {{tag.*}} attribute. This attribute prefix is used to access any of the tag values that are included with the target signal, or any of the entity tags that are associated with the target signal. If there are entity tags associated with your violation, then they can be accessed using the entity tag name. An example of this would be {{tag.aws.awsRegion}}. When entity tags are available to use, you see them included with the violation, and displayed when you view the violations in an incident. This field has a maximum character size of 4,000. Add or edit a runbook URL The alert condition creation process includes an option for setting a URL for runbook instructions. This lets you link to information or standard procedures for handling a violation. Before adding or updating the link, make sure you use a valid URL. To add, update, or delete an alert condition's runbook URL: Select an alert condition, and make changes to the Runbook URL link. Save the condition. In order to be saved, the URL must be a valid URL. Violation time limit for violations The violation time limit allows you to define a time period after which violations will be force-closed. By default, violation time limit is 24 hours. To add or update an alert condition's violation time limit: Select an alert condition, and make changes to the violation time limit. Save the condition. Alert conditions that generate too-long NRQL queries Alert conditions created for infrastructure rely on behind-the-scenes NRQL queries, and NRQL queries have a 4096-character limit. This means that if your condition generates a very complex NRQL query that filters on many elements (for example, including many hosts or many tags), it will exceed this limit and display an error message saying that the condition failed. To solve this problem, reduce the number of elements you are using in your alert condition. For example: Problem Solution Hosts If you entered a large number of hosts that caused the condition to fail, reduce the number of hosts. Use substrings to target hosts. For example, instead of targeting prod-host-01, prod-host-02, and prod-host-03, just target all hosts with prod-host-0 in the name. Entities Edit your alert condition to target specific attributes that apply to the entities you're trying to target. Create custom attributes for the entities you want to target, and use those attributes in your alert condition. For more information, see Best practices for filtering in infrastructure alerts in New Relic's Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.37447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerts</em> for <em>infrastructure</em>: Add, edit, or view host <em>alert</em> information",
        "sections": "Create <em>alert</em> <em>conditions</em> for <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "With New Relic&#x27;s <em>infrastructure</em> monitoring, you can create <em>alert</em> <em>conditions</em> directly within the context of what you are currently monitoring with New Relic. For example, if you are monitoring a filter set and notice a problem, you do not need to recreate those criteria from New Relic <em>Alerts</em>"
      },
      "id": "6043fa3428ccbc401d2c60b9"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-10-18T19:02:13Z",
      "updated_at": "2021-07-27T13:58:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances on one host This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.01653,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process is running too many instances"
      },
      "id": "603eb49128ccbca939eba74a"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range": [
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-10-18T19:01:51Z",
      "updated_at": "2021-10-18T19:01:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > Events. The Events page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 328.09955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-10-18T07:30:06Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.47374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.72668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-10-18T19:01:11Z",
      "updated_at": "2021-09-08T16:49:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.2237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-10-18T07:30:06Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.47374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.72668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs": [
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-10-18T18:52:42Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and wont be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.21365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.02954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22949,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-10-18T19:06:09Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.83708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure": [
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-10-18T19:06:09Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.83708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/https-proxy-configuration-missing": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22948,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/time-gaps-missing-data": [
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-10-18T19:05:04Z",
      "updated_at": "2021-09-14T07:22:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in infrastructure, and vice versa. If you do not see this APM-infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see APM data in infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.29013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>infrastructure</em>, and vice versa. If you do not see this APM-<em>infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-10-18T18:51:48Z",
      "updated_at": "2021-09-14T05:43:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.22946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    },
    {
      "sections": [
        "The infrastructure agent is not starting in Windows",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "The infrastructure agent is not starting in Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "c79c1fa8f7c9d87f5ed1022e1cae4026b18fdc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-windows/",
      "published_at": "2021-10-18T19:04:00Z",
      "updated_at": "2021-07-21T21:39:29Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic Infrastructure Agent service on Local Computer Error 1067: The process terminated unexpectedly Copy Solution An antivirus or security product might be preventing the New Relic infrastructure agent to be executed as a service. To validate that agent behaves without issues, run the newrelic-infra.exe file from the command line as an administrator, and confirm that the host is reporting data as expected. If that's the case, work with your security team to see if the service needs to be added to your allow list, or configured with additional parameters. Important To read about the agent's location and how to modify it, see hoe to configure the agent directory.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.84041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The <em>infrastructure</em> agent is not starting in Windows",
        "sections": "The <em>infrastructure</em> agent is not starting in Windows",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem You installed the New Relic <em>infrastructure</em> agent on a Windows server and no data is being displayed in the UI. When trying to start the service manually from Windows Services it fails with an error such as: Windows could not start the New Relic <em>Infrastructure</em> Agent service on Local Computer"
      },
      "id": "60f8941164441fafd047ac11"
    }
  ],
  "/docs/instrumentation-editor-instrument-net-ui": [
    {
      "sections": [
        "Introduction to New Relic",
        "Get started with New Relic",
        "All the answers in one place",
        "Bring all your data together",
        "Analyze your data",
        "Respond to incidents faster"
      ],
      "title": "Introduction to New Relic",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "bd62b563a23cb35cc2aabc7f1f44e3dcacbce3cf",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/using-new-relic/welcome-new-relic/get-started/introduction-new-relic/",
      "published_at": "2021-10-19T01:44:41Z",
      "updated_at": "2021-10-19T01:44:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic is an observability platform that helps you build better software. You can bring in data from any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: Instrument everything and import data from across your technology stack using our agents, integrations, and APIs, and access it from a single UI. Analyze your data: Get all your data at your fingertips to find the root causes of problems and optimize your systems. Build dashboards and charts or use our powerful query language. Respond to incidents quickly: Our machine learning solution proactively detects and explains anomalies and warns you before they become problems. Get started with New Relic Here's how you can quickly get started capturing and analyzing your data: If you don't have a New Relic account, sign up at newrelic.com/signup. It's free, forever! Follow the steps in our Add your data UI page to get data flowing in. For your first install, we recommend the Guided install option, which will setup many integrations with a single command. Once you have data coming into New Relic, learn more about the New Relic UI or set up Alerts. All the answers in one place New Relic is built for full stack observability. It links all relevant data so that you get the whole picture of everything that enables your systems to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Monitoring vs. observability: New Relic provides answers to essential questions in one place. As just one example of what you can do with New Relic, imagine you are a Kubernetes administrator overseeing many clusters and pods of software containers. Where do you start troubleshooting? This short video shows how you can locate a problem cluster and use distributed tracing to find relevant logs: Bring all your data together Capture, organize, and make sense of your data in our Telemetry Data Platformno matter where it comes from. Use our agents and integrations to automatically collect data from common frameworks and tools, or use our APIs for data thats more specific to your business or technology. If you don't see your technologies or tasks listed here, see a larger list at New Relic integrations. If you want to... New Relic can help you... Instrument your application Instrument your code: Use our APM agents to automatically instrument your applications in C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Track transactions: Gather distributed tracing details as your transactions cross boundaries between apps and services. Instrument your environment Instrument your infrastructure: Observe your entire environment (including Linux, Windows, AWS, Azure, Google Cloud Platform, Kubernetes, Docker, and more). Collect and centralize logs: See your log data in context with your other application and infrastructure data. Save time switching between tools and reach solutions more quickly. Instrument your digital experiences Enhance browser performance: Decrease page load times, as well as triage and eliminate errors. Monitor mobile apps: Troubleshoot crashes and check the health of your Android and iOS apps with our mobile agents. Simulate user activity: Ensure youre meeting customer expectations by running automated checks to monitor key user flows and experiences. Send data via APIs or build your own solution Collect data without an agent: Call our APIs directly if you prefer to use OpenTelemetry or other agents. Build your own integration: You can use our Flex tool, or one of language-specific SDKs for creating your own exporters to send data to New Relic. As a full user you get access to our entire set of observability tools in New Relic One: Application monitoring Browser monitoring Mobile monitoring Synthetic monitoring Serverless monitoring Infrastructure monitoring Log management You can start anywhere, but you'll never get lost. True observability across your entire stack means that you're in control. Analyze your data With your data secure at New Relic, our platform can alert you to problems and help you organize, process, and understand your data, whether it's metrics, events, logs, or traces: Explore your data visually: Jump into our data explorer to navigate all your data and make connections between your entities without any knowledge of query languages. Query and visualize your data: Use our curated dashboard visualizations or create your own. Use NRQL (New Relic Query Language) to slice and dice your data and dig deeper into questions. Query your data programmatically: Access your data through our NerdGraph GraphQL API. Easily prototype queries in our GraphiQL editor. Respond to incidents faster DevOps, site-reliability, and network operation teams need reliable, real-time alerts and anomaly detection to ensure their systems are always up and running efficiently. Let Applied Intelligence, our hybrid machine learning engine, automatically detect anomalies, reduce alert noise, and enrich incidents with context so that you can respond faster to incidents. Proactive detection: Be notified of unusual app behavior and get an analysis of this unusual behavior sent to Slack. Not using Slack? Set up a webhook to deliver messages when you need them. Get notifications: Set up alerts across your data sources and get notified when systems need your attention. Preserve your attention and control how many threshold violations should fire before you're notified.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.71204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "New Relic is an observability platform that helps you build better software. You can bring in data <em>from</em> any digital source so that you can fully understand your system and how to improve it. With New Relic, you can: Bring all your data together: <em>Instrument</em> everything and import data <em>from</em> across"
      },
      "id": "6043ad0764441f5a06378ecd"
    },
    {
      "sections": [
        "Custom instrumentation editor: Instrument from UI",
        "Requirements",
        "Define custom instrumentation",
        "Caution",
        "Manual instrumentation using the editor",
        "Important",
        "Deploy changes manually",
        "Page functions",
        "Instrumentation options",
        "Results with \"start\" option"
      ],
      "title": "Custom instrumentation editor: Instrument from UI",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Custom instrumentation"
      ],
      "external_id": "979a3d068ba665b13e8e9e18c432356286d61248",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/custom-instrumentation/custom-instrumentation-editor-instrument-ui/",
      "published_at": "2021-10-18T05:36:33Z",
      "updated_at": "2021-03-16T02:40:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's custom instrumentation editor allows Java app users to implement custom instrumentation via the New Relic user interface. The editor is the preferred choice when you cannot modify your application code and don't have that many methods to instrument. See Java custom instrumentation for other instrumentation options and the reasons for using each. To use the custom instrumentation editor: Go to one.newrelic.com > APM > (select a Java app) > Settings > Instrumentation. Use the custom instrumentation editor to: Instrument an unsupported framework. Gain additional insight into uninstrumented methods. Ignore particular transactions. Requirements To use the custom instrumentation editor, you must meet the following requirements: Requirement Comments Agent Java agent version 3.17.0 or higher Security Users of high security mode must export their instrumentation and manually import it to their app server. Define custom instrumentation To define custom instrumentation from the New Relic user interface, use a thread profiling session to collect detailed stack traces of each thread in your application. If possible, test your custom instrumentation in a pre-production environment before changing the instrumentation rules in your production app. In either environment, use the custom instrumentation editor to define the methods you want instrumented, and apply your changes: Create a new thread profiler session. To ensure you collect sufficient data, set the length of the session to at least two minutes. Go to one.newrelic.com > APM > (select an app) > Settings > Instrumentation. Scroll down to the bottom of the page until you see the Recently collected thread profiles list, then select the most recent thread profile. Expand individual methods to locate uninstrumented methods. To define instrumentation rules for particular nodes, select Instrument or Ignore, and customize the rules if necessary. To save your settings, select Confirm instrumentation changes. Deploy your changes from the Instrumentation page: To deploy your changes automatically, select Deploy instrumentation changes. To deploy your changes manually, select Export XML, and see exporting your instrumentation. Caution Avoid over-instrumenting whenever possible. With each additional method that is instrumented, the agent will be using more resources and your application will incur more overhead. In addition, deploying your instrumentation will cause a brief period of higher overhead. This can noticeably slow application requests for several seconds. If you applied your changes from the UI, the agent will begin instrumenting your methods within a few harvest cycles (typically a few minutes). Manual instrumentation using the editor You can also create instrumentation points directly in the editor without using a thread profile: From the custom instrumentation editor, select Add manual instrumentation to manually enter a class and method to be instrumented or ignored. Follow the custom instrumentation by XML rules when defining your instrumentation points. Deploy your changes from the instrumentation editor. Using this method to add instrumentation exposes additional functionality beyond what is available from a thread profile. In addition to matching methods by signature, you can also instrument methods by return type, methods on interfaces, and by Java annotation. These more complex instrumentation types can be created and deleted in the editor, but not edited. Important If a method is marked Instrumentation not allowed, follow New Relic's troubleshooting procedures for custom instrumentation. Deploy changes manually You can also use the custom instrumentation editor to build a custom instrumentation set, then export an instrumentation file and manually import it to your app server. This is required for users of high security mode. To export your instrumentation, define custom instrumentation via the UI. Then select Export xml from the Instrumentation page, and import the file on your app server. Page functions The Instrumentation page supports the following features: If you want to... Do this... Pause or disable custom instrumentation Select Disable instrumentation to temporarily disable all UI-defined custom instrumentation. Select Enable instrumentation to re-enable your instrumentation settings. Import existing instrumentation You can import an existing custom instrumentation xml file by selecting Import xml. You can also Export xml if you do not want to deploy your changes automatically. Edit or delete instrumentation points You cannot edit manual instrumentation, only delete it. Select Remove to stop instrumenting a particular method. Select Edit to change the instrumentation rules. View instrumentation history You can view each previous iteration of your custom instrumentation from the Instrumentation history tab, including who deployed changes and when. You can restore an old version by selecting export to download a copy of the custom instrumentation file, then importing it to the instrumentation editor. Instrumentation options You can define the following options with the custom instrumentation editor: Instrumentation options Comments Instrument methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic UI. Instrument supports the following child options: Name the transaction (transaction name): Override the standard transaction name, defined by the automatic naming rules. The UI will instead use the listed name. Start the transaction when this method executes: Rather than including metrics from this metric inside its parent transaction, create a new transaction for this method. Agent behavior with this option depends on whether there is a pre-existing transaction on the thread. Report custom attributes Method parameters can be captured as attributes on a transaction. New Relic reports these attributes to transaction traces, traced errors, and New Relic One Transaction events. For security reasons, capturing custom attributes using the Custom Instrumentation Editor is disabled by default and cannot be enabled while you are using high security mode. If you want to report custom attributes using the custom instrumentation editor and you do not want the Java agent to be in High security mode, disable High security mode and then add the following text in the common: block of your newrelic.yml: reinstrument: attributes_enabled: true Copy Ignore transactions Ignore this method entirely. The agent will not report metrics from this method, and the method will not contribute to Apdex calculations. Results with \"start\" option If you select Instrument methods > Start the transaction when this method executes, agent behavior depends on whether there is a pre-existing transaction on the thread. When the class or method is instrumented: Is the \"Start the transaction\" flag checked? Yes No If a pre-existing transaction is on that thread and the Start the transaction flag is checked: The agent ignores the Start the transaction flag. The agent includes the class/method into the pre-existing transaction. If a pre-existing transaction is on that thread and the Start the transaction flag is not checked, the agent includes the class/method into the pre-existing transaction. If a transaction is not on that thread and the Start the transaction flag is checked: The agent discovers there is no current transaction. The agent creates a new transaction starting with the class/method you have instrumented. If a transaction is not on that thread and the Start the transaction flag is not checked: The agent looks for a transaction on that thread and does not find one. The metric is dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.34973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "sections": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "tags": "Custom <em>instrumentation</em>",
        "body": " define the following options with the custom <em>instrumentation</em> <em>editor</em>: <em>Instrumentation</em> options Comments <em>Instrument</em> methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic <em>UI</em>. <em>Instrument</em> supports the following child options: Name the transaction (transaction"
      },
      "id": "603ed428e7b9d2b9b52a07e6"
    },
    {
      "sections": [
        "Ruby agent configuration",
        "Configuration methods and precedence",
        "View and edit config file options",
        "Update the config file",
        "Important",
        "General",
        "license_key",
        "agent_enabled",
        "app_name",
        "monitor_mode",
        "log_level",
        "high_security",
        "security_policies_token",
        "proxy_host",
        "proxy_port",
        "proxy_user",
        "proxy_pass",
        "capture_params",
        "Caution",
        "config_path",
        "apdex_t",
        "sync_startup",
        "send_data_on_exit",
        "timeout",
        "force_install_exit_handler",
        "log_file_name",
        "log_file_path",
        "prepend_active_record_instrumentation",
        "capture_memcache_keys",
        "message_tracer.segment_parameters.enabled",
        "marshaller",
        "backport_fast_active_record_connection_lookup",
        "labels",
        "ca_bundle_path",
        "datastore_tracer.instance_reporting.enabled",
        "datastore_tracer.database_name_reporting.enabled",
        "clear_transaction_state_after_fork",
        "exclude_newrelic_header",
        "infinite_tracing.trace_observer.host",
        "infinite_tracing.trace_observer.port",
        "Transaction Tracer",
        "transaction_tracer.enabled",
        "transaction_tracer.transaction_threshold",
        "transaction_tracer.record_sql",
        "transaction_tracer.record_redis_arguments",
        "transaction_tracer.capture_attributes",
        "transaction_tracer.explain_threshold",
        "transaction_tracer.explain_enabled",
        "transaction_tracer.stack_trace_threshold",
        "transaction_tracer.limit_segments",
        "Error Collector",
        "error_collector.enabled",
        "error_collector.capture_attributes",
        "error_collector.ignore_errors",
        "error_collector.ignore_classes",
        "error_collector.ignore_messages",
        "error_collector.ignore_status_codes",
        "error_collector.expected_classes",
        "error_collector.expected_messages",
        "error_collector.expected_status_codes",
        "error_collector.max_backtrace_frames",
        "error_collector.capture_events",
        "error_collector.max_event_samples_stored",
        "Browser Monitoring",
        "browser_monitoring.auto_instrument",
        "browser_monitoring.capture_attributes",
        "Analytics Events",
        "analytics_events.enabled",
        "analytics_events.max_samples_stored",
        "analytics_events.capture_attributes",
        "Attributes",
        "attributes.enabled",
        "transaction_tracer.attributes.enabled",
        "transaction_events.attributes.enabled",
        "error_collector.attributes.enabled",
        "browser_monitoring.attributes.enabled",
        "span_events.attributes.enabled",
        "transaction_segments.attributes.enabled",
        "attributes.exclude",
        "transaction_tracer.attributes.exclude",
        "transaction_events.attributes.exclude",
        "error_collector.attributes.exclude",
        "browser_monitoring.attributes.exclude",
        "span_events.attributes.exclude",
        "transaction_segments.attributes.exclude",
        "attributes.include",
        "transaction_tracer.attributes.include",
        "transaction_events.attributes.include",
        "error_collector.attributes.include",
        "browser_monitoring.attributes.include",
        "span_events.attributes.include",
        "transaction_segments.attributes.include",
        "Audit Log",
        "audit_log.enabled",
        "audit_log.path",
        "audit_log.endpoints",
        "Autostart",
        "autostart.denylisted_constants",
        "autostart.denylisted_executables",
        "autostart.denylisted_rake_tasks",
        "Cross Application Tracer",
        "cross_application_tracer.enabled",
        "Custom Attributes",
        "custom_attributes.enabled",
        "Custom Insights Events",
        "custom_insights_events.enabled",
        "custom_insights_events.max_samples_stored",
        "Disabling",
        "disable_rake",
        "disable_samplers",
        "disable_resque",
        "disable_sidekiq",
        "disable_dj",
        "disable_sinatra",
        "disable_sinatra_auto_middleware",
        "disable_view_instrumentation",
        "disable_activerecord_instrumentation",
        "disable_data_mapper",
        "disable_activejob",
        "disable_action_cable_instrumentation",
        "disable_active_storage",
        "disable_memcached",
        "disable_memcache_client",
        "disable_dalli",
        "disable_dalli_cas_client",
        "disable_memcache_instrumentation",
        "disable_gc_profiler",
        "disable_sequel_instrumentation",
        "disable_database_instrumentation",
        "disable_mongo",
        "disable_redis",
        "disable_vm_sampler",
        "disable_memory_sampler",
        "disable_cpu_sampler",
        "disable_delayed_job_sampler",
        "disable_active_record_notifications",
        "disable_bunny",
        "disable_curb",
        "disable_excon",
        "disable_httpclient",
        "disable_net_http",
        "disable_rack",
        "disable_rack_urlmap",
        "disable_puma_rack",
        "disable_puma_rack_urlmap",
        "disable_typhoeus",
        "disable_httprb",
        "disable_middleware_instrumentation",
        "disable_grape",
        "Distributed Tracing",
        "distributed_tracing.enabled",
        "Heroku",
        "heroku.use_dyno_names",
        "heroku.dyno_name_prefixes_to_shorten",
        "Instrumentation",
        "instrumentation.net_http",
        "instrumentation.typhoeus",
        "instrumentation.bunny",
        "instrumentation.httprb",
        "instrumentation.resque",
        "instrumentation.redis",
        "instrumentation.rake",
        "instrumentation.mongo",
        "instrumentation.delayed_job",
        "instrumentation.httpclient",
        "instrumentation.curb",
        "instrumentation.sinatra",
        "instrumentation.rack",
        "instrumentation.rack_urlmap",
        "instrumentation.puma_rack",
        "instrumentation.puma_rack_urlmap",
        "instrumentation.memcached",
        "instrumentation.memcache_client",
        "instrumentation.memcache",
        "instrumentation.logger",
        "instrumentation.excon",
        "instrumentation.grape",
        "Mongo",
        "mongo.capture_queries",
        "mongo.obfuscate_queries",
        "Process Host",
        "process_host.display_name",
        "Rake",
        "rake.tasks",
        "rake.connect_timeout",
        "Resque",
        "resque.capture_params",
        "Rules",
        "rules.ignore_url_regexes",
        "Sidekiq",
        "sidekiq.capture_params",
        "Slow SQL",
        "slow_sql.enabled",
        "slow_sql.explain_threshold",
        "slow_sql.explain_enabled",
        "slow_sql.record_sql",
        "slow_sql.use_longer_sql_id",
        "Span Events",
        "span_events.enabled",
        "span_events.queue_size",
        "span_events.max_samples_stored",
        "Strip Exception Messages",
        "strip_exception_messages.enabled",
        "strip_exception_messages.allowed_classes",
        "Thread Profiler",
        "thread_profiler.enabled",
        "Utilization",
        "utilization.detect_aws",
        "utilization.detect_azure",
        "utilization.detect_gcp",
        "utilization.detect_pcf",
        "utilization.detect_docker",
        "utilization.detect_kubernetes"
      ],
      "title": "Ruby agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "Ruby agent",
        "Configuration"
      ],
      "external_id": "ee72f1c59d456c5e5a089cfa81bfbde6064d7cb0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/ruby-agent/configuration/ruby-agent-configuration/",
      "published_at": "2021-10-19T03:52:40Z",
      "updated_at": "2021-10-19T03:52:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure the New Relic Ruby agent with settings in a configuration file, environment variables, or programmatically with server-side configuration. This document summarizes the configuration options available for the Ruby agent. If the default value for a configuration option is (Dynamic), this means the Ruby agent calculates the default at runtime. The value for the config setting defaults to the value of another setting as appropriate. Configuration methods and precedence The primary (default) method to configure the Ruby agent is via the configuration file (newrelic.yml) in the config subdirectory. To set configuration values using environment variables: Add the prefix NEW_RELIC_ to the setting's name. Replace any periods . with underscores _. You can also configure a few values in the UI via server-side configuration. The Ruby agent follows this order of precedence for configuration: Environment variables Server-side configuration Configuration file (newrelic.yml) Default configuration settings In other words, environment variables override all other configuration settings and info, server-side configuration overrides the configuration file and default config settings, and so on. View and edit config file options The Ruby agent's newrelic.yml is a standard YAML configuration file. It typically includes a Defaults section at the top, plus sections below for each application environment; for example, Development, Testing, and Production. The Ruby agent determines which section of the newrelic.yml config file to read from by looking at certain environment variables to derive the application's environment. This can be useful, for example, when you want to use info for the log_level config setting in your production environment, and you want more verbose log_level config settings (such as debug in your development environment. Here is an example newrelic.yml config file: common: &default_settings license_key: 'YOUR_LICENSE_KEY' app_name: 'My Application Name' production: <<: *default_settings log_level: info development: <<: *default_settings log_level: debug Copy For non-Rails apps, the Ruby agent looks for the following environment variables, in this order, to determine the application environment: NEW_RELIC_ENV RUBY_ENV RAILS_ENV APP_ENV RACK_ENV If the Ruby agent does not detect values for any of those environment variables, it will default the application environment to development and read from the development section of the newrelic.yml config file. When running the Ruby agent in a Rails app, the agent first looks for the NEW_RELIC_ENV environment variable to determine the application environment and which section of the newrelic.yml to use. If NEW_RELIC_ENV is not present, the agent uses the Rails environment (RAILS_ENV or RAILS.env, depending on the version of Rails) . When you edit the config file, be sure to: Indent only with two spaces. Indent only where relevant, in stanzas such as error_collector. If you do not indent correctly, the agent may throw an Unable to parse configuration file error on startup. To view the most current list of available Ruby agent configuration options, use the rake newrelic:config:docs command. This document describes the most common options. Update the config file This documentation applies to the Ruby agent's latest release. For details on earlier versions, refer to the comments in newrelic.yml itself. To update newrelic.yml file after a new release, use the template in the base directory of the agent gem. When you update to new gem versions, examine or diff config/newrelic.yml and newrelic.yml in the installation directory to take advantage of new configuration options. Important Updating the gem does not automatically update config/newrelic.yml. General These settings are available for agent configuration. Some settings depend on your New Relic subscription level. license_key Type String Default \"\" Environ variable NEW_RELIC_LICENSE_KEY Your New Relic license key. agent_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_AGENT_ENABLED If true, allows the Ruby agent to run. app_name Type String Default (Dynamic) Environ variable NEW_RELIC_APP_NAME Specify the application name used to aggregate data in the New Relic UI. To report data to multiple apps at the same time, specify a list of names separated by a semicolon ;. For example, MyApp or MyStagingApp;Instance1. monitor_mode Type Boolean Default (Dynamic) Environ variable NEW_RELIC_MONITOR_MODE When true, the agent transmits data about your app to the New Relic collector. log_level Type String Default \"info\" Environ variable NEW_RELIC_LOG_LEVEL Sets the level of detail of log messages. Possible log levels, in increasing verbosity, are: error, warn, info or debug. high_security Type Boolean Default false Environ variable NEW_RELIC_HIGH_SECURITY If true, enables high security mode. Ensure you understand the implications of high security mode before enabling this setting. security_policies_token Type String Default \"\" Environ variable NEW_RELIC_SECURITY_POLICIES_TOKEN Applies Language Agent Security Policy settings. proxy_host Type String Default nil Environ variable NEW_RELIC_PROXY_HOST Defines a host for communicating with the New Relic collector via a proxy server. proxy_port Type Integer Default 8080 Environ variable NEW_RELIC_PROXY_PORT Defines a port for communicating with the New Relic collector via a proxy server. proxy_user Type String Default nil Environ variable NEW_RELIC_PROXY_USER Defines a user for communicating with the New Relic collector via a proxy server. proxy_pass Type String Default nil Environ variable NEW_RELIC_PROXY_PASS Defines a password for communicating with the New Relic collector via a proxy server. capture_params Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_PARAMS When true, the agent captures HTTP request parameters and attaches them to transaction traces, traced errors, and TransactionError events. Caution When using the capture_params setting, the Ruby agent will not attempt to filter secret information. Recommendation: To filter secret information from request parameters, use the attributes.include setting instead. For more information, see the Ruby attribute examples. config_path Type String Default (Dynamic) Environ variable NEW_RELIC_CONFIG_PATH Path to newrelic.yml. If undefined, the agent checks the following directories (in order): config/newrelic.yml, newrelic.yml, $HOME/.newrelic/newrelic.yml and $HOME/newrelic.yml. apdex_t Type Float Default 0.5 Environ variable NEW_RELIC_APDEX_T DEPRECATED For agent versions 3.5.0 or higher, set your Apdex T via the New Relic UI. sync_startup Type Boolean Default false Environ variable NEW_RELIC_SYNC_STARTUP When set to true, forces a synchronous connection to the New Relic collector during application startup. For very short-lived processes, this helps ensure the New Relic agent has time to report. send_data_on_exit Type Boolean Default true Environ variable NEW_RELIC_SEND_DATA_ON_EXIT If true, enables the exit handler that sends data to the New Relic collector before shutting down. timeout Type Integer Default 120 Environ variable NEW_RELIC_TIMEOUT Defines the maximum number of seconds the agent should spend attempting to connect to the collector. force_install_exit_handler Type Boolean Default false Environ variable NEW_RELIC_FORCE_INSTALL_EXIT_HANDLER Forces the exit handler that sends all cached data to collector before shutting down to be installed regardless of detecting scenarios where it generally should not be. Known use-case for this option is where Sinatra is running as an embedded service within another framework and the agent is detecting the Sinatra app and skipping the at_exit handler as a result. Sinatra classically runs the entire application in an at_exit block and would otherwise misbehave if the Agent's at_exit handler was also installed in those circumstances. Note: send_data_on_exit should also be set to true in tandem with this setting. log_file_name Type String Default \"newrelic_agent.log\" Environ variable NEW_RELIC_LOG_FILE_NAME Defines a name for the log file. log_file_path Type String Default \"log/\" Environ variable NEW_RELIC_LOG_FILE_PATH Defines a path to the agent log file, excluding the filename. prepend_active_record_instrumentation Type Boolean Default false Environ variable NEW_RELIC_PREPEND_ACTIVE_RECORD_INSTRUMENTATION If true, uses Module#prepend rather than alias_method for ActiveRecord instrumentation. capture_memcache_keys Type Boolean Default false Environ variable NEW_RELIC_CAPTURE_MEMCACHE_KEYS Enable or disable the capture of memcache keys from transaction traces. message_tracer.segment_parameters.enabled Type Boolean Default true Environ variable NEW_RELIC_MESSAGE_TRACER_SEGMENT_PARAMETERS_ENABLED If true, the agent will collect metadata about messages and attach them as segment parameters. marshaller Type String Default \"json\" Environ variable NEW_RELIC_MARSHALLER Specifies a marshaller for transmitting data to the New Relic collector. Currently json is the only valid value for this setting. backport_fast_active_record_connection_lookup Type Boolean Default false Environ variable NEW_RELIC_BACKPORT_FAST_ACTIVE_RECORD_CONNECTION_LOOKUP Backports the faster ActiveRecord connection lookup introduced in Rails 6, which improves agent performance when instrumenting ActiveRecord. Note that this setting may not be compatible with other gems that patch ActiveRecord. labels Type String Default \"\" Environ variable NEW_RELIC_LABELS A dictionary of label names and values that will be applied to the data sent from this agent. May also be expressed as a semicolon-delimited ; string of colon-separated : pairs. For example, <var>Server</var>:<var>One</var>;<var>Data Center</var>:<var>Primary</var>. ca_bundle_path Type String Default nil Environ variable NEW_RELIC_CA_BUNDLE_PATH Manual override for the path to your local CA bundle. This CA bundle will be used to validate the SSL certificate presented by New Relic's data collection service. datastore_tracer.instance_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_INSTANCE_REPORTING_ENABLED If false, the agent will not report datastore instance metrics, nor add host or port_path_or_id parameters to transaction or slow SQL traces. datastore_tracer.database_name_reporting.enabled Type Boolean Default true Environ variable NEW_RELIC_DATASTORE_TRACER_DATABASE_NAME_REPORTING_ENABLED If false, the agent will not add database_name parameter to transaction or slow sql traces. clear_transaction_state_after_fork Type Boolean Default false Environ variable NEW_RELIC_CLEAR_TRANSACTION_STATE_AFTER_FORK If true, the agent will clear Tracer::State in Agent.drop_buffered_data. exclude_newrelic_header Type Boolean Default false Environ variable NEW_RELIC_EXCLUDE_NEWRELIC_HEADER Allows newrelic distributed tracing headers to be suppressed on outbound requests. infinite_tracing.trace_observer.host Type String Default \"\" Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST Configures the hostname for the Trace Observer Host. When configured, enables tail-based sampling by sending all recorded spans to a Trace Observer for further sampling decisions, irrespective of any usual agent sampling decision. infinite_tracing.trace_observer.port Type Integer Default 443 Environ variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_PORT Configures the TCP/IP port for the Trace Observer Host Transaction Tracer The transaction traces feature collects detailed information from a selection of transactions, including a summary of the calling sequence, a breakdown of time spent, and a list of SQL queries and their query plans (on mysql and postgresql). Available features depend on your New Relic subscription level. transaction_tracer.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_ENABLED If true, enables collection of transaction traces. transaction_tracer.transaction_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_TRANSACTION_THRESHOLD Specify a threshold in seconds. Transactions with a duration longer than this threshold are eligible for transaction traces. Specify a float value or the string apdex_f. transaction_tracer.record_sql Type String Default \"obfuscated\" Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_SQL Obfuscation level for SQL queries reported in transaction trace nodes. By default, this is set to obfuscated, which strips out the numeric and string literals. If you do not want the agent to capture query information, set this to none. If you want the agent to capture all query information in its original form, set this to raw. When you enable high security mode, this is automatically set to obfuscated. transaction_tracer.record_redis_arguments Type Boolean Default false Environ variable NEW_RELIC_TRANSACTION_TRACER_RECORD_REDIS_ARGUMENTS If true, the agent records Redis command arguments in transaction traces. transaction_tracer.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_tracer.attributes.enabled instead. transaction_tracer.explain_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_THRESHOLD Threshold (in seconds) above which the agent will collect explain plans. Relevant only when explain_enabled is true. transaction_tracer.explain_enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_TRACER_EXPLAIN_ENABLED If true, enables the collection of explain plans in transaction traces. This setting will also apply to explain plans in slow SQL traces if slow_sql.explain_enabled is not set separately. transaction_tracer.stack_trace_threshold Type Float Default 0.5 Environ variable NEW_RELIC_TRANSACTION_TRACER_STACK_TRACE_THRESHOLD Specify a threshold in seconds. The agent includes stack traces in transaction trace nodes when the stack trace duration exceeds this threshold. transaction_tracer.limit_segments Type Integer Default 4000 Environ variable NEW_RELIC_TRANSACTION_TRACER_LIMIT_SEGMENTS Maximum number of transaction trace nodes to record in a single transaction trace. Error Collector The agent collects and reports all uncaught exceptions by default. These configuration options allow you to customize the error collection. For information on ignored and expected errors, see this page on Error Analytics in APM. To set expected errors via the NewRelic::Agent.notice_error Ruby method, consult the Ruby Agent API. error_collector.enabled Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_ENABLED If true, the agent captures traced errors and error count metrics. error_collector.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_ATTRIBUTES DEPRECATED Use error_collector.attributes.enabled instead. error_collector.ignore_errors Type String Default \"ActionController::RoutingError,Sinatra::NotFound\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERRORS DEPRECATED Use error_collector.ignore_classes instead. Specify a comma-delimited list of error classes that the agent should ignore. Caution Server side configuration takes precedence for this setting over all environment configurations. This differs from all other configuration settings where environment variable take precedence over server side configuration. error_collector.ignore_classes Type Array Default [] Environ variable None A list of error classes that the agent should ignore. Caution This option can't be set via environment variable. error_collector.ignore_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be ignored. Caution This option can't be set via environment variable. error_collector.ignore_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_IGNORE_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be ignored. error_collector.expected_classes Type Array Default [] Environ variable None A list of error classes that the agent should treat as expected. Caution This option can't be set via environment variable. error_collector.expected_messages Type Hash Default {} Environ variable None A map of error classes to a list of messages. When an error of one of the classes specified here occurs, if its error message contains one of the strings corresponding to it here, that error will be treated as expected. Caution This option can't be set via environment variable. error_collector.expected_status_codes Type String Default \"\" Environ variable NEW_RELIC_ERROR_COLLECTOR_EXPECTED_STATUS_CODES A comma separated list of status codes, possibly including ranges. Errors associated with these status codes, where applicable, will be treated as expected. error_collector.max_backtrace_frames Type Integer Default 50 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_BACKTRACE_FRAMES Defines the maximum number of frames in an error backtrace. Backtraces over this amount are truncated at the beginning and end. error_collector.capture_events Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_CAPTURE_EVENTS If true, the agent collects TransactionError events. error_collector.max_event_samples_stored Type Integer Default 100 Environ variable NEW_RELIC_ERROR_COLLECTOR_MAX_EVENT_SAMPLES_STORED Defines the maximum number of TransactionError events sent to Insights per harvest cycle. Browser Monitoring The browser monitoring page load timing feature (sometimes referred to as real user monitoring or RUM) gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. browser_monitoring.auto_instrument Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_AUTO_INSTRUMENT If true, enables auto-injection of the JavaScript header for page load timing (sometimes referred to as real user monitoring or RUM). browser_monitoring.capture_attributes Type Boolean Default false Environ variable NEW_RELIC_BROWSER_MONITORING_CAPTURE_ATTRIBUTES DEPRECATED Use browser_monitoring.attributes.enabled instead. Analytics Events New Relic dashboards is a resource to gather and visualize data about your software and what it says about your business. With it you can quickly and easily create real-time dashboards to get immediate answers about end-user experiences, clickstreams, mobile activities, and server transactions. analytics_events.enabled Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_ENABLED If true, enables analytics event sampling. analytics_events.max_samples_stored Type Integer Default 1200 Environ variable NEW_RELIC_ANALYTICS_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of request events reported from a single harvest. analytics_events.capture_attributes Type Boolean Default true Environ variable NEW_RELIC_ANALYTICS_EVENTS_CAPTURE_ATTRIBUTES DEPRECATED Use transaction_events.attributes.enabled instead. Attributes Attributes are key-value pairs containing information that determines the properties of an event or transaction. These key-value pairs can be viewed within transaction traces in APM, traced errors in APM, transaction events in dashboards, and page views in dashboards. You can customize exactly which attributes will be sent to each of these destinations attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_ATTRIBUTES_ENABLED If true, enables capture of attributes for all destinations. transaction_tracer.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction traces. transaction_events.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes from transaction events. error_collector.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_ENABLED If true, the agent captures attributes from error collection. browser_monitoring.attributes.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_ENABLED If true, the agent captures attributes from browser monitoring. span_events.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on span events. transaction_segments.attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_ENABLED If true, the agent captures attributes on transaction segments. attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from all destinations. Allows * as wildcard at end. transaction_tracer.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction traces. Allows * as wildcard at end. transaction_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction events. Allows * as wildcard at end. error_collector.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from error collection. Allows * as wildcard at end. browser_monitoring.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from browser monitoring. Allows * as wildcard at end. span_events.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from span events. Allows * as wildcard at end. transaction_segments.attributes.exclude Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_EXCLUDE Prefix of attributes to exclude from transaction segments. Allows * as wildcard at end. attributes.include Type Array Default [] Environ variable NEW_RELIC_ATTRIBUTES_INCLUDE Prefix of attributes to include in all destinations. Allows * as wildcard at end. transaction_tracer.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_TRACER_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction traces. Allows * as wildcard at end. transaction_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include in transaction events. Allows * as wildcard at end. error_collector.attributes.include Type Array Default [] Environ variable NEW_RELIC_ERROR_COLLECTOR_ATTRIBUTES_INCLUDE Prefix of attributes to include in error collection. Allows * as wildcard at end. browser_monitoring.attributes.include Type Array Default [] Environ variable NEW_RELIC_BROWSER_MONITORING_ATTRIBUTES_INCLUDE Prefix of attributes to include in browser monitoring. Allows * as wildcard at end. span_events.attributes.include Type Array Default [] Environ variable NEW_RELIC_SPAN_EVENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on span events. Allows * as wildcard at end. transaction_segments.attributes.include Type Array Default [] Environ variable NEW_RELIC_TRANSACTION_SEGMENTS_ATTRIBUTES_INCLUDE Prefix of attributes to include on transaction segments. Allows * as wildcard at end. Audit Log audit_log.enabled Type Boolean Default false Environ variable NEW_RELIC_AUDIT_LOG_ENABLED If true, enables an audit log which logs communications with the New Relic collector. audit_log.path Type String Default (Dynamic) Environ variable NEW_RELIC_AUDIT_LOG_PATH Specifies a path to the audit log file (including the filename). audit_log.endpoints Type Array Default [\".*\"] Environ variable NEW_RELIC_AUDIT_LOG_ENDPOINTS List of allowed endpoints to include in audit log Autostart autostart.denylisted_constants Type String Default \"Rails::Console\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_CONSTANTS Specify a list of constants that should prevent the agent from starting automatically. Separate individual constants with a comma ,. For example, Rails::Console,UninstrumentedBackgroundJob. autostart.denylisted_executables Type String Default \"irb,rspec\" Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_EXECUTABLES Defines a comma-delimited list of executables that the agent should not instrument. For example, rake,my_ruby_script.rb. autostart.denylisted_rake_tasks Type String Default Copy Environ variable NEW_RELIC_AUTOSTART_DENYLISTED_RAKE_TASKS Defines a comma-delimited list of Rake tasks that the agent should not instrument. For example, assets:precompile,db:migrate. Cross Application Tracer cross_application_tracer.enabled Type Boolean Default false Environ variable NEW_RELIC_CROSS_APPLICATION_TRACER_ENABLED DEPRECATED Please see: distributed_tracing-enabled. If true, enables cross-application tracing when distributed_tracing.enabled is set to false. Custom Attributes custom_attributes.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_ATTRIBUTES_ENABLED If false, custom attributes will not be sent on Insights events. Custom Insights Events custom_insights_events.enabled Type Boolean Default true Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_ENABLED If true, the agent captures New Relic Insights custom events. custom_insights_events.max_samples_stored Type Integer Default 1000 Environ variable NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED Specify a maximum number of custom Insights events to buffer in memory at a time. Disabling Use these settings to toggle instrumentation types during agent startup. disable_rake Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RAKE DEPRECATED Please see: instrumentation.rake. If true, disables Rake instrumentation. disable_samplers Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SAMPLERS If true, disables the collection of sampler metrics. Sampler metrics are metrics that are not event-based (such as CPU time or memory usage). disable_resque Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RESQUE DEPRECATED Please see: instrumentation.resque. If true, disables Resque instrumentation. disable_sidekiq Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SIDEKIQ If true, disables Sidekiq instrumentation. disable_dj Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DJ DEPRECATED Please see: instrumentation.delayed_job. If true, disables Delayed::Job instrumentation. disable_sinatra Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA DEPRECATED Please see: instrumentation.sinatra. If true , disables Sinatra instrumentation. disable_sinatra_auto_middleware Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SINATRA_AUTO_MIDDLEWARE If true, disables agent middleware for Sinatra. This middleware is responsible for advanced feature support such as cross application tracing, page load timing, and error collection. Important Cross application tracing is deprecated in favor of distributed tracing. Distributed tracing is on by default for Ruby agent versions 8.0.0 and above. Middlewares are not required to support distributed tracing. To continue using cross application tracing, update the following options in your newrelic.yml configuration file: # newrelic.yml cross_application_tracer: enabled: true distributed_tracing: enabled: false Copy disable_view_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VIEW_INSTRUMENTATION If true, disables view instrumentation. disable_activerecord_instrumentation Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_ACTIVERECORD_INSTRUMENTATION If true, disables active record instrumentation. disable_data_mapper Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATA_MAPPER If true, disables DataMapper instrumentation. disable_activejob Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVEJOB If true, disables ActiveJob instrumentation. disable_action_cable_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTION_CABLE_INSTRUMENTATION If true, disables Action Cable instrumentation. disable_active_storage Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_STORAGE If true, disables ActiveStorage instrumentation. disable_memcached Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHED DEPRECATED Please see: instrumentation.memcached. If true, disables instrumentation for the memcached gem. disable_memcache_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_MEMCACHE_CLIENT DEPRECATED Please see: instrumentation.memcache-client. If true, disables instrumentation for the memcache-client gem. disable_dalli Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem. disable_dalli_cas_client Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_DALLI_CAS_CLIENT DEPRECATED Please see: instrumentation.memcache. If true, disables instrumentation for the dalli gem's additional CAS client support. disable_memcache_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMCACHE_INSTRUMENTATION DEPRECATED Please see: instrumentation.memcache. If true, disables memcache instrumentation. disable_gc_profiler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GC_PROFILER If true, disables the use of GC::Profiler to measure time spent in garbage collection disable_sequel_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_SEQUEL_INSTRUMENTATION If true, disables Sequel instrumentation. disable_database_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DATABASE_INSTRUMENTATION DEPRECATED Use disable_sequel_instrumentation instead. disable_mongo Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MONGO DEPRECATED Please see: instrumentation.mongo. If true, the agent won't install instrumentation for the Mongo gem. disable_redis Type Boolean Default false Environ variable NEW_RELIC_DISABLE_REDIS DEPRECATED Please see: instrumentation.redis. If true, the agent won't install instrumentation for Redis. disable_vm_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_VM_SAMPLER If true, the agent won't sample performance measurements from the Ruby VM. disable_memory_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MEMORY_SAMPLER If true, the agent won't sample the memory usage of the host process. disable_cpu_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CPU_SAMPLER If true, the agent won't sample the CPU usage of the host process. disable_delayed_job_sampler Type Boolean Default false Environ variable NEW_RELIC_DISABLE_DELAYED_JOB_SAMPLER If true, the agent won't measure the depth of Delayed Job queues. disable_active_record_notifications Type Boolean Default false Environ variable NEW_RELIC_DISABLE_ACTIVE_RECORD_NOTIFICATIONS If true, disables instrumentation for ActiveRecord 4, 5, and 6. disable_bunny Type Boolean Default false Environ variable NEW_RELIC_DISABLE_BUNNY DEPRECATED Please see: instrumentation.bunny. If true, disables instrumentation for the bunny gem. disable_curb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_CURB DEPRECATED Please see: instrumentation.curb. If true, disables instrumentation for the curb gem. disable_excon Type Boolean Default false Environ variable NEW_RELIC_DISABLE_EXCON DEPRECATED Please see: instrumentation.excon. If true, disables instrumentation for the excon gem. disable_httpclient Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPCLIENT DEPRECATED Please see: instrumentation.httpclient. If true, disables instrumentation for the httpclient gem. disable_net_http Type Boolean Default false Environ variable NEW_RELIC_DISABLE_NET_HTTP DEPRECATED Please see: instrumentation.net_http. If true, disables instrumentation for Net::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: instrumentation.rack. If true, prevents the agent from hooking into the to_app method in Rack::Builder to find gems to instrument during application startup. disable_rack_urlmap Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK_URLMAP DEPRECATED Please see: instrumentation.rack_urlmap. If true, prevents the agent from hooking into Rack::URLMap to install middleware tracing. disable_puma_rack Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK DEPRECATED Please see: instrumentation.puma_rack. If true, prevents the agent from hooking into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. disable_puma_rack_urlmap Type Boolean Default (Dynamic) Environ variable NEW_RELIC_DISABLE_PUMA_RACK_URLMAP DEPRECATED Please see: instrumentation.puma_rack_urlmap. If true, prevents the agent from hooking into Puma::Rack::URLMap to install middleware tracing. disable_typhoeus Type Boolean Default false Environ variable NEW_RELIC_DISABLE_TYPHOEUS DEPRECATED Please see: instrumentation.typhoeus. If true, the agent won't install instrumentation for the typhoeus gem. disable_httprb Type Boolean Default false Environ variable NEW_RELIC_DISABLE_HTTPRB DEPRECATED Please see: instrumentation.httprb. If true, the agent won't install instrumentation for the http.rb gem. disable_middleware_instrumentation Type Boolean Default false Environ variable NEW_RELIC_DISABLE_MIDDLEWARE_INSTRUMENTATION If true, the agent won't wrap third-party middlewares in instrumentation (regardless of whether they are installed via Rack::Builder or Rails). disable_grape Type Boolean Default false Environ variable NEW_RELIC_DISABLE_GRAPE DEPRECATED Please see: instrumentation.grape. If true, the agent won't install Grape instrumentation. Distributed Tracing distributed_tracing.enabled Type Boolean Default true Environ variable NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Distributed tracing lets you see the path that a request takes through your distributed system. Enabling distributed tracing changes the behavior of some New Relic features, so carefully consult the transition guide before you enable this feature. Heroku heroku.use_dyno_names Type Boolean Default true Environ variable NEW_RELIC_HEROKU_USE_DYNO_NAMES If true, the agent uses Heroku dyno names as the hostname. heroku.dyno_name_prefixes_to_shorten Type Array Default [\"scheduler\", \"run\"] Environ variable NEW_RELIC_HEROKU_DYNO_NAME_PREFIXES_TO_SHORTEN Ordinarily the agent reports dyno names with a trailing dot and process ID (for example, worker.3). You can remove this trailing data by specifying the prefixes you want to report without trailing data (for example, worker). Instrumentation instrumentation.net_http Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_NET_HTTP Controls auto-instrumentation of Net::HTTP at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.typhoeus Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_TYPHOEUS Controls auto-instrumentation of Typhoeus at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.bunny Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_BUNNY Controls auto-instrumentation of bunny at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httprb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPRB Controls auto-instrumentation of http.rb gem at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.resque Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RESQUE Controls auto-instrumentation of resque at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.redis Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_REDIS Controls auto-instrumentation of Redis at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rake Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RAKE Controls auto-instrumentation of rake at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.mongo Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MONGO Controls auto-instrumentation of Mongo at start up. May be one of [enabled|disabled] . instrumentation.delayed_job Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_DELAYED_JOB Controls auto-instrumentation of Delayed Job at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.httpclient Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_HTTPCLIENT Controls auto-instrumentation of HTTPClient at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.curb Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_CURB Controls auto-instrumentation of Curb at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.sinatra Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_SINATRA Controls auto-instrumentation of Sinatra at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK Controls auto-instrumentation of Rack. When enabled, the agent hooks into the to_app method in Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_RACK_URLMAP Controls auto-instrumentation of Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK Controls auto-instrumentation of Puma::Rack. When enabled, the agent hooks into the to_app method in Puma::Rack::Builder to find gems to instrument during application startup. May be one of [auto|prepend|chain|disabled] . instrumentation.puma_rack_urlmap Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_PUMA_RACK_URLMAP Controls auto-instrumentation of Puma::Rack::URLMap at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcached Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHED Controls auto-instrumentation of memcached gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache_client Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE_CLIENT Controls auto-instrumentation of memcache-client gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.memcache Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_MEMCACHE Controls auto-instrumentation of dalli gem for Memcache at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.logger Type String Default \"auto\" Environ variable NEW_RELIC_INSTRUMENTATION_LOGGER Controls auto-instrumentation of Ruby standard library Logger at start up. May be one of [auto|prepend|chain|disabled] . instrumentation.excon Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_EXCON Controls auto-instrumentation of Excon at start up. May be one of [enabled|disabled] . instrumentation.grape Type String Default (Dynamic) Environ variable NEW_RELIC_INSTRUMENTATION_GRAPE Controls auto-instrumentation of Grape at start up. May be one of [auto|prepend|chain|disabled] . Mongo mongo.capture_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_CAPTURE_QUERIES If true, the agent captures Mongo queries in transaction traces. mongo.obfuscate_queries Type Boolean Default true Environ variable NEW_RELIC_MONGO_OBFUSCATE_QUERIES If true, the agent obfuscates Mongo queries in transaction traces. Process Host process_host.display_name Type String Default (Dynamic) Environ variable NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Specify a custom host name for display in the New Relic UI. Rake rake.tasks Type Array Default [] Environ variable NEW_RELIC_RAKE_TASKS Specify an array of Rake tasks to automatically instrument. rake.connect_timeout Type Integer Default 10 Environ variable NEW_RELIC_RAKE_CONNECT_TIMEOUT Timeout for waiting on connect to complete before a rake task Resque resque.capture_params Type Boolean Default false Environ variable NEW_RELIC_RESQUE_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Resque. Rules rules.ignore_url_regexes Type Array Default [] Environ variable NEW_RELIC_RULES_IGNORE_URL_REGEXES Define transactions you want the agent to ignore, by specifying a list of patterns matching the URI you want to ignore. Note: This will only ignore transaction events, not spans or traces from the same transation. See documentation on (ignoring specific transactions) [https://docs.newrelic.com/docs/agents/ruby-agent/api-guides/ignoring-specific-transactions/#config-ignoring] for more details. Sidekiq sidekiq.capture_params Type Boolean Default false Environ variable NEW_RELIC_SIDEKIQ_CAPTURE_PARAMS DEPRECATED If true, enables the capture of job arguments for transaction traces and traced errors in Sidekiq. Slow SQL slow_sql.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_ENABLED If true, the agent collects slow SQL queries. slow_sql.explain_threshold Type Float Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_THRESHOLD Specify a threshold in seconds. The agent collects slow SQL queries and explain plans that exceed this threshold. slow_sql.explain_enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_EXPLAIN_ENABLED If true, the agent collects explain plans in slow SQL queries. If this setting is omitted, the transaction_tracer.explain_enabled setting will be applied as the default setting for explain plans in slow SQL as well. slow_sql.record_sql Type String Default (Dynamic) Environ variable NEW_RELIC_SLOW_SQL_RECORD_SQL Defines an obfuscation level for slow SQL queries. Valid options are obfuscated, raw, or none). slow_sql.use_longer_sql_id Type Boolean Default false Environ variable NEW_RELIC_SLOW_SQL_USE_LONGER_SQL_ID Generate a longer sql_id for slow SQL traces. sql_id is used for aggregation of similar queries. Span Events span_events.enabled Type Boolean Default true Environ variable NEW_RELIC_SPAN_EVENTS_ENABLED If true, enables span event sampling. span_events.queue_size Type Integer Default 10000 Environ variable NEW_RELIC_SPAN_EVENTS_QUEUE_SIZE Sets the maximum number of span events to buffer when streaming to the trace observer. span_events.max_samples_stored Type Integer Default 2000 Environ variable NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED Defines the maximum number of span events reported from a single harvest. Strip Exception Messages strip_exception_messages.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ENABLED If true, the agent strips messages from all exceptions except those in the allowlist. Enabled automatically in high security mode. strip_exception_messages.allowed_classes Type String Default \"\" Environ variable NEW_RELIC_STRIP_EXCEPTION_MESSAGES_ALLOWED_CLASSES Specify a list of exceptions you do not want the agent to strip when strip_exception_messages is true. Separate exceptions with a comma. For example, \"ImportantException,PreserveMessageException\". Thread Profiler thread_profiler.enabled Type Boolean Default (Dynamic) Environ variable NEW_RELIC_THREAD_PROFILER_ENABLED If true, enables use of the thread profiler. Utilization utilization.detect_aws Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AWS If true, the agent automatically detects that it is running in an AWS environment. utilization.detect_azure Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_AZURE If true, the agent automatically detects that it is running in an Azure environment. utilization.detect_gcp Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_GCP If true, the agent automatically detects that it is running in an Google Cloud Platform environment. utilization.detect_pcf Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_PCF If true, the agent automatically detects that it is running in a Pivotal Cloud Foundry environment. utilization.detect_docker Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_DOCKER If true, the agent automatically detects that it is running in Docker. utilization.detect_kubernetes Type Boolean Default true Environ variable NEW_RELIC_UTILIZATION_DETECT_KUBERNETES If true, the agent automatically detects that it is running in Kubernetes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.16615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Instrumentation</em>",
        "body": " <em>instrumentation</em> for <em>Net</em>::HTTP. disable_rack Type Boolean Default false Environ variable NEW_RELIC_DISABLE_RACK DEPRECATED Please see: <em>instrumentation</em>.rack. If true, prevents the agent <em>from</em> hooking into the to_app method in Rack::Builder to find gems to <em>instrument</em> during application startup. disable_rack_urlmap"
      },
      "id": "603eb6f4e7b9d22a5f2f7c73"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1482,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-19T04:51:01Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.414246,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudformation-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14813,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2613,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26122,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2611,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1479,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-19T04:51:01Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.41423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    },
    {
      "sections": [
        "Amazon VPC monitoring integration",
        "Features",
        "Activate",
        "Configuration and polling",
        "Find and use data",
        "Important",
        "Metric data",
        "VPC NAT Gateway data",
        "Tip",
        "VPC VPN Tunnel",
        "Inventory data"
      ],
      "title": "Amazon VPC monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "8b5f98e1853d95d8f563d8910d02abac829976cd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration/",
      "published_at": "2021-10-19T04:51:01Z",
      "updated_at": "2021-07-09T10:28:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The Amazon Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable infrastructure of Amazon Web Services (AWS). With New Relic's VPC integration, you can gain visibility into configuration event changes that are overlaid across your Amazon services. The Amazon VPC integration generates a feed of configuration/inventory changes that occur in your VPC. VPC data is available in pre-built dashboards, and you can create custom queries and charts in New Relic One. You can also create alert conditions to notify you about changes in the VPC. Additionally, Enhanced Amazon VPC Flow Logs enables you to capture information about IP traffic to and from network interfaces in your VPC. Activate To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon VPC integration: Default New Relic polling interval: 15 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the VPC integration links. You can query and explore your data using the PrivateNetworkSample event type, with provider values of: VpcNatGateway VpcVpnTunnel Important By default, collection of VpcNatGateway, VpcVpnTunnel, and VpcVpnConnection data is disabled. This is because if you have many NAT gateways or many VPNs (connections and tunnels), it might lead to an increase on your CloudWatch bill. For this reason, the integration provides configuration settings to set whether you want to fetch that data. For more on how to use your data, see Understand integration data. Metric data VPC NAT Gateway data This integration collects the following data from PrivateNetworkSample with a provider value of VpcNatGateway: Tip For full descriptions, see Amazon VPC NAT Gateway Metrics and Dimensions. Name Description activeConnectionCount The total number of concurrent active TCP connections through the NAT gateway. bytesInFromDestination The number of bytes received by the NAT gateway from the destination. bytesInFromSource The number of bytes received by the NAT gateway from clients in your VPC. bytesOutToDestination The number of bytes sent out through the NAT gateway to the destination. bytesOutToSource The number of bytes sent through the NAT gateway to the clients in your VPC. connectionAttemptCount The number of connection attempts made through the NAT gateway. connectionEstablishedCount The number of connections established through the NAT gateway. errorPortAllocation The number of times the NAT gateway could not allocate a source port. idleTimeoutCount The number of connections that transitioned from the active state to the idle state. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds. packetsDropCount The number of packets dropped by the NAT gateway. packetsInFromDestination The number of packets received by the NAT gateway from the destination. packetsInFromSource The number of packets received by the NAT gateway from clients in your VPC. packetsOutToDestination The number of packets sent out through the NAT gateway to the destination. packetsOutToSource The number of packets sent through the NAT gateway to the clients in your VPC. VPC VPN Tunnel This integration collects the following data from PrivateNetworkSample with a provider value of VpcVpnTunnel: Tip For full descriptions, see Amazon VPC VPN Metrics and Dimensions. Name Description tunnelState The state of the tunnel. 0 indicates DOWN and 1 indicates UP. tunnelDataIn The bytes received through the VPN tunnel. Each metric data point represents the number of bytes received after the previous data point. Use the Sum statistic to show the total number of bytes received during the period. tunnelDataOut The bytes sent through the VPN tunnel. Each metric data point represents the number of bytes sent after the previous data point. Use the Sum statistic to show the total number of bytes sent during the period. Inventory data This integration reports the following VPC configuration options and metadata as inventory data. For more about inventory data, see Understand integration data. Tip Tags (indicated with an *) are only fetched when tags collection is on. Inventory category Data aws/vpc/network-interface awsRegion subnetId status sourceDestCheck requesterManaged requesterId privateIpAddress privateDnsName networkInterfaceId macAddress ipv6Addresses securityGroups description availabilityZone attachmentInstanceId attachmentDeleteOnTermination attachmentStatus attachmentInstanceOwnerId publicIp publicDnsName tags * aws/vpc/endpoint awsRegion creationTimestamp policyDocumentMd5 routeTableIds serviceName state vpcId vpcEndpointId aws/vpc/nat-gateway awsRegion natGatewayId createTime natGatewayAddresses state subnetId vpcId aws/vpc/peering-connection awsRegion vpcPeeringConnectionId accepterVpcInfo requesterVpcInfo tags * aws/vpc/vpn/connection awsRegion vpnId state type category customerGatewayConfiguration vpnGatewayId customerGatewayId staticRoutesOnly tags * aws/vpc/vpn/tunnel awsRegion acceptedRouteCount outsideIpAddress status statusChange statusMessage aws/vpc/internet-gateway region internetGatewayId attachments tags * aws/vpc/network-acl region networkAclId associations entries isDefault vpcId tags * aws/vpc/route-table region routeTableId associations propagatingVgws routes vpcId tags * aws/vpc/security-group region description groupName groupId ipPermissions ipPermissionsEgress ownerId vpcId tags * aws/vpc/subnet region availabilityZone cidrBlock defaultForAz mapPublicIpOnLaunch subnetId state vpcId tags * aws/vpc/vpc region cidrBlock dhcpOptionsId enableDnsHostname enableDnsSupport instanceTenancy isDefault state vpcId tags *",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.41423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> VPC monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>Amazon</em> VPC data to New Relic. This document explains how to activate the integration and describes the data reported. Features The <em>Amazon</em> Virtual Private Cloud (VPC) is a virtual network that utilizes the scalable"
      },
      "id": "60450763196a678c49960f68"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.06185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.2608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26077,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.1477,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.26074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS Lambda monitoring integration",
        "Important",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Function and Alias",
        "Region",
        "Inventory data",
        "aws/lambda/function/",
        "aws/lambda/alias/",
        "aws/lambda/region/",
        "aws/lambda/event-source-mapping/"
      ],
      "title": "AWS Lambda monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4b6fa324ebfd49e73ec5c2e0544864acbe5a3949",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration/",
      "published_at": "2021-10-18T04:33:59Z",
      "updated_at": "2021-10-01T18:15:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more information, see New Relic Serverless monitoring for AWS Lambda. Features AWS Lambda is a zero-administration compute platform for back-end web developers. It runs your code for you in the AWS cloud and provides you with a fine-grained pricing structure. Lambda functions are pieces of custom code that run when a certain event happens. In order to identify the events that invoke a particular Lambda function, AWS Lambda users define event source mappings. Optionally, aliases can be used to point to a specific version of a Lambda function. New Relic's AWS Lambda integration reports data such as invocation counts, error counts, function timers, and other metrics and inventory data. You can view your Lambda data in pre-built dashboards and also create custom queries and charts in New Relic One. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Important If you use custom keys to encrypt environment variables, you might start seeing KMS decryption errors in Cloudtrail console. This is because the API that is used to fetch lambdas always tries to retrieve environment variables information as part of its response. New Relic doesn't receive or store this information. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Lambda integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the Lambda integration links. You can query and explore your data using the ServerlessSample event type, with provider values of LambdaRegion , LambdaFunction and LambdaFunctionAlias. For more on how to use your data, see Understand and use integration data. Metric data This integration collects the following metrics. For more on these metrics, see Amazon's Lambda documentation. Function and Alias Lambda function and Alias data is attached to the ServerlessSample event type, with a provider value of LambdaFunction and LambdaFunctionAlias, respectively. Additionally, if you're using AWS CloudFront to execute the functions in AWS locations closer to the clients, and have enabled the filter to collect Lambda@Edge metrics, these data will be attached to the ServerlessSample event type, with a provider value of LambdaEdgeFunction. Name Description concurrentExecutions Only available for functions that have a custom concurrency limit specified. Not applicable for versions or aliases. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. deadLetterErrors Measures the number of times that a function is unable to write the failed event payload to your configured Dead Letter Queues. This could be due to one of the following: Permissions errors Throttles from downstream services Misconfigured resources Timeouts duration Measures the elapsed wall clock time in milliseconds from when the function code starts executing as a result of an invocation to when it stops executing. (This metric replaces the deprecated Latency metric.) The maximum data point value possible is the function timeout configuration. The billed duration will be rounded up to the nearest 100 milliseconds. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. edge-region The AWS region where the function is executed. Only for functions that are run by Lambda@Edge service. errors Measures the number of invocations that failed due to errors in the function (response code 4XX). This replaces the deprecated ErrorCount metric. Failed invocations may trigger a retry attempt that succeeds. This includes: Handled exceptions (for example, context.fail(error)) Unhandled exceptions causing the code to exit Out of memory exceptions Timeouts Permissions errors This does not include invocations that fail due to invocation rates exceeding default concurrent limits (error code 429) or failures due to internal service errors (error code 500). invocations Measures the number of times a function is invoked in response to an event or invocation API call. This replaces the deprecated RequestCount metric. This includes successful and failed invocations, but does not include throttled attempts. This equals the billed requests for the function. Note that AWS Lambda only sends these metrics to CloudWatch if they have a nonzero value. iteratorAge Only available for stream-based invocations (functions triggered by an Amazon DynamoDB stream or Kinesis stream). Measures the age of the last record in milliseconds for each batch of records processed. Age is the difference between the time Lambda received the batch, and the time the last record in the batch was written to the stream. throttles Measures the number of Lambda function invocation attempts that were throttled due to invocation rates exceeding the customers concurrent limits (error code 429). Failed invocations may trigger a retry attempt that succeeds. Region Lambda region data is attached to the ServerlessSample event type, with a provider value of LambdaRegion. Name Description concurrentExecutions Emitted as an aggregate metric for all functions in the account. Measures the sum of concurrent executions for a given function at a given point in time. Must be viewed as an average metric if aggregated across a time period. unreservedConcurrentExecutions Emitted as an aggregate metric for all functions in the account only. Represents the sum of the concurrency of the functions that do not have a custom concurrency limit specified. Must be viewed as an average metric if aggregated across a time period. Inventory data This integration supports the following inventory data. For more about inventory data, see Understand integration data. aws/lambda/function/ This entity describes Lambda function inventory data. For full documentation on the possible values, see Amazon's documentation for FunctionConfiguration. Name Description codeSha256 SHA256 hash of the function deployment package. codeSize The size, in bytes, of the function .zip file that was uploaded. deadLetterArn The ARN of an Amazon SQS queue or Amazon SNS topic that has been specified as the Dead Letter Queue. description The function description provided by the user. functionArn The ARN assigned to the function. functionName The name of the function. handler The function Lambda calls to begin executing the function. kmsKeyArn The KMS key used to encrypt the function's environment variables. Only returned if you've configured a customer managed CMK. lastModified The time stamp of the last time the function was updated. layers The list of ARN of the function layers. masterArn For Lambda@Edge functions, the ARN of the master function. memorySize The memory size, in MB, that was configured for the function. revisionId Represents the latest updated revision of the function or alias. role The ARN of the IAM role that Lambda assumes when it executes the function to access any other AWS resources. runtime The runtime environment for the Lambda function. timeout The function execution time at which Lambda should terminate the function. tracingMode The tracing mode associated with the Lambda function. version The version of the Lambda function. vpcId The VPC ID associated with the Lambda function. vpcSecurityGroupsIds A list of security group IDs associated with the Lambda function. vpcSubnetIds A list of subnet IDs associated with the Lambda function. aws/lambda/alias/ This entity describes Alias inventory data. Name Description aliasArn Lambda function ARN that is qualified using the alias name as the suffix. aliasName Alias name. description Alias description. functionName Function name to which the alias points. functionVersion Function version to which the alias points. revisionId A unique identifier that changes when you update the alias. routingConfig The routing configuration of the alias. aws/lambda/region/ This entity describes Lambda region inventory data. Name Description concurrentExecutions Number of simultaneous executions of a function per region. aws/lambda/event-source-mapping/ This entity describes the mapping between an event source (such as a Kinesis stream, an SQS queue, or a DynamoDB stream) and an AWS Lambda function. For full documentation on the possible values, see Amazon's documentation for EventSourceMappingConfiguration. Name Description batchSize The largest number of records that AWS Lambda will retrieve from an event source at the time of invoking the function. eventSourceArn The ARN of the Amazon Kinesis stream that is the source of events. functionArn The Lambda function to invoke when AWS Lambda detects an event on the stream. lastModified The UTC time string indicating the last time the event mapping was updated. state The state of the event source mapping. stateTransitionReason The cause of the last state change, either User initiated or Lambda initiated . uuid The AWS Lambda assigned opaque identifier for the mapping.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 147.14769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Lambda monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Lambda data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Important New Relic also offers a more in-depth Lambda monitoring feature. For more"
      },
      "id": "604505ff196a677ded960f51"
    },
    {
      "sections": [
        "AWS Billing monitoring integration",
        "Features",
        "Requirements",
        "Important",
        "Activate integration",
        "Enable AWS budgets",
        "Tip",
        "Find and use data",
        "Budgets",
        "Aggregated service costs",
        "Aggregated account/subaccount costs",
        "Unaggregated account/subaccount and AWS service costs",
        "Configuration and polling",
        "Metric data",
        "Inventory data",
        "Other system data"
      ],
      "title": "AWS Billing monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "b9e0422ba99a86027fcba8e703e583886f12db69",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration/",
      "published_at": "2021-10-18T07:31:59Z",
      "updated_at": "2021-07-15T23:42:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic's AWS Billing integration collects financial data for all your applications and AWS accounts, and then groups it to make it easier for teams to gain cost visibility. This integration collects data from different sub-accounts and services, and also evaluates your AWS budgets in terms of actual spend and forecasted spend. This financial data is split into the following dashboards: Billing (Costs) dashboard Billing (Budgets) dashboard Requirements Before you enable AWS budgets, you must: Set up an AWS budget through AWS Console for New Relic to collect AWS Billing data. Enable the Receive Billing Alerts checkbox in AWS console > Billing > Billing preferences. This is necessary for Amazon to report usage fees via CloudWatch. You are not required to actually receive alerts from Amazon. Important You only need to enable the Receive Billing Alerts checkbox to access the Billing (Costs) dashboard. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Enable AWS budgets Enabling AWS budgets allows New Relic to capture service consumptions as well as usage and costs information for the budgets you configured in AWS. Tip If you have not created a role in AWS, follow the procedure to connect AWS to New Relic before configuring a budget policy. From the AWS Management console, select Services > IAM > Roles. Select the role you have configured for New Relic, then select Permissions. From the selected role's Inline policy tab, select the expand icon if one already exists, or select the option to add a new inline policy to the role. Select the option to add a custom policy. Enter a new custom policy name; for example, NewRelicBudget. Enter the following permission statement in the Policy Document: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Save your changes. Tip If you're configuring New Relic to fetch AWS budgets data from an AWS member account, make sure that the account owner has activated IAM user access to the Billing and Cost Management console. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS Billing integration links. For general information about how to find and use integration data, see Understand integration data. Data is attached to the FinanceSample event type. That event type can have four different provider values, depending on the type of billing data: Budgets AWS service expenses Aggregated account and sub-account expenses Unaggregated account/sub-account data, and unaggregated AWS service expenses Details for these types of billing data and how to query them are below: Budgets Data from the BillingBudget provider is related to AWS budgets. This data allows you to monitor: Money spent on a budget Limits you set for each budget Forecasted expenses You can configure budgets based on usage or expense, in different currencies, or for a monthly, quarterly, or annual time period. Budgets are a great tool to monitor and control costs and take advantage of the AWS predictive model to see forecasted costs. NRQL example: For a table of different budgets with actual spend, forecast, limits, and usage vs. monetary cost, run the following NRQL query: SELECT latest(`provider.budgetType`) as 'Budget Type', max(`provider.actualAmount`) as 'Actual Amount', max(`provider.limitAmount`) as 'Budget Limit', latest(`provider.forecastedAmount`) as 'Forecast' FROM FinanceSample WHERE provider='BillingBudget' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' FACET `provider.budgetName` SINCE 1 day ago Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated service costs The data stored in the BillingServiceCost provider is aggregated for service costs containing the latest and most recent data for all AWS service costs in all registered accounts. Tip If you have configured multiple AWS accounts, New Relic recommends filtering by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by service names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Aggregated account/subaccount costs The BillingAccountCost provider stores aggregated data for account and sub-accounts containing the latest and most recent aggregate of financial data. Please bear in mind that if you have many AWS Accounts configured it is recommended to filter by each account with the attribute providerAccountName or providerAccountId. NRQL example: To group providers by account names, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.accountId` LIMIT 20 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Unaggregated account/subaccount and AWS service costs The BillingAccountServiceCost provider contains unaggregated data filterable by AWS account ID or AWS service name. NRQL example: To understand the cost split of AWS services for a particular AWS account ID, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' SINCE 1 day ago FACET `provider.serviceName` LIMIT 100 Copy NRQL example: To understand the cost split of AWS accounts for your AWS EC2 service, run the following NRQL query: SELECT latest(`provider.estimatedCharges.Maximum`) FROM FinanceSample WHERE provider='BillingAccountServiceCost' AND providerAccountId = 'NEW_RELIC_ID_FOR_YOUR_CLOUD_ACCOUNT' AND `provider.serviceName`='AmazonEC2' FACET `provider.accountId` SINCE 1 day ago LIMIT 100 Copy Tip The providerAccountId is your cloud service account ID in New Relic. You can find it in one.newrelic.com > Infrastructure > AWS, next to Provider account. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Billing integration: New Relic polling interval: 1 hour Amazon CloudWatch data interval: 4 hours Metric data The New Relic infrastructure AWS Billing integration collects the following metric data: Data Description AWS Billing metrics EstimatedCharges: The estimated charges for your AWS usage. This can either be estimated charges for one service or a rollup of estimated charges for all services. The currency is USD. AWS Budgets metrics actualAmount: The actual cost or usage being tracked by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. forecastedAmount: The forecasted cost or usage being tracked by a budget. Inventory data Inventory data provides information about the service's state and configuration. For more about inventory data, see Understand and use data. Name Description /budgets name: The name of a budget. Unique within accounts. startTime: Start date for the period of time covered by a budget. endTime: End date for the period of time covered by a budget. limitAmount: The total amount of cost or usage that you want to track with a budget as an upper limit. limitUnit: The unit of measurement used for the budget forecast, actual spend, or budget threshold, such as dollars or GB. timeUnit: The length of time until a budget resets the actual and forecasted spend. Valid values: monthly, quarterly, annually. type: Whether this budget tracks monetary cost or usage. /budgets/costFilters name: The name of a budget. Unique within accounts. Other system data The AWS Billing integration also collects the following attributes: Attributes Description AWS Billing attributes Service Name: The name of the AWS service. This dimension is omitted for the total of estimated charges across all services. Linked Account: The linked account number. AWS Budgets attributes budgetName: The name of a budget. Unique within accounts budgetType: Whether the budget tracks monetary cost or usage",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.061844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Billing monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Billing data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features New Relic&#x27;s <em>AWS</em> Billing integration collects financial data for all your"
      },
      "id": "603e841728ccbc127feba78e"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.58313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.94478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.95387,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.614044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.944695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.953865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.61404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.944695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.953865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.72297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.94461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.95386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.61403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.94461,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.61403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    },
    {
      "sections": [
        "Connect AWS GovCloud to New Relic",
        "Important",
        "Requirements",
        "How to obtain GovCloud credentials for New Relic"
      ],
      "title": "Connect AWS GovCloud to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "ab6a129f8c50643b9af1c135863572d1ab595e30",
      "image": "https://docs.newrelic.com/static/2700987e921c2d686abb7518317cc2e1/49217/AWS-add-user.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The AWS GovCloud (US) regions are designed to address the specific regulatory needs of United States (federal, state, and local agencies), education institutions, and the supporting ecosystem. It is an isolated AWS region designed to host sensitive data and regulated workloads in the cloud, helping customers support their US government compliance requirements. The available set of AWS services is a subset of the AWS ecosystem. New Relic provides you with the confidence to deploy your most critical services on GovCloud, allowing you to monitor and observe your entire ecosystem from New Relic One. Important The AWS CloudWatch metric stream capability isn't available on GovCloud regions. Requirements Requirements include: You must have your AWS account connected to New Relic before connecting GovCloud. If you're using our AWS Lambda monitoring: our newrelic-log-ingestion is not deployed in the AWS Serverless Application Repository for AWS GovCloud; it must be installed manually. For instructions, see Enable Lambda monitoring. AWS integrations supported in GovCloud: ALB/NLB API Gateway Autoscaling CloudTrail DirectConnect DynamoDB EBS EC2 Elasticsearch ELB (Classic) EMR IAM Lambda RDS Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. Obtain your credentials. Go to one.newrelic.com > Infrastructure > GovCloud. Click on Add AWS GovCloud account. Give your AWS account a name, provide the credentials to connect your account, and click Submit. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then click Save. How to obtain GovCloud credentials for New Relic From the IAM console, click Add user. For the User name, type NewRelicInfrastructure-Integrations. For Select AWS access type, select as Programmatic access. AWS IAM console > Add user: add NewRelicInfrastructure-Integrations as a user. Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Tags (adding tags is optional). Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. AWS IAM console > Add user > Set permissions: select ReadOnlyAccess. On the Tags page, click Next: Review. Review the user detail summary and click Create user. AWS IAM console > Add user > Set permissions > Tags > Review: verify that the new user information is accurate. Your user should be successfully created. Download the user security credentials by clicking on the Download .csv button and then click Close.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.72296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " Redshift Route53 S3 SNS SQS Step Functions Connect AWS GovCloud to New Relic To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. Obtain your credentials. Go to one.newrelic.com &gt; Infrastructure &gt; GovCloud. Click on Add AWS GovCloud account. Give"
      },
      "id": "603e85bc196a675469a83dcd"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "EOL NOTICE",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-10-19T04:00:55Z",
      "updated_at": "2021-10-19T04:00:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility EOL NOTICE We're discontinuing support for several capabilities in December 2021, including Kubernetes instrumentation support for versions v1.10 to v1.15. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.16 to 1.22 Kubernetes cluster GKE Currently tested with versions 1.17 to 1.19 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.16 or higher Kubernetes cluster AKS Compatible with version 1.16 or higher Kubernetes cluster OpenShift Currently tested with versions 4.6 Kubernetes cluster VMware Tanzu Compatible with VMware Tanzu (Pivotal Platform) version 2.5 to 2.11, and Ops Manager version 2.5 to 2.10 Control plane monitoring Compatible with version 1.16 or higher Service monitoring Compatible with version 1.16 or higher Requirements The New Relic Kubernetes integration has the following requirements: A New Relic account. Don't have one? Sign up for free. No credit card required. Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.8 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For detailed instructions about how to install our integration using Helm, see Manual install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.94452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.95384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.61402,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To <em>start</em> receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.566895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.583115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.58311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "03477643c0b632b9d2af95a83fa0e435d4675b18",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.523605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "603e7d6728ccbca028eba786"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56689,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.58311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.5831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56688,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.5831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "No data appears: AWS API polling integrations",
        "Problem",
        "Solution",
        "Tip"
      ],
      "title": "No data appears: AWS API polling integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "c3b24f8315e55455537a9c167b992649d8ed8abe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations/",
      "published_at": "2021-10-19T04:58:16Z",
      "updated_at": "2021-09-20T19:31:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic Infrastructure agent and then connected your Amazon account to it. After waiting a few minutes, you still do not see data for your Amazon Web Service (AWS) integrations in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don't see data after waiting for at least 10 minutes, try these troubleshooting suggestions: Make sure that the New Relic Infrastructure agent is installed and running properly. You need to install the Infrastructure agent first, and then connect to your AWS account. Tip If you see attribute names, but no data, at one.newrelic.com > Infrastructure > Events or Infrastructure > Settings > Agents, you might not have installed the Infrastructure agent. Correct any errors that you see in the Account status dashboards. Go to one.newrelic.com > Infrastructure > AWS and select the Account status dashboard for each of your accounts. If you see Role errors or Permission errors reporting, refer to Integrations and managed policies, and check that you've granted New Relic the required permissions to read the relevant data from your account. If you see other errors reporting, go to the AWS IAM console and make sure the settings for your AWS ARN match the following: Setting Value Account ID 754728514883 External ID your New Relic account ID Policy ReadOnlyAccess Make sure that you are looking in the right place for your data. You can find all integration data in the data explorer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 107.56687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears: AWS API polling <em>integrations</em>",
        "sections": "No data appears: AWS API polling <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem You installed the New Relic Infrastructure agent and then connected your <em>Amazon</em> account to it. After waiting a few minutes, you still do not see data for your <em>Amazon</em> Web Service (AWS) <em>integrations</em> in the New Relic Infrastructure UI or in New Relic Insights. Solution If you don&#x27;t see data"
      },
      "id": "603e8309e7b9d2862d2a07fb"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.5831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-10-19T04:56:15Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.62996,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    },
    {
      "sections": [
        "No data appears: AWS CloudWatch metric streams",
        "Problem",
        "Solutions",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Important",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "No data appears: AWS CloudWatch metric streams",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting",
        "CloudWatch Metric Streams"
      ],
      "external_id": "c5ddb1e7cfb5f71539d35a231363e0e7cf7a5bb9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams/",
      "published_at": "2021-10-19T04:59:12Z",
      "updated_at": "2021-09-19T15:20:35Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've followed the steps to link your AWS account, configured the AWS CloudWatch metrics stream and AWS Kinesis Data Firehose, and you still don't see the expected metrics in New Relic. Solutions No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This indicates that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal character license key. Ensure the right data center US or EU has been selected for your New Relic account. Tip: If the license_key starts with eu then you need to select the EU data center. Check that your Kinesis Data Firehose has permissions to write to the configured destination. For example, the S3 bucket policy allows to write. Missing metrics for certain AWS namespaces New Relic doesn't apply any filter on the metrics received from the AWS CloudWatch metric stream. If you're expecting certain metrics to be ingested and they aren't, verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS CloudWatch and can be queried in the AWS CloudWatch interface. For some specific AWS services, such as ECS/ EKS container insights, enhanced monitoring needs to be explicitly enabled in AWS-sdide before getting access to the metrics. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution (1 minute, 5 minutes, etc.) for every metric reported in AWS CloudWatch. AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Even if it's running, there may not be any metric data being streamed due to the configured filters. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.5831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to <em>troubleshoot</em> your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS <em>Troubleshooting</em> docs for additional details. Check"
      },
      "id": "6147554428ccbc83d356a816"
    },
    {
      "sections": [
        "Authentication issues",
        "Problem",
        "Solution",
        "Important"
      ],
      "title": "Authentication issues",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "03477643c0b632b9d2af95a83fa0e435d4675b18",
      "image": "https://docs.newrelic.com/static/5cb5abfba8e187fc0bfeb9f6e6cbff77/c1b63/aws-status.png",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/authentication-issues/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You've set up your AWS integration and connected it to New Relic, but cannot see any data in the AWS dashboard. Solution Make sure you've granted us the right permissions to retrieve your metrics. To verify so, go to the Account status dashboard of your integration to check that no errors are being reported: In the Account status dashboard, check the Permission Errors dashboard and see if you have method errors for any of your data sources: If errors are reported, make sure your permissions policy document (if it isn't the standard AWS Read-Only Access policy) has the methods reported in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all integrations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.523605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " in the errors dashboard according to our custom permissions documentation. Important Some methods are not integration specific and must be granted for all <em>integrations</em>."
      },
      "id": "603e7d6728ccbca028eba786"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/no-data-metric-streams": [
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-10-19T04:44:05Z",
      "updated_at": "2021-10-07T05:06:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 302.8164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "sections": "<em>Amazon</em> <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": " duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> (inventory telemetry is not included in the <em>stream</em>). <em>Integrations</em> not fully replaced by <em>metric</em> <em>streams</em> The AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration only collects <em>CloudWatch</em>"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data",
        "Region availability"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-10-19T04:55:09Z",
      "updated_at": "2021-09-20T19:30:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. Enabling the AWS CloudWatch Metric Streams integration is the recommended solution to monitor all CloudWatch metrics from all AWS services (including custom namespaces). On top of this, additional integrations are available to get extended visibility on key AWS services beyond the available CloudWatch metrics. For a full reference of the supported metrics, please check the available CloudWatch metrics for each service in the AWS documentation pages. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic. Additional API Polling integrations can be enabled on top of the AWS CloudWatch metric streams in order to pull data that's not available as CloudWatch metrics. The following integrations are not replaced by the metric streams: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Finally, other integrations may require additional configurations in your AWS account: AWS VPC Flow Logs AWS CloudFormation Integrations and AWS costs Keep in mind the following items: AWS CloudWatch metric streams pricing is defined based on the number of metric updates. For up-to-date pricing information check AWS CloudWatch Pricing. AWS Kinesis Data Firehose is used as the delivery method. For details, see the AWS Firehose pricing page. AWS Config can be optionally enabled in your AWS account, and used to enrich CloudWatch metrics with custom tags and resource metadata. With AWS Config, you are charged based on the number of configuration items recorded. See the AWS Config pricing page for details. If polling integrations are enabled (instead of metric streams), New Relic uses the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations. Add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. AWS offers enhanced monitoring for some of their services which allows for more metrics, more often. For example, see RDS enhanced monitoring costs. View your AWS data Once you follow the configuration process, data from your Amazon Web Services report directly to New Relic. AWS entities for most used services will be listed in the New Relic Explorer. Metrics and events will appear in the Data Explorer. AWS data will also be visible in the Infrastructure UI. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: For active streams, select the Explore your data link. OR For other integrations, browse the available dashboard or click on the Explore Data link. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions, except China.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 283.5593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. Enabling the AWS <em>CloudWatch</em> <em>Metric</em> <em>Streams</em> integration is the recommended solution to monitor all <em>CloudWatch</em> metrics from all AWS services (including custom namespaces). On top of this, additional <em>integrations</em>"
      },
      "id": "603e84ec28ccbc9dffeba789"
    },
    {
      "sections": [
        "Connect AWS to New Relic infrastructure monitoring",
        "Connect AWS to New Relic",
        "Important",
        "Connect multiple AWS integrations",
        "Connect multiple AWS accounts",
        "Add or edit custom tags",
        "Disconnect your AWS integrations",
        "Regional support"
      ],
      "title": "Connect AWS to New Relic infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "a00c91900961871b2c48d88bca610d5457473f11",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring/",
      "published_at": "2021-10-19T04:53:25Z",
      "updated_at": "2021-09-20T19:30:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To start receiving Amazon data with New Relic AWS integrations, connect your Amazon account to New Relic. If you don't have one already, create a New Relic account. It's free, forever. Connect AWS to New Relic Important AWS CloudWatch metric streams is now the recommended solution to monitor AWS services. Learn more in New Relic's CloudWatch solution and AWS CloudWatch blog posts. Follow the steps documented in the AWS CloudWatch metric stream integration to ingest all available CloudWatch metrics. To connect additional API Polling integrations: Go to one.newrelic.com > Infrastructure > AWS. Click on one of the available service tiles. From the IAM console, click Create role, then click Another AWS account. For Account ID, use 754728514883. Check the Require external ID box. For External ID, enter your New Relic account ID. Do not enable the setting to Require MFA (multi-factor authentication). Attach the Policy: Search for ReadOnlyAccess, select the checkbox for the policy named ReadOnlyAccess, then click Next: Review. Alternatively, you can create your own managed policy and limit the permissions you grant New Relic according to the AWS services you want to monitor. For the Role name, enter NewRelicInfrastructure-Integrations, then click Create role. Select the newly created role from the listed roles. On the Role summary page, select and copy the entire Role ARN (required later in this procedure). Configure a Budgets policy: While viewing the Role summary for your new role, select Add inline policy. Create a Custom policy: Enter a policy name (for example, NewRelicBudget), add the following permission statement, and then select Apply policy. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"budgets:ViewBudget\" ], \"Resource\": \"*\" } ] } Copy Return to the New Relic UI to enter your AWS account name and the ARN for the new role. Select the Amazon Web Services to be monitored with New Relic infrastructure integrations, then Save. Connect multiple AWS integrations To connect multiple AWS integrations to a single New Relic account: If you previously set up an ARN with the more restrictive AmazonEC2ReadOnlyAccess policy, first unlink your existing integration, then create a new one with a broader policy. Follow the instructions to connect your Amazon account to New Relic . Provide the ARN that contains the ReadOnlyAccess policy. Once setup is complete, select the integrations you want to monitor: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Select the checkbox for each integration you want to monitor. Connect multiple AWS accounts By default, the Amazon EC2 AmazonEC2ReadOnlyAccess permission grants New Relic access to all EC2 instances in the individual Amazon account you specify during the setup steps. If you have multiple AWS accounts, follow the steps to connect an AWS account for each AWS account you want to associate with New Relic. Add or edit custom tags New Relic automatically imports custom tags you have added or edited for your AWS resources. Most metrics received via CloudWatch metric streams will have custom tags as dimensions. For API Polling integrations, if you don't see any tags in the Add filter menu of the Filter sets sidebar within a few minutes, delete the integration and try again: Go to one.newrelic.com > Infrastructure > AWS. Select the edit icon. Remove individual integrations or the entire account linkage as needed. Note that not all integrations support tags collection. You can enable (and disable) tags collection in the integration settings. Disconnect your AWS integrations You can disable one or more integrations anytime and still keep your AWS account connected to New Relic. However, New Relic recommends that you do not disable EC2 or EBS monitoring. These two integrations add important metadata to your EC2 instances and EBS volumes in New Relic. To uninstall your services completely from New Relic infrastructure Integrations, unlink your AWS account. Regional support China regions are not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.8271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Connect multiple AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "To start receiving <em>Amazon</em> data with New Relic AWS <em>integrations</em>, connect your <em>Amazon</em> account to New Relic. If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Connect AWS to New Relic Important AWS <em>CloudWatch</em> <em>metric</em> <em>streams</em> is now the recommended solution to monitor AWS"
      },
      "id": "6045079f196a679cc1960f2d"
    }
  ]
}