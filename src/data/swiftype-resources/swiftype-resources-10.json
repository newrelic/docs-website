{
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range": [
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-06-25T18:27:53Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.37148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-06-25T20:15:08Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.36606,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-06-25T20:04:17Z",
      "updated_at": "2021-03-09T04:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.07094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-06-25T20:15:08Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "he events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.02469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-06-25T18:27:53Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.37148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-06-25T20:04:17Z",
      "updated_at": "2021-03-09T04:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.07094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs": [
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-06-25T18:21:33Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and wont be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.41013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-06-25T18:21:33Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 175.4046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-25T20:02:01Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.45947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-25T20:02:01Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.55801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-25T20:03:03Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you dont want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.51076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-06-26T14:03:52Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: New Relic APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/https-proxy-configuration-missing": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-25T20:02:01Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.55801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-25T20:03:03Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you dont want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.51076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-25T20:16:18Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported": [
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-25T20:03:03Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you dont want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.51076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-25T20:16:18Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-06-26T14:03:52Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: New Relic APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-25T20:02:01Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.55801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-25T20:16:18Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    },
    {
      "sections": [
        "No data appears (Infrastructure)",
        "Problem",
        "Solution",
        "Important",
        "Missing infrastructure data",
        "Verify install for apt (Debian or Ubuntu)",
        "Verify install for yum (Amazon Linux, CentOS, or RHEL)",
        "Verify install for Windows Server",
        "Verify status with SystemD",
        "Verify status with System V",
        "Verify status with Upstart",
        "Verify status with Windows",
        "Missing integration data"
      ],
      "title": "No data appears (Infrastructure)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "fd618376814a1ec7b486c00e524b0203bbfa0e09",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure/",
      "published_at": "2021-06-26T14:03:52Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed the New Relic infrastructure agent and waited a few minutes, but no data appears in the Infrastructure UI. Solution Data should appear in the Infrastructure monitoring UI within a few minutes for accounts with previously installed agents. Important For accounts installing the infrastructure agent for the first time, the latency for data appearing in the Infrastructure monitoring UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, monitor the Infrastructure UI for a longer period before contacting support.newrelic.com for assistance. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Missing infrastructure data If no data appears in the UI, try the following steps to diagnose the problem: Use your package manager to verify that the infrastructure agent is installed: Verify install for apt (Debian or Ubuntu) Use dpkg to verify that the agent is installed: dpkg -l | grep newrelic-infra Copy If dpkg returns no output, see Install with apt. Verify install for yum (Amazon Linux, CentOS, or RHEL) Use rpm to verify that agent is installed: rpm -qa | grep newrelic-infra Copy If rpm returns no output, see Install with yum. Verify install for Windows Server Use the Windows command prompt or Powershell to verify that the agent directory exists: dir \"C:\\Program Files\\New Relic\\newrelic-infra\" Copy If you receive a File not found error, see Install for Windows Server. Use your init system to verify that the agent is running: Verify status with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: Check that the agent is running: sudo systemctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo systemctl start newrelic-infra Copy Verify status with System V Use System V commands with Debian 7: Check that the agent is running: sudo /etc/init.d/newrelic-infra status Copy If the agent isn't running, start the agent manually: sudo /etc/init.d/newrelic-infra start Copy Verify status with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: Check that the agent is running: sudo initctl status newrelic-infra Copy If the agent isn't running, start the agent manually: sudo initctl start newrelic-infra Copy Verify status with Windows Use the Windows command prompt: Check that the agent is running: sc query \"newrelic-infra\" | find \"RUNNING\" Copy If the agent isn't running, start the agent manually with the Windows command prompt: net start newrelic-infra Copy If running net start newrelic-infra returns The service name is invalid, the Infrastructure agent may not have been installed correctly and the service was not properly created. To test this: From Powershell, run the command get-service newrelic-infra, which will return the status of the service. If it returns an error Cannot find any service with service name newrelic-infra, then follow standard procedures to reinstall the agent. Use New Relic Diagnostics to try to automatically identify the issue. Verify that your newrelic-infra.yml configuration file contains a valid license_key setting. Verify that the host has a unique hostname, and verify that the hostname is not localhost. For more information, see this Explorers Hub post. Verify that no firewalls or proxies are blocking outbound connections from the agent process to the Infrastructure domains and ports. Confirm the host is reporting correctly even though it is not appearing in the Infrastructure monitoring UI by creating a basic query in Insights, like: SELECT * FROM SystemSample SINCE 60 minutes ago LIMIT 100 Copy Use the query results to note the timestamps, which show when the data was reported. To determine when data was first received, look at the earliest timestamp. Generate verbose logs and examine the logs for errors. Missing integration data If you are missing data from an integration, see troubleshooting procedures for: New Relic APM data missing from infrastructure monitoring Amazon/AWS integrations On-host integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Infrastructure</em>)",
        "sections": "No data appears (<em>Infrastructure</em>)",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " the <em>infrastructure</em> agent for the first time, the latency for data appearing in the <em>Infrastructure</em> <em>monitoring</em> UI can be tens of minutes. If the following steps verify the installation and no obvious error conditions appear in the verbose logs, <em>monitor</em> the <em>Infrastructure</em> UI for a longer period before"
      },
      "id": "603e90b9e7b9d26d8c2a07a9"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/troubleshooting/time-gaps-missing-data": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-25T20:02:01Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.55801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-25T20:03:03Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you dont want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.51076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-25T20:16:18Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.50464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/insights-usage-ui-page": [
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-06-26T14:38:25Z",
      "updated_at": "2021-06-26T14:38:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in Mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The Mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the Mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.392746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "Mobile monitoring <em>UI</em>",
        "body": " and attributes View legacy HTTP errors <em>UI</em> <em>page</em> Accounts that do not have an Enterprise-level subscription see a different HTTP Errors <em>UI</em> <em>page</em>: The Errors <em>page</em> includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed"
      },
      "id": "603e8eb428ccbcd174eba791"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Tip",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-06-25T16:56:59Z",
      "updated_at": "2021-06-20T02:16:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If youre on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Tip To use our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, defined as users with access to Full Stack Observability features. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, ingested refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, its not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, thats counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. More user-related billing details: You can see your full user count in the UI. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. For organizations on our original account/user model that have a master/sub-account structure, the count of billable users in the UI may differ from the list of users you see. For more on this, see User count discrepancy. A user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. The Standard edition of the New Relic One pricing plan includes one free full user. Users with duplicate email addresses are only counted once. For organizations on our original user model, a user may be set as a basic user in one account, and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition for Full Stack Observability, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise Full Stack Observability editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If youre a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 99.12314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Billing and <em>usage</em> in the <em>UI</em>",
        "body": "&#x27;s included for free, see Free edition. For an overview of pricing, see our Pricing <em>page</em>. Keep reading for details about New Relic One pricing and billing. Billing and <em>usage</em> in the <em>UI</em> For how to view and manage billing and <em>usage</em> in the <em>UI</em>, see Pricing and billing <em>UI</em>. If you need more detail than the <em>usage</em> <em>UI</em>"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount thats free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so theyre not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you dont need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.72951,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " of the content in the <em>UI</em> is variable, depending on your account. This information is intended to help you understand how we&#x27;re working with your ingest data. The chart on the Data ingestion <em>page</em> shows data <em>usage</em> for a little longer time frame than that covered by your retention settings for each data ingest"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/instrument-errors-c-sdk": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/c-sdk-release-notes/c-sdk-100/",
      "sections": [
        "C SDK v1.0.0",
        "New Features",
        "End of Life Notice"
      ],
      "published_at": "2021-06-25T22:36:09Z",
      "title": "C SDK v1.0.0",
      "updated_at": "2021-03-16T12:13:41Z",
      "type": "docs",
      "external_id": "bc68847dddf3b5226d442626a141c3090bbb2809",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "New Features This is the first release of the New Relic C SDK! If your application does not use other New Relic APM agent languages, you can use the C SDK to take advantage of New Relic's monitoring capabilities and features to instrument a wide range of applications. For more information, see: Documentation: How to get started with the C SDK, install and configure it, instrument transactions, segments, and errors, use the C SDK API, and do some basic troubleshooting. GitHub: SDK files, data structure, field definitions and parameters, code examples, functions, variables. End of Life Notice The previous APM Agent SDK is deprecated beta software. If you were previously using the Agent SDK, you can switch to the C SDK. Check the compatibility and requirements, and then instrument, compile and link your application's code to use the C SDK. The C SDK currently does not support New Relic's HSM feature; this may impact how you schedule your transition away from the Agent SDK.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 837.9007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> v1.0.0",
        "sections": "<em>C</em> <em>SDK</em> v1.0.0",
        "body": ": Documentation: How to get started with the <em>C</em> <em>SDK</em>, install and configure it, <em>instrument</em> transactions, segments, and <em>errors</em>, use the <em>C</em> <em>SDK</em> API, and do some basic troubleshooting. GitHub: <em>SDK</em> files, data structure, field definitions and parameters, code examples, functions, variables. End of Life Notice"
      },
      "id": "603ec0fae7b9d223882a07b9"
    },
    {
      "sections": [
        "Instrument your app with the C SDK",
        "Instrument a transaction",
        "Instrument segments",
        "Instrument calls to external services",
        "Instrument calls to arbitrary code (custom segments)",
        "Instrument calls to datastores",
        "Tip",
        "Report slow query traces for datastore segments (SQL only)",
        "Important",
        "Instrument errors",
        "Avoid metric grouping issues"
      ],
      "title": "Instrument your app with the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "dc21642bac9d779820a40eea8601434c4242f425",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/c-sdk/instrumentation/instrument-your-app-c-sdk/",
      "published_at": "2021-06-25T16:42:04Z",
      "updated_at": "2021-03-16T13:43:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to monitor any application on Linux using a language that can import C libraries, you must: Create a config using newrelic_new_app_config(), connect to the daemon using newrelic_init(), and connect your application using newrelic_create_app(). For more information, see the C SDK installation procedures. Manually instrument transactions using the C SDK, as described in this document. New Relic defines a web or non-web transaction as one logical unit of work in a software application. After you manually instrument transactions in your source code by adding New Relic functions, you can view the data on the Transactions page in New Relic. You can also instrument segments of a transaction and errors. Instrument a transaction To instrument a transaction so you can monitor it, wrap the New Relic functions that start and stop instrumentation around the transaction. The function that you use depends on whether you want to instrument a web or non-web transaction. In the following example, the app is created after a call to newrelic_create_app(). For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Add the following code immediately before the transaction that you want to monitor, supplying the required parameters. For web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy For non-web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_non_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy Add newrelic_end_transaction() immediately after the web or non-web transaction that you want to monitor, supplying a pointer the transaction, &txn, as a parameter. Instrument segments Once you instrument a transaction using the C SDK, you can instrument segments in it. By instrumenting segments, you can monitor the individual functions and calls inside a transaction. Segments example You have a transaction associated with a checkout process, which processes both shipping information and credit card information. You can instrument your application to break that transaction up into two segments: one segment for shipping and one segment for payment. You can instrument segments to monitor the following kinds of calls: External services using external segments Custom segments for arbitrary code Datastores using datastore segments Slow query traces (SQL databases only) For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to external services To monitor calls to external services, instrument external segments that are within an instrumented transaction. External segments appear in the Transactions page's Breakdown table and the External services page. To instrument an external segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_external_segment_params_t that describes the external segment, supplying the required parameters. Add newrelic_start_external_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to arbitrary code (custom segments) To monitor calls to arbitrary code, instrument custom segments that are within an instrumented transaction. Custom segments appear in the Breakdown table on the Transactions page. To instrument a custom segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Add newrelic_start_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to datastores To monitor calls to datastores, instrument the datastore segments within an instrumented transaction. Datastore segments appear in the Breakdown table and Databases tab on the Transactions page in New Relic. You can also view datastore segments as a databaseDuration attribute of APM Transaction events. To instrument a datastore segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_datastore_segment_params_t that describes the datastore segment. Add newrelic_start_datastore_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Tip To configure how the database name and database instance are reported, use the newrelic_datastore_segment_config_t. Report slow query traces for datastore segments (SQL only) Important You can report slow query traces for SQL databases only. To report slow query trace data for datastore segments that take longer than the time you specify, enable these settings in your newrelic_app_config_t: Enable slow query tracing by setting transaction_tracer.datastore_reporting.enabled to true. To set the threshold, add a length of time in microseconds to transaction_tracer.datastore_reporting.threshold_us. Then, if a datastore call takes longer than the threshold, the C SDK reports it as a slow query. To view slow query trace details, use the Databases and Slow queries pages in New Relic. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument errors In order to use the C SDK to monitor errors in transactions, you must manually instrument your source code by adding the newrelic_notice_error() function to it. Transaction errors and error traces appear on the Error analytics page in New Relic. The C SDK reports the total number of errors and up to 100 error traces per minute. You can also view, query, and visualize transaction errors as APM TransactionError events. Tip To include function calls in error traces, use GNU's -rdynamic linker flag to link your apps when compiling. The -rdynamic linker flag gives you more meaningful error traces. To instrument errors in transactions: Start a transaction. Record an error with newrelic_notice_error(), supplying the required parameters. End the transaction, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Avoid metric grouping issues When an account or application sends many individual metrics that could be better managed in groups, New Relic uses the term metric grouping issue or MGI to describe this situation. If your application sends unnecessarily large amounts of data to New Relic, this reduces the effectiveness of charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. To help prevent this situation, see Metric grouping issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 373.5001,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> your app <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "sections": "<em>Instrument</em> your app <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>C</em> <em>SDK</em>",
        "body": " the <em>C</em> <em>SDK</em> installation procedures as well as the <em>C</em> <em>SDK</em> libnewrelic.h documentation on GitHub. <em>Instrument</em> <em>errors</em> In order to use the <em>C</em> <em>SDK</em> to monitor <em>errors</em> in transactions, you must manually <em>instrument</em> your source code by adding the newrelic_notice_<em>error</em>() function to it. Transaction <em>errors</em> and <em>error</em>"
      },
      "id": "603ec08fe7b9d229232a0810"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/instrument-transactions-c-sdk/",
      "sections": [
        "Instrument transactions with the C SDK",
        "Contents",
        "Instrument a transaction",
        "Instrument segments and errors",
        "For more help"
      ],
      "published_at": "2021-06-25T15:59:42Z",
      "title": "Instrument transactions with the C SDK",
      "updated_at": "2021-03-13T01:07:13Z",
      "type": "docs",
      "external_id": "ae7079cba195e3b79ead057e230e0c2693a090df",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument transactions using the C SDK so you can monitor any application on Linux that uses a language that can import C libraries. After you manually instrument transactions in your source code by adding New Relic functions, you can view the data on the Transactions page in the New Relic UI. Contents For an index of documentation during the private Beta, see the C SDK table of contents. Instrument a transaction To instrument a transaction so you can monitor it in the New Relic UI, wrap the New Relic functions that start and stop instrumentation around the transaction. The function that you use depends on whether you want to instrument a web or non-web transaction. Add the following code immediately before the transaction that you want to monitor: For web transactions: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy For non-web transactions: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_non_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy Add the following code immediately after the web or non-web transaction that you want to monitor: newrelic_end_transaction(&txn); Copy Instrument segments and errors Segments are the functions and calls that make up a transaction. After you instrument transactions, you can: Instrument segments of a transaction if you want more data about functions called during that transaction. Instrument errors so that you can use the New Relic UI to monitor errors that occur during your transactions. For more help Beta support for the C SDK is being handled through New Relic's Explorers Hub in a private group. If you need access to the support group, contact Jodee Varney (Product Manager) at jvarney@newrelic.com. Normal support channels will re-route you to the community or the Product Manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.49518,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> transactions <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "sections": "<em>Instrument</em> transactions <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "body": "<em>Instrument</em> transactions using the <em>C</em> <em>SDK</em> so you can monitor any application on Linux that uses a language that can import <em>C</em> libraries. After you manually <em>instrument</em> transactions in your source code by adding New Relic functions, you can view the data on the Transactions page in the New Relic UI"
      },
      "id": "6043bac3e7b9d2ff4d579a08"
    }
  ],
  "/docs/instrument-transactions-c-sdk": [
    {
      "sections": [
        "Instrument your app with the C SDK",
        "Instrument a transaction",
        "Instrument segments",
        "Instrument calls to external services",
        "Instrument calls to arbitrary code (custom segments)",
        "Instrument calls to datastores",
        "Tip",
        "Report slow query traces for datastore segments (SQL only)",
        "Important",
        "Instrument errors",
        "Avoid metric grouping issues"
      ],
      "title": "Instrument your app with the C SDK",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "dc21642bac9d779820a40eea8601434c4242f425",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/c-sdk/instrumentation/instrument-your-app-c-sdk/",
      "published_at": "2021-06-25T16:42:04Z",
      "updated_at": "2021-03-16T13:43:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to monitor any application on Linux using a language that can import C libraries, you must: Create a config using newrelic_new_app_config(), connect to the daemon using newrelic_init(), and connect your application using newrelic_create_app(). For more information, see the C SDK installation procedures. Manually instrument transactions using the C SDK, as described in this document. New Relic defines a web or non-web transaction as one logical unit of work in a software application. After you manually instrument transactions in your source code by adding New Relic functions, you can view the data on the Transactions page in New Relic. You can also instrument segments of a transaction and errors. Instrument a transaction To instrument a transaction so you can monitor it, wrap the New Relic functions that start and stop instrumentation around the transaction. The function that you use depends on whether you want to instrument a web or non-web transaction. In the following example, the app is created after a call to newrelic_create_app(). For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Add the following code immediately before the transaction that you want to monitor, supplying the required parameters. For web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy For non-web transactions: // Example code: newrelic_txn_t *txn; /* ... */ txn = newrelic_start_non_web_transaction(app, \"NAME_YOUR_TRANSACTION\"); Copy Add newrelic_end_transaction() immediately after the web or non-web transaction that you want to monitor, supplying a pointer the transaction, &txn, as a parameter. Instrument segments Once you instrument a transaction using the C SDK, you can instrument segments in it. By instrumenting segments, you can monitor the individual functions and calls inside a transaction. Segments example You have a transaction associated with a checkout process, which processes both shipping information and credit card information. You can instrument your application to break that transaction up into two segments: one segment for shipping and one segment for payment. You can instrument segments to monitor the following kinds of calls: External services using external segments Custom segments for arbitrary code Datastores using datastore segments Slow query traces (SQL databases only) For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to external services To monitor calls to external services, instrument external segments that are within an instrumented transaction. External segments appear in the Transactions page's Breakdown table and the External services page. To instrument an external segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_external_segment_params_t that describes the external segment, supplying the required parameters. Add newrelic_start_external_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to arbitrary code (custom segments) To monitor calls to arbitrary code, instrument custom segments that are within an instrumented transaction. Custom segments appear in the Breakdown table on the Transactions page. To instrument a custom segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Add newrelic_start_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument calls to datastores To monitor calls to datastores, instrument the datastore segments within an instrumented transaction. Datastore segments appear in the Breakdown table and Databases tab on the Transactions page in New Relic. You can also view datastore segments as a databaseDuration attribute of APM Transaction events. To instrument a datastore segment, wrap the New Relic functions that start and stop instrumentation around the function you want to monitor: Instrument a transaction. Create a newrelic_datastore_segment_params_t that describes the datastore segment. Add newrelic_start_datastore_segment() immediately before the function you want to monitor, supplying the required parameters. Add newrelic_end_segment() immediately after the function you want to monitor, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Tip To configure how the database name and database instance are reported, use the newrelic_datastore_segment_config_t. Report slow query traces for datastore segments (SQL only) Important You can report slow query traces for SQL databases only. To report slow query trace data for datastore segments that take longer than the time you specify, enable these settings in your newrelic_app_config_t: Enable slow query tracing by setting transaction_tracer.datastore_reporting.enabled to true. To set the threshold, add a length of time in microseconds to transaction_tracer.datastore_reporting.threshold_us. Then, if a datastore call takes longer than the threshold, the C SDK reports it as a slow query. To view slow query trace details, use the Databases and Slow queries pages in New Relic. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Instrument errors In order to use the C SDK to monitor errors in transactions, you must manually instrument your source code by adding the newrelic_notice_error() function to it. Transaction errors and error traces appear on the Error analytics page in New Relic. The C SDK reports the total number of errors and up to 100 error traces per minute. You can also view, query, and visualize transaction errors as APM TransactionError events. Tip To include function calls in error traces, use GNU's -rdynamic linker flag to link your apps when compiling. The -rdynamic linker flag gives you more meaningful error traces. To instrument errors in transactions: Start a transaction. Record an error with newrelic_notice_error(), supplying the required parameters. End the transaction, supplying the required parameters. For more information, see the C SDK installation procedures as well as the C SDK libnewrelic.h documentation on GitHub. Avoid metric grouping issues When an account or application sends many individual metrics that could be better managed in groups, New Relic uses the term metric grouping issue or MGI to describe this situation. If your application sends unnecessarily large amounts of data to New Relic, this reduces the effectiveness of charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. To help prevent this situation, see Metric grouping issues.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 924.4789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Instrument</em> your app <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "sections": "<em>Instrument</em> your app <em>with</em> <em>the</em> <em>C</em> <em>SDK</em>",
        "tags": "<em>C</em> <em>SDK</em>",
        "body": " installation procedures. Manually <em>instrument</em> <em>transactions</em> using the <em>C</em> <em>SDK</em>, as described in this document. New Relic defines a web or non-web transaction as one logical unit of work in a software application. After you manually <em>instrument</em> <em>transactions</em> in your source code by adding New Relic functions, you can"
      },
      "id": "603ec08fe7b9d229232a0810"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/c-sdk-release-notes/c-sdk-100/",
      "sections": [
        "C SDK v1.0.0",
        "New Features",
        "End of Life Notice"
      ],
      "published_at": "2021-06-25T22:36:09Z",
      "title": "C SDK v1.0.0",
      "updated_at": "2021-03-16T12:13:41Z",
      "type": "docs",
      "external_id": "bc68847dddf3b5226d442626a141c3090bbb2809",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "New Features This is the first release of the New Relic C SDK! If your application does not use other New Relic APM agent languages, you can use the C SDK to take advantage of New Relic's monitoring capabilities and features to instrument a wide range of applications. For more information, see: Documentation: How to get started with the C SDK, install and configure it, instrument transactions, segments, and errors, use the C SDK API, and do some basic troubleshooting. GitHub: SDK files, data structure, field definitions and parameters, code examples, functions, variables. End of Life Notice The previous APM Agent SDK is deprecated beta software. If you were previously using the Agent SDK, you can switch to the C SDK. Check the compatibility and requirements, and then instrument, compile and link your application's code to use the C SDK. The C SDK currently does not support New Relic's HSM feature; this may impact how you schedule your transition away from the Agent SDK.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 864.3879,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>C</em> <em>SDK</em> v1.0.0",
        "sections": "<em>C</em> <em>SDK</em> v1.0.0",
        "body": ": Documentation: How to get started with the <em>C</em> <em>SDK</em>, install and configure it, <em>instrument</em> <em>transactions</em>, segments, and errors, use the <em>C</em> <em>SDK</em> API, and do some basic troubleshooting. GitHub: <em>SDK</em> files, data structure, field definitions and parameters, code examples, functions, variables. End of Life Notice"
      },
      "id": "603ec0fae7b9d223882a07b9"
    },
    {
      "sections": [
        "Guide to using the C SDK API",
        "Ensure your customization is thread-safe",
        "Monitor transactions",
        "Time specific methods using segments",
        "Enhance the metadata of a transaction",
        "Instrument calls to external services",
        "Collect or log errors",
        "Send custom data from your app",
        "Custom events",
        "Tip",
        "Custom event attributes",
        "Custom metrics",
        "Important",
        "Monitor desktop browser performance",
        "Change configuration settings"
      ],
      "title": "Guide to using the C SDK API",
      "type": "docs",
      "tags": [
        "Agents",
        "C SDK",
        "Instrumentation"
      ],
      "external_id": "fd96697be408715e6330a91b237c5fb6b5042bce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/c-sdk/instrumentation/guide-using-c-sdk-api/",
      "published_at": "2021-06-25T16:41:09Z",
      "updated_at": "2021-03-16T09:07:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's C SDK monitors your applications and microservices to help you identify and solve performance issues. C applications run from a compiled, native binary file. In order to monitor transactions, you must manually instrument your code by adding New Relic methods to it. This guide helps you to decide which method to use. The method's code, required parameters, and examples reside in New Relic's C SDK documentation on GitHub. Ensure your customization is thread-safe The C SDK supports instrumentation of multi-threaded applications, but it must be initialized before instrumenting multiple threads. When calling any of the following functions, ensure that they are called on the main thread before any other C SDK functions are called: newrelic_configure_log newrelic_init Monitor transactions Before you manually instrument your code to monitor transactions: Check the C SDK compatibility and requirements for your app. Make sure you are using the latest version of the C SDK library, and update as needed. If you want to... Use this method... Start timing a web transaction newrelic_start_web_transaction() Start timing a non-web transaction newrelic_start_non_web_transaction() Stop timing a transaction newrelic_end_transaction() Prevent a transaction from reporting to New Relic newrelic_ignore_transaction() Time specific methods using segments If a transaction is already visible in New Relic, but you do not have enough data about a particular method that was called during that transaction, you can instrument segments. For example, if you want to time a method that has complex logic, you can create a segment for each of the methods in the transaction. To instrument a method within an existing transaction, create segments for any of the following: External services Functions or other arbitrary blocks of code (using custom segments) Datastores Slow query traces (SQL datastores only) If you want to... Use this method... Start timing a segment newrelic_start_datastore_segment()newrelic_start_external_segment()newrelic_start_segment() Stop timing a segment newrelic_end_segment() Manually parent segments newrelic_set_segment_parent() and newrelic_set_segment_parent_root() This is useful, for example, with an asynchronous process when you want to visualize a segment as a child of the transaction's top-level call. For more information, see the manual segment parenting documentation on GitHub. Segments are recorded on the active transaction. When adding a segment to an active transaction, you need access to the newrelic_txn_t* or transaction pointer, returned by newrelic_start_web_transaction() or newrelic_start_non_web_transaction(). Enhance the metadata of a transaction You can manage the metadata that New Relic reports for transactions. This is useful when you want a different level of detail for your transactions. For example: If you are experiencing a metric grouping issue, you can change the default names for your transactions to make them more identifiable. If you want to create dashboards for your transactions, you can add custom attributes. If you want to... Use this method... Add metadata (such as your customer's account name or subscription level) to your transaction Add custom attributes to your transaction based on their type: newrelic_add_attribute_int() newrelic_add_attribute_string() newrelic_add_attribute_long() newrelic_add_attribute_double() Instrument calls to external services Use these methods to collect data about your app's connections to other apps or databases: If you want to... Use this method... See the path that a request takes as it travels through a distributed system Follow the procedures to enable and instrument distributed tracing. Time a call to an external resource (such as an external service, database server, or message queue) Follow the procedures to Instrument calls to external segments. Collect or log errors The C SDK detects errors automatically. If you want to change the way it reports errors to New Relic, change the error collector configuration. If you want to... Use this method... Set logging levels for your app Use newrelic_configure_log() to configure the C SDK logs and command-line flags to configure the C daemon logs. For more information, see the C SDK logging documentation. Report an error newrelic_notice_error() Send custom data from your app To record custom data with the C SDK, you can use any of the following methods: Custom events: At New Relic, event data is a fundamental data type. Event data represents a record of a single event at a particular moment in time. This is useful to view or query specific details. Custom event attributes: To include additional metadata about the event, you can add key/value pairs (custom-attributes) to your custom event. Custom metrics: Metric timeslice data is the statistical measure of data that New Relic aggregates so that you can view it in the UI and chart it. Typically metric data has a longer retention period than event data. Custom events The C SDK provides a custom events API that allows you to send custom events to New Relic. To send an event, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For example: // txn is a newrelic_txn_t*, created via newrelic_start_web_transaction newrelic_custom_event_t* custom_event=0; custom_event = newrelic_create_custom_event(\"aTypeForYourEvent\"); newrelic_record_custom_event(txn, &custom_event); Copy Be sure to review the custom data requirements and limits for guidance on what values are and are not allowed inside your custom event. For more information, see Custom events in APM. Tip If you created a custom event but need to remove it before the transaction has ended, use newrelic_discard_custom_event(&custom_event);. Custom event attributes You can also add int, long, double, and char* (string) attributes to your custom event by using the newrelic_custom_event_add_* family of functions. For example: // Example custom attributes: newrelic_custom_event_t* custom_event=0; custom_event = newrelic_create_custom_event(\"aTypeForYourEvent\"); newrelic_custom_event_add_attribute_int(custom_event, \"keya\", 42); newrelic_custom_event_add_attribute_long(custom_event, \"keyb\", 84); newrelic_custom_event_add_attribute_double(custom_event, \"keyc\", 42.42); newrelic_custom_event_add_attribute_string(custom_event, \"keyd\", \"A string\"); newrelic_record_custom_event(txn, &custom_event); Copy For more information, see the documentation about custom attributes. Custom metrics The C SDK provides the newrelic_record_custom_metric() function. This allows you to record time-based performance data using an API call, such as: Transaction timing data Computer resource data Subscription or purchasing data To create a custom metric, provide a name or other identifier and an amount of time in milliseconds to the function, along with the active transaction. Important Always prefix custom metric names with Custom/. For example: // txn is a newrelic_txn_t*, created via newrelic_start_web_transaction // Record a metric value of 100ms in the transaction txn newrelic_record_custom_metric(txn, \"Custom/MyMetric/My_label\", 100); Copy For more information, see Collect custom metrics. Here are some ways to use your custom data. For code details and examples for these options, see the New Relic globals documentation on GitHub. If you want to... Use this method... Create a custom event to populate with a timestamp and attributes. newrelic_create_custom_event() Timestamp and add the custom event to the current transaction so you can query or visualize it. newrelic_record_custom_event() Enhance your custom event with additional metadata. Add custom event attributes to your custom event based on type: newrelic_custom_event_add_attribute_double() newrelic_custom_event_add_attribute_int() newrelic_custom_event_add_attribute_long() newrelic_custom_event_add_attribute_string() Discard a custom event after it was created, but before its transaction has ended, to avoid reporting it to New Relic. newrelic_discard_custom_event This is necessary to free the allocated memory for your unwanted custom event in order to avoid leaks in your program. Report a custom performance duration that you can search or chart. newrelic_record_custom_metric() Monitor desktop browser performance To monitor desktop browser performance for your application, install the browser agent using the copy/paste method. Change configuration settings Typically the default settings for your application's configuration do not need to be changed. However, when necessary, you can adjust some of the settings. For more information, see the C SDK configuration documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.31128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Guide to using <em>the</em> <em>C</em> <em>SDK</em> API",
        "sections": "Guide to using <em>the</em> <em>C</em> <em>SDK</em> API",
        "tags": "<em>C</em> <em>SDK</em>",
        "body": "New Relic&#x27;s <em>C</em> <em>SDK</em> monitors your applications and microservices to help you identify and solve performance issues. <em>C</em> applications run from a compiled, native binary file. In order to monitor <em>transactions</em>, you must manually <em>instrument</em> your code by adding New Relic methods to it. This guide helps you"
      },
      "id": "603ec04928ccbc252beba785"
    }
  ],
  "/docs/instrumentation-editor-instrument-net-ui": [
    {
      "sections": [
        "Custom instrumentation editor: Instrument from UI",
        "Requirements",
        "Define custom instrumentation",
        "Caution",
        "Manual instrumentation using the editor",
        "Important",
        "Deploy changes manually",
        "Page functions",
        "Instrumentation options",
        "Results with \"start\" option"
      ],
      "title": "Custom instrumentation editor: Instrument from UI",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Custom instrumentation"
      ],
      "external_id": "979a3d068ba665b13e8e9e18c432356286d61248",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/custom-instrumentation/custom-instrumentation-editor-instrument-ui/",
      "published_at": "2021-06-25T16:40:04Z",
      "updated_at": "2021-03-16T02:40:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's custom instrumentation editor allows Java app users to implement custom instrumentation via the New Relic user interface. The editor is the preferred choice when you cannot modify your application code and don't have that many methods to instrument. See Java custom instrumentation for other instrumentation options and the reasons for using each. To use the custom instrumentation editor: Go to one.newrelic.com > APM > (select a Java app) > Settings > Instrumentation. Use the custom instrumentation editor to: Instrument an unsupported framework. Gain additional insight into uninstrumented methods. Ignore particular transactions. Requirements To use the custom instrumentation editor, you must meet the following requirements: Requirement Comments Agent Java agent version 3.17.0 or higher Security Users of high security mode must export their instrumentation and manually import it to their app server. Define custom instrumentation To define custom instrumentation from the New Relic user interface, use a thread profiling session to collect detailed stack traces of each thread in your application. If possible, test your custom instrumentation in a pre-production environment before changing the instrumentation rules in your production app. In either environment, use the custom instrumentation editor to define the methods you want instrumented, and apply your changes: Create a new thread profiler session. To ensure you collect sufficient data, set the length of the session to at least two minutes. Go to one.newrelic.com > APM > (select an app) > Settings > Instrumentation. Scroll down to the bottom of the page until you see the Recently collected thread profiles list, then select the most recent thread profile. Expand individual methods to locate uninstrumented methods. To define instrumentation rules for particular nodes, select Instrument or Ignore, and customize the rules if necessary. To save your settings, select Confirm instrumentation changes. Deploy your changes from the Instrumentation page: To deploy your changes automatically, select Deploy instrumentation changes. To deploy your changes manually, select Export XML, and see exporting your instrumentation. Caution Avoid over-instrumenting whenever possible. With each additional method that is instrumented, the agent will be using more resources and your application will incur more overhead. In addition, deploying your instrumentation will cause a brief period of higher overhead. This can noticeably slow application requests for several seconds. If you applied your changes from the UI, the agent will begin instrumenting your methods within a few harvest cycles (typically a few minutes). Manual instrumentation using the editor You can also create instrumentation points directly in the editor without using a thread profile: From the custom instrumentation editor, select Add manual instrumentation to manually enter a class and method to be instrumented or ignored. Follow the custom instrumentation by XML rules when defining your instrumentation points. Deploy your changes from the instrumentation editor. Using this method to add instrumentation exposes additional functionality beyond what is available from a thread profile. In addition to matching methods by signature, you can also instrument methods by return type, methods on interfaces, and by Java annotation. These more complex instrumentation types can be created and deleted in the editor, but not edited. Important If a method is marked Instrumentation not allowed, follow New Relic's troubleshooting procedures for custom instrumentation. Deploy changes manually You can also use the custom instrumentation editor to build a custom instrumentation set, then export an instrumentation file and manually import it to your app server. This is required for users of high security mode. To export your instrumentation, define custom instrumentation via the UI. Then select Export xml from the Instrumentation page, and import the file on your app server. Page functions The Instrumentation page supports the following features: If you want to... Do this... Pause or disable custom instrumentation Select Disable instrumentation to temporarily disable all UI-defined custom instrumentation. Select Enable instrumentation to re-enable your instrumentation settings. Import existing instrumentation You can import an existing custom instrumentation xml file by selecting Import xml. You can also Export xml if you do not want to deploy your changes automatically. Edit or delete instrumentation points You cannot edit manual instrumentation, only delete it. Select Remove to stop instrumenting a particular method. Select Edit to change the instrumentation rules. View instrumentation history You can view each previous iteration of your custom instrumentation from the Instrumentation history tab, including who deployed changes and when. You can restore an old version by selecting export to download a copy of the custom instrumentation file, then importing it to the instrumentation editor. Instrumentation options You can define the following options with the custom instrumentation editor: Instrumentation options Comments Instrument methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic UI. Instrument supports the following child options: Name the transaction (transaction name): Override the standard transaction name, defined by the automatic naming rules. The UI will instead use the listed name. Start the transaction when this method executes: Rather than including metrics from this metric inside its parent transaction, create a new transaction for this method. Agent behavior with this option depends on whether there is a pre-existing transaction on the thread. Report custom attributes Method parameters can be captured as attributes on a transaction. New Relic reports these attributes to transaction traces, traced errors, and New Relic One Transaction events. For security reasons, capturing custom attributes using the Custom Instrumentation Editor is disabled by default and cannot be enabled while you are using high security mode. If you want to report custom attributes using the custom instrumentation editor and you do not want the Java agent to be in High security mode, disable High security mode and then add the following text in the common: block of your newrelic.yml: reinstrument: attributes_enabled: true Copy Ignore transactions Ignore this method entirely. The agent will not report metrics from this method, and the method will not contribute to Apdex calculations. Results with \"start\" option If you select Instrument methods > Start the transaction when this method executes, agent behavior depends on whether there is a pre-existing transaction on the thread. When the class or method is instrumented: Is the \"Start the transaction\" flag checked? Yes No If a pre-existing transaction is on that thread and the Start the transaction flag is checked: The agent ignores the Start the transaction flag. The agent includes the class/method into the pre-existing transaction. If a pre-existing transaction is on that thread and the Start the transaction flag is not checked, the agent includes the class/method into the pre-existing transaction. If a transaction is not on that thread and the Start the transaction flag is checked: The agent discovers there is no current transaction. The agent creates a new transaction starting with the class/method you have instrumented. If a transaction is not on that thread and the Start the transaction flag is not checked: The agent looks for a transaction on that thread and does not find one. The metric is dropped.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.94916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "sections": "Custom <em>instrumentation</em> <em>editor</em>: <em>Instrument</em> <em>from</em> <em>UI</em>",
        "tags": "Custom <em>instrumentation</em>",
        "body": " define the following options with the custom <em>instrumentation</em> <em>editor</em>: <em>Instrumentation</em> options Comments <em>Instrument</em> methods Begin instrumenting the selected method. Instrumented methods will be visible in the New Relic <em>UI</em>. <em>Instrument</em> supports the following child options: Name the transaction (transaction"
      },
      "id": "603ed428e7b9d2b9b52a07e6"
    },
    {
      "sections": [
        "Java custom instrumentation",
        "Important",
        "When to choose custom instrumentation",
        "Implement custom instrumentation"
      ],
      "title": "Java custom instrumentation",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Custom instrumentation"
      ],
      "external_id": "76fd78e33105744dc4c6342d8059b2b966f90196",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/custom-instrumentation/java-custom-instrumentation/",
      "published_at": "2021-06-26T07:44:25Z",
      "updated_at": "2021-03-16T09:00:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "APM for Java will typically produce useful performance data automatically. However, if New Relic does not support your framework, or if you want to set up additional monitoring, you will want to implement custom instrumentation. Custom instrumentation allows you to track interactions that aren't captured by New Relic's automatic instrumentation, and lets you add detail to your transaction traces, to help you identify key issues. New Relic collects metrics and events from many frameworks automatically. If you are using a supported framework or component, you may see some transaction information out of the box, and custom instrumentation can be used to supplement the information the Agent reports by default. Important If you are using a supported framework, but are not seeing transactions, get support at support.newrelic.com to ensure the framework instrumentation is working. When to choose custom instrumentation Choose custom instrumentation in these situations: New Relic does not support your framework and transactions do not appear in the UI You would like to add detail to your transaction traces Transaction traces include large blocks of application code time without sufficient detail Implement custom instrumentation You can implement custom instrumentation with one of these methods: Method Description The New Relic UI New Relic for Java includes an option in the UI for custom instrumentation called the Custom Instrumentation Editor. This option doesn't require any direct modification of your application code, so is a good choice if you don't want to or can't modify your code. The editor is, however, fairly limited in functionality compared to the Java agent API. API annotation Using the New Relic Java agent API, you can annotate the methods in your application code that you want to monitor. The annotation method is robust and easy to troubleshoot. If you are willing to modify your source code, annotation is the recommended method. If you have many methods you want to instrument, you might prefer XML instrumentation. For more about the API and its other functions, see Intro to the Java agent API. XML If you can't modify your code, or if you need to instrument many methods, XML instrumentation is the best custom instrumentation method. With this method, you specify the classes you want to instrument in an external XML file. While XML instrumentation is powerful, it is also more difficult to use than the other instrumentation methods. For simpler instrumentation needs, New Relic recommends annotation or instrumentation via the UI. For more information, see Java instrumentation by XML. You can also monitor Java Management Extensions (JMX) via custom instrumentation. JMX is a way to monitor and manage applications, devices, and services. You can implement JMX monitoring via an external YAML file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.86891,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java custom <em>instrumentation</em>",
        "sections": "Java custom <em>instrumentation</em>",
        "tags": "Custom <em>instrumentation</em>",
        "body": " detail Implement custom <em>instrumentation</em> You can implement custom <em>instrumentation</em> with one of these methods: Method Description The New Relic <em>UI</em> New Relic for Java includes an option in the <em>UI</em> for custom <em>instrumentation</em> called the Custom <em>Instrumentation</em> <em>Editor</em>. This option doesn&#x27;t require any direct"
      },
      "id": "603eb6b6196a67b753a83db7"
    },
    {
      "sections": [
        ".NET agent reports handled errors",
        "Problem",
        "Solution",
        "GetResponse() throws an error",
        "Define a custom instrumentation file",
        "Wrap the method in a custom transaction",
        "Cause"
      ],
      "title": ".NET agent reports handled errors",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Troubleshooting"
      ],
      "external_id": "5cd50fdec02b9d8e48348c183e786eac54c312e8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/troubleshooting/net-agent-reports-handled-errors/",
      "published_at": "2021-06-25T16:58:56Z",
      "updated_at": "2021-04-29T00:18:04Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem New Relic's .NET agent reports handled errors as though they are standard errors. This is most common with Azure worker roles, console apps, async work, and similar operations. Solution To avoid false error reports, instrument a method that directly or indirectly contains the exception handler. Instrument the target method by defining a custom instrumentation file, or by wrapping the method in a custom transaction, as shown in this example: GetResponse() throws an error In this example, New Relic reports an error from GetResponse() unless the method Foo() is instrumented. As long is Foo is instrumented, New Relic begins a transaction when Foo is called and ends the transaction when Foo ends. Because the error is handled before Foo ends, New Relic will not report an error. Note also that GetResponse() becomes a segment of the Foo transaction. using System; using System.Collections.Generic; using System.Threading; using System.Threading.Tasks; using System.Net; using System.IO; namespace ErrorTester { class Program { static void Main(string[] args) { var i = 0; while (true) { Foo(++i); } } static void Foo(int i) { try { GetNotFound(); } catch (Exception ex) { Console.WriteLine(\"Got it \" + i + \"!\"); Thread.Sleep(1000); } } static string GetNotFound() { string uri = \"http://localhost/Test/this/is/not/a/real/page\"; var request = (HttpWebRequest)WebRequest.Create(uri); var response = request.GetResponse(); var data = new StreamReader(response.GetResponseStream()).ReadToEnd(); response.Close(); return data; } } } Copy Define a custom instrumentation file To instrument Foo: Define a custom instrumentation file; for example, CustomInstrumentation.xml: <?xml version=\"1.0\" encoding=\"utf-8\"?> <!--  2008-2014 New Relic, Inc. All rights reserved. --> <!-- When you edit this file, please use an XML aware editor (such as Visual Studio), and pair with the companion file extension.xsd to minimize the chance of introducing typos that may confuse the agent when it is run. --> <extension xmlns=\"urn:newrelic-extension\"> <instrumentation> <tracerFactory > <match assemblyName=\"ErrorTester\" className=\"ErrorTester.Program\"> <exactMethodMatcher methodName=\"Foo\" /> </match> </tracerFactory> </instrumentation> </extension> Copy Place CustomInstrumenation.xml in the New Relic extensions folder, alongside CoreInstrumentation.xml, and restart your application. Wrap the method in a custom transaction To instrument Foo, wrap it in a custom transaction: <extension xmlns=\"urn:newrelic-extension\"> <instrumentation> <tracerFactory name=\"NewRelic.Agent.Core.Tracer.Factories.BackgroundThreadTracerFactory\" metricName=\"Background/Task\"> <match assemblyName=\"ErrorTester\" className=\"ErrorTester.Program\"> <exactMethodMatcher methodName=\"Foo\" /> </match> </tracerFactory> </instrumentation> </extension> Copy Cause The only errors New Relic's .NET agent reports are unhandled errors that end a transaction. If your app calls an exception handler before the transaction ends, New Relic will not report an error. However, New Relic does not always detect exception handlers when the error occurs outside of a web transaction, WCF transaction, or custom transaction. This is because the agent creates \"mini-transactions\" for instrumented methods that are not associated with a transaction. When the instrumented method exits, the mini-transaction ends. If the mini-transaction throws an error and the instrumented method does not handle it, then New Relic will report an error. You can see this in a console app that calls GetResponse(), as shown in the example. If GetResponse throws an error, then New Relic will report it, even though GetResponse() is called within a try/catch block. The agent reports an error because the GetResponse() \"mini-transaction\" ended and the error was still unhandled on transaction exit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.96215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".<em>NET</em> agent reports handled errors",
        "sections": ".<em>NET</em> agent reports handled errors",
        "tags": "<em>NET</em> agent",
        "body": " handler. <em>Instrument</em> the target method by defining a custom <em>instrumentation</em> file, or by wrapping the method in a custom transaction, as shown in this example: GetResponse() throws an error In this example, New Relic reports an error <em>from</em> GetResponse() unless the method Foo() is instrumented. As long"
      },
      "id": "603e910028ccbcc7c0eba7b4"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-cognito-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26341,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-sqs-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26341,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/amazon-transit-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.7641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.7641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48746,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26335,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4874,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76396,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.33475,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-athena-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-auto-scaling-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26323,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-billing-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudformation-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26317,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudfront-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-cloudtrail-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48721,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2631,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-connect-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-direct-connect-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76337,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-documentdb-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76321,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-dynamodb-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76321,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ebs-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48701,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ec2-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48701,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26292,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-ecsecr-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76291,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-efs-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76291,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elastic-beanstalk-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticache-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.33444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26274,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediaconvert-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26274,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-elemental-mediapackage-vod-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48676,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-emr-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-fsx-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-glue-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration": [
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.33435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with <em>AWS</em> to collect performance metrics and metadata for more than 50 <em>AWS</em> services. With the new <em>AWS</em> Metric Streams integration, you only need a single service, <em>AWS</em> CloudWatch, to gather all <em>AWS</em> metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iam-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76202,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-iot-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76202,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.2625,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-analytics-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-firehose-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48651,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-kinesis-data-streams-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-lambda-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-managed-kafka-msk-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48639,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26231,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48639,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26231,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-mq-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-neptune-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-qldb-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-enhanced-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-rds-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48627,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-redshift-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.4862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26213,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route-53-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-route53-resolver-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48615,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-s3-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26201,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-simple-email-service-ses-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26201,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-sns-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-step-functions-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-trusted-advisor-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26195,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-flow-logs-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-vpc-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-waf-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26183,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/aws-x-ray-monitoring-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.76024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Health monitoring <em>integration</em>",
        "sections": "<em>AWS</em> Health monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your <em>AWS</em> Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from <em>AWS</em> Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "AWS AppSync monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "AppSync Api data"
      ],
      "title": "AWS AppSync monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "0ea2f07ae74c1b4184b647164010bd152ad53cb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-appsync-monitoring-integration/",
      "published_at": "2021-06-25T18:22:25Z",
      "updated_at": "2021-06-20T20:54:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your AWS AppSync data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS AppSync integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select an integration. You can query and explore your data using this event type: Entity Event Type Provider Api AwsAppSyncApiSample AwsAppSyncApi For more on how to use your data, see New Relic data types. Metric data This integration collects AWS AppSync data for Api. AppSync Api data Metric Unit Description 4XXError Count The number of errors captured as a result of invalid requests due to incorrect client configuration. Typically, these errors happen anywhere outside of the GraphQL execution. For example, this could be an incorrect JSON payload or an incorrect query in the request, when the service is throttled, or even a potential misconfiguration on the Auth settings. 5XXError Count Errors encountered during the execution of a GraphQL query. For example, this could occur when a query request is initiated for an empty or incorrect schema, if the Amazon Cognito user pool ID or AWS Region is invalid. Alternatively, this could also happen if AWS AppSync encounters an issue during an execution of a request. Latency Milliseconds The time between when AWS AppSync receives a request from a client and when it returns a response to the client. This doesn't include the network latency encountered for a response to reach the end devices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.48581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "sections": "<em>AWS</em> AppSync monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": " and polling You can change the polling frequency and filter data using configuration options. Default polling information for the <em>AWS</em> AppSync integration: New Relic polling interval: 5 minutes <em>Amazon</em> CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure"
      },
      "id": "603eaf99196a67d294a83dbf"
    },
    {
      "sections": [
        "Amazon Elasticsearch monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Configuration",
        "eBSOptions",
        "snapshotOptions",
        "elasticsearchClusterConfig"
      ],
      "title": "Amazon Elasticsearch monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "66a8a74032ef636e2f8646447174aadf280d7b60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elasticsearch-monitoring-integration/",
      "published_at": "2021-06-26T14:04:48Z",
      "updated_at": "2021-06-20T15:26:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting Amazon Elasticsearch data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features Amazon Elasticsearch Service is a fully managed service that delivers Elasticsearchs easy-to-use APIs and real-time capabilities along with the availability, scalability, and security required by production workloads. New Relic's Elasticsearch monitoring integration allows you to track cluster status, CPU utilization, read/write latency, throughput, and other metrics, at specific points in time. Elasticsearch data is also available to query, analyze, and chart your data. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon Elasticsearch integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the Elasticsearch integration links. To query and explore your data, use the DatastoreSample event type with the appropriate provider value: ElasticsearchCluster for clusters ElasticsearchNode for nodes Metric data The Elasticsearch integration collects these metrics for clusters: Name Relevant statistics Description ClusterStatus.green Minimum, Maximum Indicates that all index shards are allocated to nodes in the cluster. ClusterStatus.yellow Minimum, Maximum Indicates that the primary shards for all indices are allocated to nodes in a cluster, but the replica shards for at least one index are not. Single node clusters always initialize with this cluster status because there is no second node to which a replica can be assigned. You can either increase your node count to obtain a green cluster status, or you can use the Amazon ES API to set the number_of_replicas setting for your index to 0. For more information, see Amazon's documentation for Updating indices settings. ClusterStatus.red Minimum, Maximum Indicates that the primary and replica shards of at least one index are not allocated to nodes in a cluster. For more information, see Amazon's documentation on Red Cluster Status. Nodes Minimum, Maximum, Average The number of nodes in the Amazon ES cluster. SearchableDocuments Minimum, Maximum, Average The total number of searchable documents across all indices in the cluster. DeletedDocuments Minimum, Maximum, Average The total number of deleted documents across all indices in the cluster. CPUUtilization Minimum, Maximum, Average The maximum percentage of CPU resources used for data nodes in the cluster. FreeStorageSpace Minimum The free space, in megabytes, for all data nodes in the cluster. ClusterUsedSpace Minimum, Maximum The total used space, in megabytes, for a cluster. ClusterIndexWritesBlocked Maximum Indicates whether your cluster is accepting or blocking incoming write requests. A value of 0 means that the cluster is accepting requests. A value of 1 means that it is blocking requests. JVMMemoryPressure Maximum The maximum percentage of the Java heap used for all data nodes in the cluster. AutomatedSnapshotFailure Minimum, Maximum The number of failed automated snapshots for the cluster. A value of 1 indicates that no automated snapshot was taken for the domain in the previous 36 hours. CPUCreditBalance Minimum The remaining CPU credits available for data nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metrics is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. KibanaHealthyNodes Minimum A health check for Kibana. A value of 1 indicates normal behavior. A value of 0 indicates that Kibana is inaccessible. In most cases, the health of Kibana mirrors the health of the cluster. KMSKeyError Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been disabled. To restore the domain to normal operations, re-enable the key. KMSKeyInaccessible Minimum, Maximum A value of 1 indicates that the KMS customer master key used to encrypt data at rest has been deleted or revoked its grants to Amazon ES. You can't recover domains that are in this state. If you have a manual snapshot, though, you can use it to migrate the domain's data to a new domain. InvalidHostHeaderRequests Sum The number of HTTP requests made to the Elasticsearch cluster that included an invalid (or missing) host header. ElasticsearchRequests Sum The number of requests made to the Elasticsearch cluster. RequestCount Sum The number of requests to a domain and the HTTP response code (2xx, 3xx, 4xx, 5xx) for each request. MasterCPUUtilization Average The maximum percentage of CPU resources used by the dedicated master nodes. We recommend increasing the size of the instance type when this metric reaches 60 percent. MasterJVMMemoryPressure Maximum The maximum percentage of the Java heap used for all dedicated master nodes in the cluster. We recommend moving to a larger instance type when this metric reaches 85 percent. MasterCPUCreditBalance Minimum The remaining CPU credits available for dedicated master nodes in the cluster. A CPU credit provides the performance of a full CPU core for one minute. This metric is available only for the t2.micro.elasticsearch, t2.small.elasticsearch, and t2.medium.elasticsearch instance types. MasterReachableFromNode Minimum A health check for MasterNotDiscovered exceptions. A value of 1 indicates normal behavior. A value of 0 indicates that /_cluster/health/ is failing. Failures mean that the master node stopped or is not reachable. They are usually the result of a network connectivity issue or AWS dependency problem. ReadLatency Minimum, Maximum, Average The latency, in seconds, for read operations on EBS volumes. WriteLatency Minimum, Maximum, Average The latency, in seconds, for write operations on EBS volumes. ReadThroughput Minimum, Maximum, Average The throughput, in bytes per second, for read operations on EBS volumes. WriteThroughput Minimum, Maximum, Average The throughput, in bytes per second, for write operations on EBS volumes. DiskQueueDepth Minimum, Maximum, Average The number of pending input and output (I/O) requests for an EBS volume. ReadIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for read operations on EBS volumes. WriteIOPS Minimum, Maximum, Average The number of input and output (I/O) operations per second for write operations on EBS volumes. The following metrics are collected for Elasticsearch clusters, and optionally for each instance or node in a domain as well: Name Relevant statistics Description IndexingLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete an indexing operation. IndexingRate For nodes: Average For clusters: Average, Maximum, Sum The number of indexing operations per minute. SearchLatency For nodes: Average For clusters: Average, Maximum The average time, in milliseconds, that it takes a shard to complete a search operation. SearchRate For nodes: Average For clusters: Average, Maximum, Sum The total number of search requests per minute for all shards on a node. SysMemoryUtilization Minimum, Maximum, Average The percentage of the instance's memory that is in use. JVMGCYoungCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"young generation\" garbage collection has run. A large, ever-growing number of runs is a normal part of cluster operations. JVMGCYoungCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"young generation\" garbage collection. JVMGCOldCollectionCount For nodes: Maximum For clusters: Sum, Maximum, Average The number of times that \"old generation\" garbage collection has run. In a cluster with sufficient resources, this number should remain small and grow infrequently. JVMGCOldCollectionTime For nodes: Maximum For clusters: Sum, Maximum, Average The amount of time, in milliseconds, that the cluster has spent performing \"old generation\" garbage collection. ThreadpoolForce_mergeQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the force merge thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolForce_mergeRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the force merge thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolForce_mergeThreads For nodes: Maximum For clusters: Sum, Average The size of the force merge thread pool. ThreadpoolIndexQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the index thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum index queue size is 200. ThreadpoolIndexRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the index thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolIndexThreads For nodes: Maximum For clusters: Sum, Average The size of the index thread pool. ThreadpoolSearchQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the search thread pool. If the queue size is consistently high, consider scaling your cluster. The maximum search queue size is 1000. ThreadpoolSearchRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the search thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolSearchThreads For nodes: Maximum For clusters: Sum, Average The size of the search thread pool. ThreadpoolBulkQueue For nodes: Maximum For clusters: Sum, Maximum, Average The number of queued tasks in the bulk thread pool. If the queue size is consistently high, consider scaling your cluster. ThreadpoolBulkRejected For nodes: Maximum For clusters: Sum The number of rejected tasks in the bulk thread pool. If this number continually grows, consider scaling your cluster. ThreadpoolBulkThreads For nodes: Maximum For clusters: Sum, Average The size of the bulk thread pool. Inventory data The integration collects this ElasticSearch data as inventory data. Configuration The integration collects this data from aws/elasticsearch/cluster/config: Inventory Description aRN The Amazon resource name (ARN) of an Elasticsearch domain. accessPolicies The IAM access policy. created The domain creation status. True if the creation of an Elasticsearch domain is complete. False if domain creation is still in progress. deleted The domain deletion status. True if a delete request has been received for the domain but resource cleanup is still in progress. False if the domain has not been deleted. domainId The unique identifier for the specified Elasticsearch domain. domainName Name of the Elasticsearch domain. elasticsearchVersion Elasticsearch version. endpoint The Elasticsearch domain endpoint that you use to submit index and search requests. processing The status of the Elasticsearch domain configuration. True if Amazon Elasticsearch Service is processing configuration changes. False if the configuration is active. upgradeProcessing The status of an Elasticsearch domain version upgrade. True if Amazon Elasticsearch Service is undergoing a version upgrade. False if the configuration is active. eBSOptions The integration collects this data from aws/elasticsearch/cluster/config/eBSOptions: Name Description eBSEnabled Specifies whether EBS-based storage is enabled. iops Specifies the IOPD for a Provisioned IOPS EBS volume (SSD). volumeSize Integer to specify the size of an EBS volume. volumeType Specifies the volume type for EBS-based storage. snapshotOptions The integration collects this data from aws/elasticsearch/cluster/config/snapshotOptions: Name Description automatedSnapshotStartHour Specifies the time, in UTC format, when the service takes a daily automated snapshot of the specified Elasticsearch domain. elasticsearchClusterConfig The integration collects this data from aws/elasticsearch/cluster/config/elasticsearchClusterConfig: Name Description dedicatedMasterCount Total number of dedicated master nodes, active and on standby, for the cluster. dedicatedMasterEnabled A boolean value to indicate whether a dedicated master node is enabled. dedicatedMasterType The instance type for a dedicated master node. instanceCount The number of instances in the specified domain cluster. instanceType The instance type for an Elasticsearch cluster. zoneAwarenessEnabled A boolean value to indicate whether zone awareness is enabled.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 181.26176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "sections": "<em>Amazon</em> Elasticsearch monitoring <em>integration</em>",
        "tags": "<em>AWS</em> <em>integrations</em> <em>list</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting <em>Amazon</em> Elasticsearch data to New Relic. This document explains the integration&#x27;s features, how to activate it, and what data can be reported. Features <em>Amazon</em> Elasticsearch Service is a fully managed service that delivers"
      },
      "id": "603ea15d196a67aa5ba83dc9"
    }
  ],
  "/docs/integrations/amazon-integrations/aws-integrations-list/rate-limit-alerts-amazon": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.22934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/aws-integrations-metrics": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.23936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-05-09T17:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.6871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-govcloud-new-relic": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.23936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-05-09T17:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.6871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/connect-aws-new-relic-infrastructure-monitoring": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.23927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-05-09T17:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.6871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/integrations-managed-policies": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98663,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.23927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Introduction to AWS integrations",
        "Tip",
        "Region availability",
        "Connect AWS and New Relic",
        "Integrations and AWS costs",
        "View your AWS data"
      ],
      "title": "Introduction to AWS integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "26a36d0da0ba98b48ccaff2e574ec4e535e68844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations/",
      "published_at": "2021-06-25T23:50:09Z",
      "updated_at": "2021-03-16T05:37:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon integrations let you monitor your AWS data in several New Relic features. To see the features of specific integrations and the data you can collect, see the AWS integrations list. Tip To use Amazon integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Region availability Most AWS services offer regional endpoints to reduce data latency between cloud resources and applications. New Relic can obtain monitoring data from services and endpoints that are located in all AWS regions except from China regions. Connect AWS and New Relic In order to obtain AWS data, follow the procedure to connect AWS to New Relic, or learn more about the types of integration data that New Relic receives. The New Relic AWS integration also supports seamless deployments of your workloads using AWS Outposts. Integrations and AWS costs New Relic integrations use the Amazon CloudWatch API to obtain metrics from the AWS services you monitor. The number of calls to the CloudWatch API increases as you enable more integrations, add AWS resources to those integrations, or scale those integrations across more regions. This can cause requests to the CloudWatch API to exceed the 1 million free limits granted by AWS and increase your CloudWatch bill. View your AWS data Once you follow the configuration process, data from your Amazon Web Services will report directly to New Relic. AWS data will also be visible in the Infrastructure UI. However, unlike standard New Relic dashboards, pre-configured integrations dashboards can't be edited. To view your AWS data: Go to one.newrelic.com > Infrastructure > AWS. For any of the AWS integrations listed: Select an integration name to view data. OR Select the Explore data icon to view AWS data. You can view and reuse NRQL queries both in the pre-configured dashboards and in the Events explorer dashboards. This allows you to tailor queries to your specific needs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.61809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to AWS <em>integrations</em>",
        "sections": "Introduction to AWS <em>integrations</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "<em>Amazon</em> <em>integrations</em> let you monitor your AWS data in several New Relic features. To see the features of specific <em>integrations</em> and the data you can collect, see the AWS <em>integrations</em> list. Tip To use <em>Amazon</em> <em>integrations</em> and the rest of our observability platform, join the New Relic family! Sign up"
      },
      "id": "603e84ec28ccbc9dffeba789"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/introduction-aws-integrations": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.2392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-05-09T17:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.687096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/get-started/polling-intervals-aws-integrations": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if youre looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You wont have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and therell be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes youre monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free  we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relics Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.98654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Prometheus OpenMetrics <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " to <em>get</em> <em>started</em>, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics <em>integrations</em> gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.2392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Integrations and managed policies",
        "Recommended policy",
        "Important",
        "Optional policy",
        "Option 1: Use our CloudFormation template",
        "CloudFormation template",
        "Option 2: Manually add permissions",
        "Required by all integrations",
        "ALB permissions",
        "API Gateway permissions",
        "Auto Scaling permissions",
        "Billing permission",
        "Cloudfront permissions",
        "CloudTrail permissions",
        "DynamoDB permissions",
        "EBS permissions",
        "EC2 permissions",
        "ECS/ECR permissions",
        "EFS permissions",
        "ElastiCache permissions",
        "ElasticSearch permissions",
        "Elastic Beanstalk permissions",
        "ELB permissions",
        "EMR permissions",
        "Health permissions",
        "IAM permissions",
        "IoT permissions",
        "Kinesis Firehose permissions",
        "Kinesis Streams permissions",
        "Lambda permissions",
        "RDS, RDS Enhanced Monitoring permissions",
        "Redshift permissions",
        "Route 53 permissions",
        "S3 permissions",
        "Simple Email Service (SES) permissions",
        "SNS permissions",
        "SQS permissions",
        "Trusted Advisor permissions",
        "VPC permissions",
        "X-Ray monitoring permissions"
      ],
      "title": "Integrations and managed policies",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Get started"
      ],
      "external_id": "80e215e7b2ba382de1b7ea758ee1b1f0a1e3c7df",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/get-started/integrations-managed-policies/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-05-09T17:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to use infrastructure integrations, you need to grant New Relic permission to read the relevant data from your account. Amazon Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed policy from AWS. AWS automatically updates this policy when new services are added or existing services are modified. New Relic infrastructure integrations have been designed to function with ReadOnlyAccess policies. For instructions, see Connect AWS integrations to infrastructure. Exception: The Trusted Advisor integration is not covered by the ReadOnlyAccess policy. It requires the additional AWSSupportAccess managed policy. This is also the only integration that requires full access permissions (support:*) in order to correctly operate. We notified Amazon about this limitation. Once it's resolved we'll update documentation with more specific permissions required for this integration. Optional policy If you cannot use the ReadOnlyAccess managed policy from AWS, you can create your own customized policy based on the list of permissions. This allows you to specify the optimal permissions required to fetch data from AWS for each integration. While this option is available, it is not recommended because it must be manually updated when you add or modify your integrations. Important New Relic has no way of identifying problems related to custom permissions. If you choose to create a custom policy, it is your responsibility to maintain it and ensure proper data is being collected. There are two ways to set up your customized policy: You can either use our CloudFormation template, or create own yourself by adding the permissions you need. Option 1: Use our CloudFormation template Our CloudFormation template contains all the permissions for all our AWS integrations. A user different than root can be used in the managed policy. CloudFormation template AWSTemplateFormatVersion: 2010-09-09 Outputs: NewRelicRoleArn: Description: NewRelicRole to monitor AWS Lambda Value: !GetAtt - NewRelicIntegrationsTemplate - Arn Parameters: NewRelicAccountNumber: Type: String Description: The Newrelic account number to send data AllowedPattern: '[0-9]+' Resources: NewRelicIntegrationsTemplate: Type: 'AWS::IAM::Role' Properties: RoleName: !Sub NewRelicTemplateTest AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: AWS: !Sub 'arn:aws:iam::754728514883:root' Action: 'sts:AssumeRole' Condition: StringEquals: 'sts:ExternalId': !Ref NewRelicAccountNumber Policies: - PolicyName: NewRelicIntegrations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticloadbalancing:DescribeTargetGroups' - 'elasticloadbalancing:DescribeTags' - 'elasticloadbalancing:DescribeLoadBalancerAttributes' - 'elasticloadbalancing:DescribeListeners' - 'elasticloadbalancing:DescribeRules' - 'elasticloadbalancing:DescribeTargetGroupAttributes' - 'elasticloadbalancing:DescribeInstanceHealth' - 'elasticloadbalancing:DescribeLoadBalancerPolicies' - 'elasticloadbalancing:DescribeLoadBalancerPolicyTypes' - 'apigateway:GET' - 'apigateway:HEAD' - 'apigateway:OPTIONS' - 'autoscaling:DescribeLaunchConfigurations' - 'autoscaling:DescribeAutoScalingGroups' - 'autoscaling:DescribePolicies' - 'autoscaling:DescribeTags' - 'autoscaling:DescribeAccountLimits' - 'budgets:ViewBudget' - 'cloudfront:ListDistributions' - 'cloudfront:ListStreamingDistributions' - 'cloudfront:ListTagsForResource' - 'cloudtrail:LookupEvents' - 'config:BatchGetResourceConfig' - 'config:ListDiscoveredResources' - 'dynamodb:DescribeLimits' - 'dynamodb:ListTables' - 'dynamodb:DescribeTable' - 'dynamodb:ListGlobalTables' - 'dynamodb:DescribeGlobalTable' - 'dynamodb:ListTagsOfResource' - 'ec2:DescribeVolumeStatus' - 'ec2:DescribeVolumes' - 'ec2:DescribeVolumeAttribute' - 'ec2:DescribeInstanceStatus' - 'ec2:DescribeInstances' - 'ec2:DescribeVpnConnections' - 'ecs:ListServices' - 'ecs:DescribeServices' - 'ecs:DescribeClusters' - 'ecs:ListClusters' - 'ecs:ListTagsForResource' - 'ecs:ListContainerInstances' - 'ecs:DescribeContainerInstances' - 'elasticfilesystem:DescribeMountTargets' - 'elasticfilesystem:DescribeFileSystems' - 'elasticache:DescribeCacheClusters' - 'elasticache:ListTagsForResource' - 'es:ListDomainNames' - 'es:DescribeElasticsearchDomain' - 'es:DescribeElasticsearchDomains' - 'es:ListTags' - 'elasticbeanstalk:DescribeEnvironments' - 'elasticbeanstalk:DescribeInstancesHealth' - 'elasticbeanstalk:DescribeConfigurationSettings' - 'elasticloadbalancing:DescribeLoadBalancers' - 'elasticmapreduce:ListInstances' - 'elasticmapreduce:ListClusters' - 'elasticmapreduce:DescribeCluster' - 'elasticmapreduce:ListInstanceGroups' - 'health:DescribeAffectedEntities' - 'health:DescribeEventDetails' - 'health:DescribeEvents' - 'iam:ListSAMLProviders' - 'iam:ListOpenIDConnectProviders' - 'iam:ListServerCertificates' - 'iam:GetAccountAuthorizationDetails' - 'iam:ListVirtualMFADevices' - 'iam:GetAccountSummary' - 'iot:ListTopicRules' - 'iot:GetTopicRule' - 'iot:ListThings' - 'firehose:DescribeDeliveryStream' - 'firehose:ListDeliveryStreams' - 'kinesis:ListStreams' - 'kinesis:DescribeStream' - 'kinesis:ListTagsForStream' - 'rds:ListTagsForResource' - 'rds:DescribeDBInstances' - 'rds:DescribeDBClusters' - 'redshift:DescribeClusters' - 'redshift:DescribeClusterParameters' - 'route53:ListHealthChecks' - 'route53:GetHostedZone' - 'route53:ListHostedZones' - 'route53:ListResourceRecordSets' - 'route53:ListTagsForResources' - 's3:GetLifecycleConfiguration' - 's3:GetBucketTagging' - 's3:ListAllMyBuckets' - 's3:GetBucketWebsite' - 's3:GetBucketLogging' - 's3:GetBucketCORS' - 's3:GetBucketVersioning' - 's3:GetBucketAcl' - 's3:GetBucketNotification' - 's3:GetBucketPolicy' - 's3:GetReplicationConfiguration' - 's3:GetMetricsConfiguration' - 's3:GetAccelerateConfiguration' - 's3:GetAnalyticsConfiguration' - 's3:GetBucketLocation' - 's3:GetBucketRequestPayment' - 's3:GetEncryptionConfiguration' - 's3:GetInventoryConfiguration' - 's3:GetIpConfiguration' - 'ses:ListConfigurationSets' - 'ses:GetSendQuota' - 'ses:DescribeConfigurationSet' - 'ses:ListReceiptFilters' - 'ses:ListReceiptRuleSets' - 'ses:DescribeReceiptRule' - 'ses:DescribeReceiptRuleSet' - 'sns:GetTopicAttributes' - 'sns:ListTopics' - 'sqs:ListQueues' - 'sqs:ListQueueTags' - 'sqs:GetQueueAttributes' - 'tag:GetResources' - 'ec2:DescribeInternetGateways' - 'ec2:DescribeVpcs' - 'ec2:DescribeNatGateways' - 'ec2:DescribeVpcEndpoints' - 'ec2:DescribeSubnets' - 'ec2:DescribeNetworkAcls' - 'ec2:DescribeVpcAttribute' - 'ec2:DescribeRouteTables' - 'ec2:DescribeSecurityGroups' - 'ec2:DescribeVpcPeeringConnections' - 'ec2:DescribeNetworkInterfaces' - 'lambda:GetAccountSettings' - 'lambda:ListFunctions' - 'lambda:ListAliases' - 'lambda:ListTags' - 'lambda:ListEventSourceMappings' - 'cloudwatch:GetMetricStatistics' - 'cloudwatch:ListMetrics' - 'cloudwatch:GetMetricData' - 'support:*' Resource: '*' Copy Option 2: Manually add permissions To create your own policy using available permissions: Add the permissions for all integrations. Add permissions that are specific to the integrations you need The following permissions are used by New Relic to retrieve data for specific AWS integrations: Required by all integrations Important If an integration is not listed on this page, these permissions are all you need. All integrations Permissions CloudWatch cloudwatch:GetMetricStatistics cloudwatch:ListMetrics cloudwatch:GetMetricData Config API config:BatchGetResourceConfig config:ListDiscoveredResources Resource Tagging API tag:GetResources ALB permissions Additional ALB permissions: elasticloadbalancing:DescribeLoadBalancers elasticloadbalancing:DescribeTargetGroups elasticloadbalancing:DescribeTags elasticloadbalancing:DescribeLoadBalancerAttributes elasticloadbalancing:DescribeListeners elasticloadbalancing:DescribeRules elasticloadbalancing:DescribeTargetGroupAttributes elasticloadbalancing:DescribeInstanceHealth elasticloadbalancing:DescribeLoadBalancerPolicies elasticloadbalancing:DescribeLoadBalancerPolicyTypes API Gateway permissions Additional API Gateway permissions: apigateway:GET apigateway:HEAD apigateway:OPTIONS Auto Scaling permissions Additional Auto Scaling permissions: autoscaling:DescribeLaunchConfigurations autoscaling:DescribeAutoScalingGroups autoscaling:DescribePolicies autoscaling:DescribeTags autoscaling:DescribeAccountLimits Billing permission Additional Billing permission: budgets:ViewBudget Cloudfront permissions Additional Cloudfront permissions: cloudfront:ListDistributions cloudfront:ListStreamingDistributions cloudfront:ListTagsForResource CloudTrail permissions Additional CloudTrail permissions: cloudtrail:LookupEvents DynamoDB permissions Additional DynamoDB permissions: dynamodb:DescribeLimits dynamodb:ListTables dynamodb:DescribeTable dynamodb:ListGlobalTables dynamodb:DescribeGlobalTable dynamodb:ListTagsOfResource EBS permissions Additional EBS permissions: ec2:DescribeVolumeStatus ec2:DescribeVolumes ec2:DescribeVolumeAttribute EC2 permissions Additional EC2 permissions: ec2:DescribeInstanceStatus ec2:DescribeInstances ECS/ECR permissions Additional ECS/ECR permissions: ecs:ListServices ecs:DescribeServices ecs:DescribeClusters ecs:ListClusters ecs:ListTagsForResource ecs:ListContainerInstances ecs:DescribeContainerInstances EFS permissions Additional EFS permissions: elasticfilesystem:DescribeMountTargets elasticfilesystem:DescribeFileSystems ElastiCache permissions Additional ElastiCache permissions: elasticache:DescribeCacheClusters elasticache:ListTagsForResource ElasticSearch permissions Additional ElasticSearch permissions: es:ListDomainNames es:DescribeElasticsearchDomain es:DescribeElasticsearchDomains es:ListTags Elastic Beanstalk permissions Additional Elastic Beanstalk permissions: elasticbeanstalk:DescribeEnvironments elasticbeanstalk:DescribeInstancesHealth elasticbeanstalk:DescribeConfigurationSettings ELB permissions Additional ELB permissions: elasticloadbalancing:DescribeLoadBalancers EMR permissions Additional EMR permissions: elasticmapreduce:ListInstances elasticmapreduce:ListClusters elasticmapreduce:DescribeCluster elasticmapreduce:ListInstanceGroups elasticmapreduce:ListInstanceFleets Health permissions Additional Health permissions: health:DescribeAffectedEntities health:DescribeEventDetails health:DescribeEvents IAM permissions Additional IAM permissions: iam:ListSAMLProviders iam:ListOpenIDConnectProviders iam:ListServerCertificates iam:GetAccountAuthorizationDetails iam:ListVirtualMFADevices iam:GetAccountSummary IoT permissions Additional IoT permissions: iot:ListTopicRules iot:GetTopicRule iot:ListThings Kinesis Firehose permissions Additional Kinesis Firehose permissions: firehose:DescribeDeliveryStream firehose:ListDeliveryStreams Kinesis Streams permissions Additional Kinesis Streams permissions: kinesis:ListStreams kinesis:DescribeStream kinesis:ListTagsForStream Lambda permissions Additional Lambda permissions: lambda:GetAccountSettings lambda:ListFunctions lambda:ListAliases lambda:ListTags lambda:ListEventSourceMappings RDS, RDS Enhanced Monitoring permissions Additional RDS and RDS Enhanced Monitoring permissions: rds:ListTagsForResource rds:DescribeDBInstances rds:DescribeDBClusters Redshift permissions Additional Redshift permissions: redshift:DescribeClusters redshift:DescribeClusterParameters Route 53 permissions Additional Route 53 permissions: route53:ListHealthChecks route53:GetHostedZone route53:ListHostedZones route53:ListResourceRecordSets route53:ListTagsForResources S3 permissions Additional S3 permissions: s3:GetLifecycleConfiguration s3:GetBucketTagging s3:ListAllMyBuckets s3:GetBucketWebsite s3:GetBucketLogging s3:GetBucketCORS s3:GetBucketVersioning s3:GetBucketAcl s3:GetBucketNotification s3:GetBucketPolicy s3:GetReplicationConfiguration s3:GetMetricsConfiguration s3:GetAccelerateConfiguration s3:GetAnalyticsConfiguration s3:GetBucketLocation s3:GetBucketRequestPayment s3:GetEncryptionConfiguration s3:GetInventoryConfiguration s3:GetIpConfiguration Simple Email Service (SES) permissions Additional SES permissions: ses:ListConfigurationSets ses:GetSendQuota ses:DescribeConfigurationSet ses:ListReceiptFilters ses:ListReceiptRuleSets ses:DescribeReceiptRule ses:DescribeReceiptRuleSet SNS permissions Additional SNS permissions: sns:GetTopicAttributes sns:ListTopics SQS permissions Additional SQS permissions: sqs:ListQueues sqs:GetQueueAttributes sqs:ListQueueTags Trusted Advisor permissions Additional Trusted Advisor permissions: support:* See also the note about the Trusted Advisor integration and recommended policies. VPC permissions Additional VPC permissions: ec2:DescribeInternetGateways ec2:DescribeVpcs ec2:DescribeNatGateways ec2:DescribeVpcEndpoints ec2:DescribeSubnets ec2:DescribeNetworkAcls ec2:DescribeVpcAttribute ec2:DescribeRouteTables ec2:DescribeSecurityGroups ec2:DescribeVpcPeeringConnections ec2:DescribeNetworkInterfaces ec2:DescribeVpnConnections X-Ray monitoring permissions Additional X-ray monitoring permissions: xray:BatchGet* xray:Get*",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.687096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integrations</em> and managed policies",
        "sections": "<em>Integrations</em> and managed policies",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "In order to use infrastructure <em>integrations</em>, you need to grant New Relic permission to read the relevant data from your account. <em>Amazon</em> Web Services (AWS) uses managed policies to grant these permissions. Recommended policy Important Recommendation: Grant an account-wide ReadOnlyAccess managed"
      },
      "id": "6045079fe7b9d27db95799d9"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/authentication-issues": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.229034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.229034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "CloudWatch billing increase",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "CloudWatch billing increase",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "db3cd732ea370f1d579f2f79a03a342efe77eaa0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/cloudwatch-billing-increase/",
      "published_at": "2021-06-26T14:05:43Z",
      "updated_at": "2021-03-13T01:09:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After setting up New Relic Infrastructure Amazon integrations, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you need to manage your Amazon CloudWatch bill, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you need to manage your Amazon CloudWatch bill, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, contact your New Relic account representative or get support at support.newrelic.com. Cause New Relic Infrastructure Amazon integrations leverage CloudWatch to gather metrics. AWS charges joint customers for requests that exceed the first one million per month. CloudWatch billing issues may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.45018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After setting up New Relic Infrastructure <em>Amazon</em> <em>integrations</em>, your usage of the CloudWatch API has increased and subsequently impacted your CloudWatch usage bill. Solution Verify your Infrastructure account&#x27;s ARN Ensure that you are not collecting inventory information for the wrong ARN"
      },
      "id": "604507f9196a67eba2960f36"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cannot-create-alert-condition-infrastructure-integration": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.22896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/cloudwatch-billing-increase": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.22896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/invalid-principal-error-unsupported-aws-regions": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.22888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/metric-data-delays-amazon-aws-integrations": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.22888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/no-data-appears-aws-integrations": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.228806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda": [
    {
      "sections": [
        "AWS Health monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Configuration and polling",
        "Explore integration data",
        "Events monitoring and alerts",
        "Inventory data"
      ],
      "title": "AWS Health monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "d75bbba73face9ecdde4bf98addfd11292332157",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-health-monitoring-integration/",
      "published_at": "2021-06-25T22:05:49Z",
      "updated_at": "2021-06-25T22:05:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can affect the AWS resources and services globally or in a specific account. This data can help you anticipate potential application outages. AWS Health reports three types of events: Open issues: Shows issues that might affect your AWS infrastructure. Scheduled changes: Informs you in advance of scheduled activities that might have an impact on AWS services and resources. Notifications: Provides additional information. Requirements This integration is available only for AWS customers who have a Business or Enterprise support plan, because this is a requirement for using the AWS Health API. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS Health integration: New Relic polling interval: 5 minutes Explore integration data To use this integration's data: Go to one.newrelic.com > Infrastructure > AWS. Select any of the available AWS Health integration links. To view a complete list of open issues, select the Inventory page. To view a timeline when an AWS Health inventory event is created, modified, or deleted, use the Events page. Events monitoring and alerts AWS Health events are ingested in New Relic One as AwsHealthNotification events. You can query, create widgets, and define NRQL alert policies based on these events. The following table shows the main attributes available for AwsHealthNotification events: Event Attribute Description affectedEntityArn The AWS resource ARN. arn The ARN of the AWS Health event itself. affectedRegion The AWS affected region. affectedResources Number of affected resources. Auto-generated metric that can be used to define New Relic alert conditions. description Detailed description of the event. eventTypeCategory AWS Health category: Issue, ScheduledChange, AccountNotification, Investigation. eventTypeCode A list of unique identifiers for event types. For example,AWS_EC2_SYSTEM_MAINTENANCE_EVENT or AWS_RDS_MAINTENANCE_SCHEDULED. service The AWS services associated with the event. For example, EC2, RDS. statusCode The AWS health event status: Open, Closed, Upcoming. startTime Date and time the event began. NRQL alert conditions can be defined to receive notifications when health events are reported by AWS. For example, the following query monitors any open issues on EC2 by resource: SELECT uniqueCount(affectedEntityArn) FROM AwsHealthNotification where statusCode = 'open' and eventTypeCategory = 'Issue' and service = 'EC2' Copy Inventory data Inventory data provides information about active AWS Health events. New Relic's AWS Health integration generates three types of entities, each of which have the same inventory data: aws/health/issue/ aws/health/scheduled-change/ aws/health/notification/ Name Description affectedAvailabilityZone The AWS Availability Zone of the event. affectedEntities The ARNs of the entities that are affected by the event. Entities can refer to individual customer resources, groups of customer resources, or any other construct, depending on the AWS service. affectedRegion The AWS region of the affected entities. arn The unique identifier for the event. awsRegion The Personal Health Dashboard region. description The most recent description of the event. endTime The date and time that the event ended. eventTypeCategory The category of the event type. Possible values are issue, scheduledChange, or accountNotification. eventTypeCode The unique identifier for the event type. service The AWS service that is affected by the event. startTime The date and time that the event began. statusCode The most recent status of the event. Examples of possible values are open, closed, and upcoming.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.228806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "AWS Health monitoring <em>integration</em>",
        "sections": "AWS Health monitoring <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> include an integration for reporting your AWS Health data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features This integration collects information from AWS Health about events that can"
      },
      "id": "6044e36d64441f2793378f16"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-26T13:32:56Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.06523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "sections": "<em>Amazon</em> CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": ". In order to continue collecting that additional data, keep those enabled as polling <em>integrations</em>. <em>Troubleshooting</em> No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "AWS service specific API rate limiting",
        "Problem",
        "Solution",
        "Verify your Infrastructure account's ARN",
        "Change the polling frequency",
        "Filter your data",
        "Review API usage",
        "Cause"
      ],
      "title": "AWS service specific API rate limiting",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "785db1a9f5d5d9b89c2d304d1260ce5a8f30a680",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/troubleshooting/aws-service-specific-api-rate-limiting/",
      "published_at": "2021-06-25T23:51:03Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling Amazon integrations with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your Infrastructure account's ARN Ensure that you are not collecting inventory information for the wrong ARN account. Verify that the ARN associated with your Infrastructure account is correct. Change the polling frequency The polling frequency determines how often New Relic gathers data from your cloud provider. By default, the polling frequency is set to the maximum frequency that is available for each service. If you reach your API rate limit, you may want to decrease the polling frequency. Filter your data You can set filters for each integration in order to specify which information you want captured. If you reach your API rate limit, you may want to filter your data. Review API usage To review the API usage for New Relic Infrastructure integrations with Amazon AWS: Go to one.newrelic.com > Infrastructure > AWS > Account status dashboard. Review the New Relic Insights dashboard, which appears automatically. The Insights dashboard includes a chart with your account's Amazon AWS API call count for the last month as well as the CloudWatch API calls (per AWS resource) for the last day. This information is the API usage for New Relic only. It does not include other AWS API or CloudWatch usage that may occur. For assistance determining which services may cause an increase in billing, get support at support.newrelic.com, or contact your New Relic account representative. Cause Infrastructure Amazon integrations leverage the AWS monitoring APIs to gather inventory data. AWS imposes hard rate limits on many of the AWS service-specific APIs consumed by New Relic Infrastructure integrations. Adding New Relic Amazon integrations will increase usage of the service-specific APIs and could impact how quickly you reach your rate limit. This may be caused by either of the following: Enabling Amazon integrations on several plugins for the same service Adding the incorrect Role ARN to your AWS integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.98924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Amazon</em> <em>integrations</em>",
        "body": "Problem After enabling <em>Amazon</em> <em>integrations</em> with New Relic Infrastructure, you encounter a rate limit for service-specific APIs. You might see this message in your AWS monitoring software, often with a 503 error: AWS::EC2::Errors::RequestLimitExceeded Request limit exceeded. Solution Verify your"
      },
      "id": "604507c428ccbc013a2c60c4"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Tip",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document explains how to install this integration. Tip To use ECS integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install overview Before you install our ECS integration, we recommend reviewing the requirements. Here's a brief overview of what happens during the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure youre deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.22755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document explains how to install this <em>integration</em>. Tip To use ECS <em>integrations</em> and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "78bfa3ecb2059e2641be8e22cd8ebb025da625a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-06-26T04:17:19Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 launch type, and not Fargate: Delete the service: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.16583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "603e9e7464441fd9cf4e885b"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration": [
    {
      "sections": [
        "Uninstall the ECS integration",
        "Uninstall",
        "CloudFormation uninstall",
        "Automatic uninstall",
        "Manual uninstall"
      ],
      "title": "Uninstall the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "78bfa3ecb2059e2641be8e22cd8ebb025da625a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/uninstall-ecs-integration/",
      "published_at": "2021-06-26T04:17:19Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this integration. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script Manual uninstall CloudFormation uninstall To uninstall the ECS integration using the CloudFormation templates: Go to the list of stacks in your AWS console. For each New Relic stack: Select the stack Click the delete button Click the delete stack button on the confirmation pop-up. Automatic uninstall To uninstall the ECS integration using the installer script: For EC2 launch type: run $ ./newrelic-infrastructure-ecs-installer.sh -u -c YOUR_CLUSTER_NAME Copy For Fargate launch type: $ ./newrelic-infrastructure-ecs-installer.sh -f -u -c YOUR_CLUSTER_NAME Copy You only need to execute the command once, regardless of the number of nodes in your cluster. The command will delete the AWS resources created during the install procedure. The installer provides a dry run mode that shows you the awscli commands that are going to be executed. The dry run mode for the uninstall process is activated by passing the -d flag to the command: $ ./newrelic-infrastructure-ecs-installer.sh -d -u -c YOUR_CLUSTER_NAME Copy Manual uninstall To uninstall manually, you must delete all the AWS resources related to the integration. To do this: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Delete the Systems Manager (SSM) parameter that stores the New Relic license key: aws ssm delete-parameter --name \"/newrelic-infra/ecs/license-key\" Copy Before deleting the IAM role, you need to detach all of its policies. To get a list of the attached policies: aws iam list-attached-role-policies --role-name \"NewRelicECSTaskExecutionRole\" --output text --query 'AttachedPolicies[*].PolicyArn' Copy Detach all the policies returned in the previous step from the IAM role: aws iam detach-role-policy --role-name \"NewRelicECSTaskExecutionRole\" --policy-arn \"POLICY_ARN\" Copy Delete the IAM role: aws iam delete-role --role-name \"NewRelicECSTaskExecutionRole\" Copy Delete the IAM policy NewRelicSSMLicenseKeyReadAccess, which grants System Manager license key access: aws iam delete-policy --policy-arn \"POLICY_ARN\" Copy The remaining steps are only for EC2 launch type, and not Fargate: Delete the service: aws ecs delete-service --service \"newrelic-infra\" --cluster \"YOUR_CLUSTER_NAME\" Copy List the task definition for the newrelic-infra family of tasks: aws ecs list-task-definitions \\ --family-prefix newrelic-infra \\ --output text \\ --query taskDefinitionArns Copy Deregister the tasks: aws ecs deregister-task-definition --task-definition \"TASK_DEFINITION_ARN\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.99008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Uninstall the ECS <em>integration</em>",
        "sections": "Uninstall the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. Read on to learn how to uninstall this <em>integration</em>. Uninstall There are several uninstall options, depending on how you installed: Uninstall with CloudFormation Use automatic installer script"
      },
      "id": "603e9e7464441fd9cf4e885b"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.45555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/installation/uninstall-ecs-integration": [
    {
      "sections": [
        "Install the ECS integration",
        "Tip",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document explains how to install this integration. Tip To use ECS integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install overview Before you install our ECS integration, we recommend reviewing the requirements. Here's a brief overview of what happens during the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure youre deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.05179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the ECS <em>integration</em>",
        "sections": "<em>Install</em> the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document explains how to install this <em>integration</em>. Tip To use ECS <em>integrations</em> and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign"
      },
      "id": "603e9e76196a676684a83de9"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.45555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No data appears",
        "sections": "ECS <em>integration</em> troubleshooting: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs": [
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.2455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: No data appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". <em>Troubleshoot</em> in the UI To use the UI to <em>troubleshoot</em>: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, use the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.00043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Tip",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document explains how to install this integration. Tip To use ECS integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install overview Before you install our ECS integration, we recommend reviewing the requirements. Here's a brief overview of what happens during the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure youre deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.90375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document explains how to install this <em>integration</em>. Tip To use ECS <em>integrations</em> and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign"
      },
      "id": "603e9e76196a676684a83de9"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears": [
    {
      "sections": [
        "ECS integration troubleshooting: Generate verbose logs",
        "Problem",
        "Solution",
        "Using task definition environment variable",
        "Retrieve logs via SSH (EC2 launch type only)",
        "Forward logs to CloudWatch and download them with awscli",
        "From running container"
      ],
      "title": "ECS integration troubleshooting: Generate verbose logs",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "06198f1b2e0faa69bd8a7dfb93f18c8955fea83b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-generate-verbose-logs/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-13T03:35:43Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting the on-host ECS integration, you can generate verbose logs for a few minutes to find and investigate errors. This can be useful for conducting your own troubleshooting or when providing information to New Relic support. Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. You can automate this process by using the newrelic-infra-ctl command. For more information, see Troubleshooting a running agent. Solution Generating verbose log files requires editing your task definition file. For a sample config file that includes all applicable settings, see Infrastructure configuration settings. You have several options for implementing verbose logs: Change the task definition environment variable and do a task restart For EC2 launch type: Retrieve logs via SSH Forward to CloudWatch and download with awscli Run a command from the running container Using task definition environment variable To enable verbose logs by changing the environment variable and doing a task restart: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. Save your task definition. Update your service to use the newly registered task definition. If you chose NRIA_VERBOSE=3 and you're not sending the logs directly to New Relic, you have two options for viewing and downloading the logs: For EC2 launch type: you can retrieve the logs via SSH, or Forward logs to CloudWatch Return your settings to default: Disable verbose logging by editing your task definition and setting NRIA_VERBOSE to 0. Save your task definition. Update your service to the latest version of your task. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file. Retrieve logs via SSH (EC2 launch type only) To get logs via SSH: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. SSH into one of your container instances. Find the container ID of the New Relic integration container, by running the command docker ps -a. The name of the container should be nri-ecs. Save the logs from the container with the command docker logs NRI_ECS_CONTAINER_ID > logs.txt. Leave the command running for about three minutes to generate sufficient logging data. Continue with the instructions in the enable verbose logs section. Forward logs to CloudWatch and download them with awscli To get logs via CloudWatch: Edit your task definition. Change the value of NRIA_VERBOSE from 0 to: 1 for always-on verbose logs 2 for smart logging 3 for sending to New Relic Read more about these options. We use a CloudWatch log group called /newrelic-infra/ecs to forward the logs to. To see if it already exists, run: aws logs describe-log-groups --log-group-name-prefix /newrelic-infra/ecs Copy If a log group exists with that prefix, you'll get this output: { \"logGroups\": [ { \"logGroupName\": \"/newrelic-infra/ecs\", \"creationTime\": 1585828615225, \"metricFilterCount\": 0, \"arn\": \"arn:aws:logs:YOUR_REGION:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:*\", \"storedBytes\": 122539356 } ] } Copy Because this command matches log groups with prefixes, ensure the log group name returned is exactly /newrelic-infra/ecs. If the log group doesn't exist, the output will be: { \"logGroups\": [] } Copy If the log group doesn't exist, create it by running: aws logs create-log-group --log-group-name /newrelic-infra/ecs Copy Edit your task definition. In the container definition for the newrelic-infra container, add the following logConfiguration: \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/newrelic-infra/ecs\", \"awslogs-region\": \"AWS_REGION_OF_YOUR_CLUSTER\", \"awslogs-stream-prefix\": \"verbose\" } } Copy Register the new task version and update your service. Next you'll look for the relevant log stream. If you have multiple instances of the task running, they'll all send their logs to the same log group but each will have its own log stream. Log streams names follow the structure AWSLOGS_STREAM_PREFIX/TASK_FAMILY_NAME/TASK_ID. In this case, it will be verbose/newrelic-infra/TASK_ID. To get all the log streams for a given log group, run this command: aws logs describe-log-streams --log-group-name /newrelic-infra/ecs Copy The following is an example output of a log group with two streams: { \"logStreams\": [ { \"logStreamName\": \"verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"creationTime\": 1586166741197, \"firstEventTimestamp\": 1586166742030, \"lastEventTimestamp\": 1586173933472, \"lastIngestionTime\": 1586175101220, \"uploadSequenceToken\": \"49599989655680038369205623273330095416487086853777112338\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/9dfb28114e40415ebc399ec1e53a21b7\", \"storedBytes\": 0 }, { \"logStreamName\": \"verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"creationTime\": 1586166745643, \"firstEventTimestamp\": 1586166746491, \"lastEventTimestamp\": 1586173037927, \"lastIngestionTime\": 1586175100660, \"uploadSequenceToken\": \"49605664273821671319096446647846424799651902350804230514\", \"arn\": \"arn:aws:logs:AWS_REGION_OF_YOUR_CLUSTER:YOUR_AWS_ACCOUNT:log-group:/newrelic-infra/ecs:log-stream:verbose/newrelic-infra/f6ce0be416804bc4bfa658da5514eb00\", \"storedBytes\": 0 } ] } Copy From the previous list of log streams, identify the one with the task ID for which you want to retrieve the logs and use the logStreamName in this command: aws logs get-log-events --log-group-name /newrelic-infra/ecs --log-stream-name \"LOG_STREAM_NAME\" --output text > logs.txt Copy Continue with the enable verbose logs instructions. From running container To enable verbose logs by running a command from the running container: SSH into one of your container instances. Find the container ID of the New Relic integration container by running the command docker ps -a. The name of the container should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec INTEGRATION_CONTAINER_ID /usr/bin/newrelic-infra-ctl Copy For more details, see Troubleshoot the agent. Save the logs from the container with the command docker logs INTEGRATION_CONTAINER_ID > logs.txt Copy Leave the command running for about three minutes to generate sufficient logging data. Examine the log file for errors. If you need to send your log file to New Relic support: Include the line in your log file that contains the ECS integration version: New Relic ECS integration version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your task definition .yml file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.18793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "sections": "ECS <em>integration</em> <em>troubleshooting</em>: Generate verbose logs",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": " by running the command docker ps -a. The name of the <em>container</em> should be nri-ecs. Enable verbose logs for a limited period of time by using newrelic-infra-ctl. Run the command: docker exec <em>INTEGRATION_CONTAINER</em>_ID &#x2F;usr&#x2F;bin&#x2F;newrelic-infra-ctl Copy For more details, see <em>Troubleshoot</em> the agent. Save"
      },
      "id": "604507f9196a67c1ae960f5e"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.00043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "Install the ECS integration",
        "Tip",
        "Install overview",
        "Install using CloudFormation",
        "EC2 launch type",
        "Fargate launch type",
        "Install with automatic script",
        "Manual install",
        "AWS resources created"
      ],
      "title": "Install the ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Installation"
      ],
      "external_id": "857b78b6e7de76449f3f9569cee4700705b7d7fe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/installation/install-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-16T05:40:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document explains how to install this integration. Tip To use ECS integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install overview Before you install our ECS integration, we recommend reviewing the requirements. Here's a brief overview of what happens during the install process: For EC2 launch type: The infrastructure agent (newrelic-infra) gets deployed onto an ECS cluster as a service using the daemon scheduling strategy. This deployment installs the infrastructure agent in all the container instances of the cluster. The infrastructure agent then monitors ECS and Docker containers. For Fargate launch type: The infrastructure agent (newrelic-infra) gets deployed as a sidecar in every task to monitor. Install options: Install using AWS CloudFormation Install using automatic script Install manually Install using CloudFormation One install option is using AWS CloudFormation. We provide some CloudFormation templates that install the ECS integration onto your AWS account for both EC2 and Fargate launch types: To register the New Relic's ECS integration task, deploy this stack. Ensure youre deploying the stack to your desired region(s). This stack creates the following resources: A secret that stores the license key. A policy to access the license key. An instance role to be used as an ECS task ExecutionRole, with access to the license key. For EC2 launch type: Registers the New Relic Infrastructure ECS integration task. Follow the additional instructions for your launch type: EC2 launch type Additional steps for EC2 launch type: To create a service that runs the task on every container instance, deploy this stack. Fargate launch type Additional steps for Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Install with automatic script One install option is using our install script. To use the automatic install script: Download the ECS integration installer: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-installer.sh Copy Add execute permissions to the installer: chmod +x newrelic-infra-ecs-installer.sh Copy Execute it with -h to see the documentation and requirements: ./newrelic-infra-ecs-installer.sh -h Copy Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Execute the installer, specifying your license key and cluster name. EC2 launch type: ./newrelic-infra-ecs-installer.sh -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Fargate launch type: ./newrelic-infra-ecs-installer.sh -fargate -c YOUR_CLUSTER_NAME -l YOUR_LICENSE_KEY Copy Additional steps for Fargate launch type (not EC2 launch type): Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the single container in this task definition as a sidecar to the task definitions you want monitored. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, which gets you other ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. Manual install One install option is to manually do the steps that are done by the automatic installer script. We will describe how this is done using the awscli tool: Check that your AWS profile points to the same region where your ECS cluster was created: $ aws configure get region us-east-1 $ aws ecs list-clusters YOUR_CLUSTER_ARNS arn:aws:ecs:us-east-1:YOUR_AWS_ACCOUNT:cluster/YOUR_CLUSTER Copy Save your New Relic license key as a Systems Manager (SSM) parameter: aws ssm put-parameter \\ --name \"/newrelic-infra/ecs/license-key\" \\ --type SecureString \\ --description 'New Relic license key for ECS monitoring' \\ --value \"NEW_RELIC_LICENSE_KEY\" Copy Create an IAM policy to access the license key parameter: aws iam create-policy \\ --policy-name \"NewRelicSSMLicenseKeyReadAccess\" \\ --policy-document \"{\"Version\"\\\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"ssm:GetParameters\"],\"Resource\":[\"ARN_OF_LICENSE_KEY_PARAMETER\"]}]}\" --description \"Provides read access to the New Relic SSM license key parameter\" Copy Create an IAM role to be used as the task execution role: aws iam create-role \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --assume-role-policy-document '{\"Version\":\"2008-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ecs-tasks.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}' \\ --description \"ECS task execution role for New Relic infrastructure\" Copy Attach the policies NewRelicSSMLicenseKeyReadAccess, AmazonEC2ContainerServiceforEC2Role, and AmazonECSTaskExecutionRolePolicy to the role: aws iam attach-role-policy \\ --role-name \"NewRelicECSTaskExecutionRole\" \\ --policy-arn \"POLICY_ARN\" Copy Choose your launch type for more instructions: EC2 launch type Additional steps for EC2 launch type: Download the New Relic ECS integration task definition template file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-ec2-latest.json Copy Replace the task execution role in the template file with the newly created role: \"executionRoleArn\": \"NewRelicECSTaskExecutionRole\", Copy Replace the valueFrom attribute of the secret with the name of the Systems Manager parameter: secrets\": [ { \"valueFrom\": \"/newrelic-infra/ecs/license-key\", \"name\": \"NRIA_LICENSE_KEY\" } ], Copy Register the task definition file: aws ecs register-task-definition --cli-input-json file://newrelic-infra-ecs-ec2-latest.json Copy Create a service with the daemon scheduling strategy for the registered task: aws ecs create-service --cluster \"YOUR_CLUSTER_NAME\" --service-name \"newrelic-infra\" --task-definition \"newrelic-infra\" --scheduling-strategy DAEMON Copy Fargate launch type Additional steps for the Fargate launch type: Download the task definition example with the sidecar container to be deployed: curl -O https://download.newrelic.com/infrastructure_agent/integrations/ecs/newrelic-infra-ecs-fargate-example-latest.json Copy Add the newrelic-infra container in this task definition as a sidecar to the task definitions you want to monitor. In this example task, your application's containers replace the placeholder busybox container. Next steps: Wait a few minutes and then look for your data in the UI. Recommended: Install our ECS cloud integration, a separate integration which gets you supplementary ECS data, including information about clusters and services. See recommended alert conditions. Understand the AWS resources created by this process. AWS resources created When you install the ECS integration using default/recommended values, it does the following in AWS: Creates Systems Manager (SSM) parameter /newrelic-infra/ecs/license-key. This system parameter contains the New Relic license key. Creates IAM policy NewRelicSSMLicenseKeyReadAccess, which enables access to the SSM parameter with the license key. Creates IAM role NewRelicECSTaskExecutionRole used as the task execution role. Policies attached to the role: NewRelicSSMLicenseKeyReadAccess (created by the installer). AmazonEC2ContainerServiceforEC2Role AmazonECSTaskExecutionRolePolicy For EC2 launch type, this is also done: Registers the newrelic-infra ECS task definition. Creates the service newrelic-infra for the registered task using a daemon scheduling strategy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.90375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the ECS <em>integration</em>",
        "sections": "Install the ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance data from your Amazon ECS environment. This document explains how to install this <em>integration</em>. Tip To use ECS <em>integrations</em> and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign"
      },
      "id": "603e9e76196a676684a83de9"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions": [
    {
      "sections": [
        "Understand and use ECS data",
        "View data",
        "Query your data"
      ],
      "title": "Understand and use ECS data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "16689cc080d4a8482e802b404df9ae45c4283db2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/understand-use-ecs-data/",
      "published_at": "2021-06-26T04:18:23Z",
      "updated_at": "2021-03-29T20:30:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's on-host ECS integration reports and displays performance data from your Amazon ECS environment. Here we explain how to find, understand, and use the data reported by this integration. View data To view the ECS integration dashboard: Go to one.newrelic.com and select Explorer. On the left, search for ECS clusters, or type the name of your ECS cluster in the search bar. To view a dashboard, select the entity name corresponding to your ECS cluster. In addition to the pre-built dashboards, you can also create your own custom queries and charts using the query builder. To learn how to query this data, see Understand data. Query your data Data reported by this integration is displayed in its dashboards and is also available for querying and the creation of custom charts and dashboards. This integration reports an EcsClusterSample event, with attributes clusterName and arn. Other types of data that may be available for querying: Infrastructure agent-reported events, including Docker All the events reported from an ECS cluster contain the attributes ecsClusterName and ecsClusterArn. Here's an example NRQL query that returns the count of containers associated with each Docker image in an ECS cluster named MyClusterName created in us-east-1: SELECT uniqueCount(containerId) FROM ContainerSample WHERE awsRegion = 'us-east-1' AND ecsClusterName = 'MyClusterName' FACET imageName SINCE 1 HOUR AGO Copy To learn more about creating custom queries and charts: How to query New Relic data Introduction to NRQL",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.60623,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "sections": "<em>Understand</em> and <em>use</em> ECS <em>data</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s on-host ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. Here we explain how to find, <em>understand</em>, and <em>use</em> the <em>data</em> reported by this <em>integration</em>. View <em>data</em> To view the ECS <em>integration</em> dashboard: Go to one.newrelic.com and select Explorer"
      },
      "id": "603e9eb664441fbaad4e889f"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.45554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No <em>data</em> appears",
        "sections": "ECS <em>integration</em> troubleshooting: No <em>data</em> appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To <em>use</em> the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, <em>use</em> the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/elastic-container-service-integration/understand-use-data/understand-use-ecs-data": [
    {
      "sections": [
        "Recommended ECS alert conditions",
        "Recommended alert conditions"
      ],
      "title": "Recommended ECS alert conditions",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Understand use data"
      ],
      "external_id": "334d80a75b3ef0a7b6125bf2a15f643ea46d7282",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/understand-use-data/ecs-integration-recommended-alert-conditions/",
      "published_at": "2021-06-26T04:18:24Z",
      "updated_at": "2021-03-16T05:41:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's ECS integration reports and displays performance data from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go to the Alerts UI and add the following NRQL alert conditions to an existing or new alert policy: High CPU usage NRQL: FROM ContainerSample SELECT cpuUsed / cpuLimitCores Critical: > 90% for 5 minutes High memory usage NRQL: FROM ContainerSample SELECT memoryUsageBytes / memorySizeLimitBytes Critical: > 80% for 5 minutes Restart count NRQL: FROM ContainerSample SELECT max(restartCount) - min(restartCount) Critical: > 5 for 5 minutes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.95384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "New Relic&#x27;s ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. This document provides some recommended alert conditions for monitoring ECS performance. Recommended alert conditions Here are some recommended ECS alert conditions. To add these alerts, go"
      },
      "id": "603e7eee64441f0f674e889f"
    },
    {
      "sections": [
        "Introduction to the Amazon ECS integration",
        "Features",
        "Important",
        "Compatibility and requirements",
        "Install",
        "Check the source code"
      ],
      "title": "Introduction to the Amazon ECS integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Get started"
      ],
      "external_id": "a2af5484b25f8595032cc1937210c9a41024a138",
      "image": "https://docs.newrelic.com/static/986bdb22950fdd8b222a850e205882a9/c1b63/new-relic-ecs-integration-dashboards_0.png",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/get-started/introduction-amazon-ecs-integration/",
      "published_at": "2021-06-25T22:07:57Z",
      "updated_at": "2021-03-30T21:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our ECS integration reports and displays performance data from your Amazon ECS environment. The ECS integration works well with other integrations, so you can also monitor services running on ECS. Features Amazon Elastic Container Service (ECS) is a scalable container management service that makes it easy to run, stop, and manage Docker containers on Amazon EC2 clusters. Our ECS integration instruments the underlying container instance (EC2 launch type) and the container layer by reporting metrics from ECS objects. The integration gives you insight into your ECS instances, tasks, services, and containers. one.newrelic.com > Explorer > ECS dashboard: The ECS integration reports performance data about your Amazon ECS containers. Features include: View your data in pre-built dashboards for immediate insight into your ECS environment. Create your own queries and charts in the query builder from automatically reported data. Create alert conditions on ECS data. Explore entities using the New Relic Explorer. Important New Relic also offers an ECS cloud integration, which reports a different data set than our on-host integration. For complete ECS monitoring, we recommend enabling both integrations. Compatibility and requirements Requirements: Amazon ECS container agent 1.21.0 or higher. Windows not supported. This integration uses our infrastructure agent and our Docker instrumentation: applicable requirements and restrictions of those systems apply. Install To install, see Install integration. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.45554,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Amazon ECS <em>integration</em>",
        "sections": "Introduction to the Amazon ECS <em>integration</em>",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": "Our ECS <em>integration</em> reports and displays performance <em>data</em> from your Amazon ECS environment. The ECS <em>integration</em> works well with other <em>integrations</em>, so you can also monitor services running on ECS. Features Amazon <em>Elastic</em> <em>Container</em> <em>Service</em> (ECS) is a scalable <em>container</em> management <em>service</em> that makes"
      },
      "id": "603eb04b196a6752b5a83dc8"
    },
    {
      "sections": [
        "ECS integration troubleshooting: No data appears",
        "Problem",
        "Important",
        "Solution",
        "Troubleshoot via awscli",
        "Troubleshoot in the UI",
        "Reasons for stopped tasks",
        "AWS Secrets Manager",
        "AWS Systems Manager Parameter Store"
      ],
      "title": "ECS integration troubleshooting: No data appears",
      "type": "docs",
      "tags": [
        "Integrations",
        "Elastic Container Service integration",
        "Troubleshooting"
      ],
      "external_id": "a86730dfe4c4cfdb6d293675c2c97e7393939331",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/elastic-container-service-integration/troubleshooting/ecs-integration-troubleshooting-no-data-appears/",
      "published_at": "2021-06-26T04:17:18Z",
      "updated_at": "2021-03-30T12:41:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You installed our on-host ECS integration and waited a few minutes, but your cluster is not showing in the explorer. Important We have two ECS integrations: a cloud-based integration and an on-host integration. This document is about the on-host integration. Solution If your New Relic account had previously installed the infrastructure agent or an infrastructure on-host integration, your data should appear in the UI within a few minutes. If your account had not previously done either of those things before installing the on-host ECS integration, it may take tens of minutes for data to appear in the UI. In that case, we recommend waiting up to an hour before doing the following troubleshooting steps or contacting support. There are several options for troubleshooting no data appearing: Troubleshoot via the awscli tool (recommended when talking to New Relic technical support) Troubleshoot via the UI For information about stopped tasks, see Stopped tasks reasons. Troubleshoot via awscli When interacting with New Relic support, use this method and send the generated files with your support request: Retrieve the information related to the newrelic-infra service or the Fargate service that contains a task with a newrelic-infra sidecar: aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service newrelic-infra > newrelic-infra-service.json Copy aws ecs describe-services --cluster YOUR_CLUSTER_NAME --service YOUR_FARGATE_SERVICE_WITH_NEW_RELIC_SIDECAR > newrelic-infra-sidecar-service.json Copy The failures attribute details any errors for the services. Under services is the status attribute. It says ACTIVE if the service has no issues. The desiredCount should match the runningCount. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. The pendingCount attribute should be zero, because all tasks should be running. Inspect the events attribute of services to check for issues with scheduling or starting the tasks. For example: if the service is unable to start tasks successfully, it will display a message like: { \"id\": \"5295a13c-34e6-41e1-96dd-8364c42cc7a9\", \"createdAt\": \"2020-04-06T15:28:18.298000+02:00\", \"message\": \"(service newrelic-ifnra) is unable to consistently start tasks successfully. For more information, see the Troubleshooting section of the Amazon ECS Developer Guide.\" } Copy In the same section, you can also see which tasks were started by the service from the events: { \"id\": \"1c0a6ce2-de2e-49b2-b0ac-6458a804d0f0\", \"createdAt\": \"2020-04-06T15:27:49.614000+02:00\", \"message\": \"(service fargate-fail) has started 1 tasks: (task YOUR_TASK_ID).\" } Copy Retrieve the information related to the task with this command: aws ecs describe-tasks --tasks YOUR_TASK_ID --cluster YOUR_CLUSTER_NAME > newrelic-infra-task.json Copy The desiredStatus and lastStatus should be RUNNING. If the task couldn't start normally, it will have a STOPPED status. Inspect the stopCode and stoppedReason. One reason example: a task that couldn't be started because the task execution role doesn't have the appropriate permissions to download the license-key-containing secret would have the following output: \"stopCode\": \"TaskFailedToStart\", \"stoppedAt\": \"2020-04-06T15:28:54.725000+02:00\", \"stoppedReason\": \"Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/NewRelicECSIntegration-Ne-NewRelicECSTaskExecution-1C0ODHVT4HDNT/8637b461f0f94d649e9247e2f14c3803 is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:NewRelicLicenseKeySecret-Dh2dLkgV8VyJ-80RAHS-fail-DmLHfs status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\", \"stoppingAt\": \"2020-04-06T15:28:10.953000+02:00\", Copy If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Troubleshoot in the UI To use the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 Container Service section. Click on the cluster where you installed the New Relic ECS integration. On the Services tab, use the filter to search for the integration service. If you used the automatic install script, the name of the service will be newrelic-infra. If you are using Fargate, it will be the name of your monitored service. Once found, click on the name. The service page shows the Status of the service. It says ACTIVE if the service has no issues. On the same page, the Desired count should match the Running count. This is the number of tasks the service is handling. Because we use the daemon service type, there should be one task per container instance in your cluster. Pending count should be zero, because all tasks should be running. Inspect the Events tab to check for issues with scheduling or starting the tasks. In the Tasks tab of your service, you can inspect the running tasks and the stopped tasks by clicking on the Task status selector. Containers that failed to start are shown when you select the Stopped status. Click on a task to go to the task details page. Under Stopped reason, it displays a message explaining why the task was stopped. If the task is running but youre still not seeing data, generate verbose logs and examine them for errors. For details about reasons for stopped tasks, see Stopped tasks. Reasons for stopped tasks In the AWS ECS troubleshooting documentation you can find information on common causes of errors related to running tasks and services. See below for details about some reasons for stopped tasks. Task stopped with reason: Fetching secret data from AWS Secrets Manager in region YOUR_AWS_REGION: secret arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME: AccessDeniedException: User: arn:aws:sts::YOUR_AWS_ACCOUNT:assumed-role/YOUR_ROLE_NAME is not authorized to perform: secretsmanager:GetSecretValue on resource: arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME status code: 400, request id: 9cf1881e-14d7-4257-b4a8-be9b56e09e3c\" Copy This means that the IAM role specified using executionRoleArn in the task definition doesn't have access to the secret used for the NRIA_LICENSE_KEY. The execution role should have a policy attached that grants it access to read the secret. Get the execution role of your task: aws ecs describe-task-definition --task-definition newrelic-infra --output text --query taskDefinition.executionRoleArn Copy You can replace the --task-definition newrelic-infra with the name of your fargate task that includes the sidecar container. aws ecs describe-task-definition --task-definition YOUR_FARGATE_TASK_NAME --output text --query taskDefinition.executionRoleArn Copy List the policies attached to role: aws iam list-attached-role-policies --role-name YOUR_EXECUTION_ROLE_NAME Copy This should return 3 policies AmazonECSTaskExecutionRolePolicy, AmazonEC2ContainerServiceforEC2Role and a third one that should grant read access to the license key. In the following example the policy it's named NewRelicLicenseKeySecretReadAccess. { \"AttachedPolicies\": [ { \"PolicyName\": \"AmazonECSTaskExecutionRolePolicy\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" }, { \"PolicyName\": \"AmazonEC2ContainerServiceforEC2Role\", \"PolicyArn\": \"arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\" }, { \"PolicyName\": \"YOUR_POLICY_NAME\", \"PolicyArn\": \"arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME\" } ] } Copy Retrieve the default policy version: aws iam get-policy-version --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --version-id $(aws iam get-policy --policy-arn arn:aws:iam::YOUR_AWS_ACCOUNT:policy/YOUR_POLICY_NAME --output text --query Policy.DefaultVersionId) Copy This retrieves the policy permissions. There should be an entry for Actionsecretsmanager:GetSecretValue if you used AWS Secrets Manager to store your license key, or an entry for ssm:GetParametersif you used AWS Systems Manager Parameter Store: AWS Secrets Manager { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"secretsmanager:GetSecretValue\", \"Resource\": \"arn:aws:secretsmanager:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:secret:YOUR_SECRET_NAME\", \"Effect\": \"Allow\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2020-03-31T13:47:07+00:00\" } } Copy AWS Systems Manager Parameter Store { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"ssm:GetParameters\", \"Resource\": [ \"arn:aws:ssm:YOUR_AWS_REGION:YOUR_AWS_ACCOUNT:parameter/YOUR_SECRET_NAME\" ], \"Effect\": \"Allow\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.14801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "ECS <em>integration</em> troubleshooting: No <em>data</em> appears",
        "sections": "ECS <em>integration</em> troubleshooting: No <em>data</em> appears",
        "tags": "<em>Elastic</em> <em>Container</em> <em>Service</em> <em>integration</em>",
        "body": ". Troubleshoot in the UI To <em>use</em> the UI to troubleshoot: Log in to your AWS Console and navigate to the EC2 <em>Container</em> <em>Service</em> section. Click on the cluster where you installed the New Relic ECS <em>integration</em>. On the Services tab, <em>use</em> the filter to search for the <em>integration</em> <em>service</em>. If you used"
      },
      "id": "60450883196a671c8c960f27"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-app-engine-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-bigquery-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-bigtable-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-composer-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataproc-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.45671,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-database-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.4567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-hosting-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.4567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firebase-storage-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.4567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-firestore-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.4567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Cloud Functions monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Important"
      ],
      "title": "Google Cloud Functions monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "2805038e3e7040ea7032a96268fceba1faa0647e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration/",
      "published_at": "2021-06-26T04:19:28Z",
      "updated_at": "2021-03-16T05:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure integrations with the Google Cloud Platform (GCP) includes one that reports Google Cloud Functions data to our products. This document explains how to activate the GCP Cloud Functions integration and describes the data that can be reported. Features Google Cloud Functions service allows running code in a serverless way. Using the Google UI, developers can create short pieces of code that are intended to do a specific function. The function can then respond to cloud events without the need to manage an application server or runtime environment. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency Our integrations query your GCP services according to a polling interval, which varies depending on the integration. Polling frequency for GCP Cloud Functions: five minutes Resolution: one data point every minute View and use data After activating the integration and then waiting a few minutes (based on the polling frequency), data will appear in the UI. To view and use your data, including links to your dashboards and alert settings, go to one.newrelic.com, in top nav click Infrastructure, click GCP, then (select an integration). Metric data Metric data we receive from your GCP Cloud Functions integration includes: Attribute Description function.Executions Count of functions that executed, by status. function.ExecutionTimeNanos Time for each function to execute, in nanoseconds. function.UserMemoryBytes Memory used for each function, in bytes. Inventory data Inventory data we receive from your GCP Cloud Functions integration includes the following inventory. Important Inventory indicated with * are fetched only when the GCP project is linked to New Relic through a service account. Inventory Description description * User-provided description of a function. entryPoint * The name of the function (as defined in source code) that will be executed. eventTriggerFailurePolicy * For functions that can be triggered by events, the policy for failed executions. eventTriggerResource * For functions that can be triggered by events, the resource(s) from which to observe events. eventTriggerService * For functions that can be triggered by events, the hostname of the service that should be observed. eventTriggerType * For functions that can be triggered by events, the type of event to observe. httpsTriggerUr * For functions that can be triggered via HTTPS endpoint, the deployed URL for the function. label * Labels for the function. memory * The amount of memory in MB available for a function. name The name of the function. project The Google Cloud project that the function belongs to. runtime * The runtime in which the function is going to run. status * Status of the function deployment. timeout * The function execution timeout. Execution is considered failed and can be terminated if the function is not completed at the end of the timeout period. versionId * The version identifier of the Cloud Function. zone The zone where the function is running.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.56837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Functions monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "Our infrastructure <em>integrations</em> with the <em>Google</em> <em>Cloud</em> <em>Platform</em> (<em>GCP</em>) includes one that reports <em>Google</em> <em>Cloud</em> Functions data to our products. This document explains how to activate the <em>GCP</em> <em>Cloud</em> Functions integration and describes the data that can be reported. Features <em>Google</em> <em>Cloud</em> Functions service"
      },
      "id": "603e8f62e7b9d2fe6b2a081d"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    }
  ],
  "/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-functions-monitoring-integration": [
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-26T01:18:04Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.4567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "sections": "<em>Google</em> Compute Engine monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " your <em>GCP</em> service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your <em>Google</em> <em>Cloud</em> projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Google Serverless VPC Access monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "VPC Access Connector data"
      ],
      "title": "Google Serverless VPC Access monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "a1ee8cb1f9d6a05f4a5e5ec6ac4c5e275868e891",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-serverless-vpc-access-monitoring-integration/",
      "published_at": "2021-06-26T00:08:05Z",
      "updated_at": "2021-03-16T05:48:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your GCP VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the GCP VPC Access integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > GCP and select an integration. Data is attached to the following event type: Entity Event Type Provider Connector GcpVpcaccessConnectorSample GcpVpcaccessConnector For more on how to use your data, see Understand and use integration data. Metric data This integration collects GCP VPC Access data for Connector. VPC Access Connector data Metric Unit Description connector.ReceivedBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.ReceivedPackets Count Delta of packets received by a VPC Access Connector. connector.SentBytes Bytes Delta of bytes transferred by a VPC Access Connector. connector.SentPackets Count Delta of packets sent by a VPC Access Connector.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "sections": "<em>Google</em> Serverless VPC Access monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>GCP</em> VPC Access data to our products. Here we explain how to activate the integration and what data it collects. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e9e73196a67f7b0a83da7"
    },
    {
      "sections": [
        "Google Cloud Storage monitoring integration",
        "Features",
        "Activate integration",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "Inventory data"
      ],
      "title": "Google Cloud Storage monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "b82474e156f5c250b2a97c371b450b9254183297",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-storage-monitoring-integration/",
      "published_at": "2021-06-25T23:51:50Z",
      "updated_at": "2021-03-16T05:46:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Google Cloud Storage data to New Relic. Learn how to connect this integration to infrastructure monitoring and about the metric data and inventory data that New Relic reports for this integration. Features Google Cloud Storage is a Google Cloud Platform service that you can use to serve website content, to store data for archival and disaster recovery, and to distribute data objects via direct download. With the Google Cloud Storage integration, you can access these features: View charts and information about the data you are storing and retrieving from Google Cloud Storage. Create custom queries and charts in from automatically captured data. Set alerts on your Google Cloud Storage data directly from the Integrations page. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic. Polling frequency New Relic queries your Google Cloud Storage services based on a polling interval of 5 minutes. Find and use data After connecting the integration to New Relic and waiting a few minutes, data will appear in the New Relic UI. To find and use integration data, including your dashboards and your alert settings, go to one.newrelic.com > Infrastructure > GCP > Google Cloud Storage. To create custom dashboards for the integration, create queries for the GcpStorageBucketSample event type with the provider value GcpStorageBucket. Metric data The integration reports metric data for all values of method and response_code: response_code: The response code of the requests. method: The name of the API method called. The metric data that New Relic receives from your Google Cloud Storage integration includes: Metric Description api.Requests Delta count of API calls. network.ReceivedBytes Delta count of bytes received over the network. network.SentBytes Delta count of bytes sent over the network. Inventory data Inventory data for Google Cloud Storage bucket objects includes the following properties: Inventory data Description acl Access control list for the bucket that lets you specify who has access to your data and to what extent. cors The Cross-Origin Resource Sharing (CORS) configuration for the bucket. createTime Time when the bucket was created. defaultAcl Default access control list configuration for the bucket's blobs. etag HTTP 1.1 entity tag for the bucket. indexPage The bucket's website index page. This behaves as the bucket's directory index where missing blobs are treated as potential directories. labels Labels for the bucket, in key/value pairs. This is only available if the GCP project is linked to New Relic through a service account and extended inventory collection is enabled. metageneration The generation of the metadata for the bucket. name The name of the bucket. notFoundPage The custom object that will be returned when a requested resource is not found. owner The owner of the bucket. A bucket is always owned by the project team owners group. project The name that you assigned to the project. A project consists of a set of users, a set of APIs, and settings for those APIs. requesterPays If set to true, the user accessing the bucket or an object it contains assumes the access transit costs. storageClass The default storage class for a bucket, if you don't specify one for a new object. The storage class defines how Google Cloud Storage stores objects in the bucket and determines the SLA and storage cost. For more information, see storage classes. zone The zone where the bucket is deployed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.2667,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Google</em> <em>Cloud</em> Storage monitoring <em>integration</em>",
        "sections": "<em>Google</em> <em>Cloud</em> Storage monitoring <em>integration</em>",
        "tags": "<em>Google</em> <em>Cloud</em> <em>Platform</em> <em>integrations</em>",
        "body": " and retrieving from <em>Google</em> <em>Cloud</em> Storage. Create custom queries and charts in from automatically captured data. Set alerts on your <em>Google</em> <em>Cloud</em> Storage data directly from the <em>Integrations</em> page. Activate integration To enable the integration follow standard procedures to connect your <em>GCP</em> service to New Relic"
      },
      "id": "603e8f63196a67fa56a83dbc"
    }
  ]
}